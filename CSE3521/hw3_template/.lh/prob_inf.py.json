{
    "sourceFile": "prob_inf.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 39,
            "patches": [
                {
                    "date": 1699506624831,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1699506637766,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,9 +18,9 @@\n   variableValues: dictionary of boolean values, keys are variable names\r\n   \"\"\"\r\n   \r\n   # YOUR CODE HERE\r\n-  read_model_file(burglary_alram.csv)\r\n+  read_model_file(burglary_alarm.csv)\r\n   #\r\n   # You may assume variableValues is complete, i.e containes all variables in the model\r\n   #   Thus, no marginalization is necessary\r\n   # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n"
                },
                {
                    "date": 1699507518618,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,9 +18,8 @@\n   variableValues: dictionary of boolean values, keys are variable names\r\n   \"\"\"\r\n   \r\n   # YOUR CODE HERE\r\n-  read_model_file(burglary_alarm.csv)\r\n   #\r\n   # You may assume variableValues is complete, i.e containes all variables in the model\r\n   #   Thus, no marginalization is necessary\r\n   # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n@@ -33,10 +32,22 @@\n   #\r\n   # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n   #\r\n   # (Reference solution is 7 lines of code.)\r\n-  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+  joint_prob = 1.0\r\n \r\n+    for var in model.vars:\r\n+        parents = model.varDist[var].parents\r\n+        cond_vals = {parent: variableValues[parent] for parent in parents}\r\n+        cpt_entry = read_cpt(model, var, cond_vals)\r\n+\r\n+        if variableValues[var]:\r\n+            joint_prob *= cpt_entry\r\n+        else:\r\n+            joint_prob *= 1 - cpt_entry\r\n+\r\n+    return joint_prob\r\n+\r\n def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n   \"\"\"\r\n   Calculate posterior probability for a given variable\r\n \r\n"
                },
                {
                    "date": 1699507532394,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,684 @@\n+import argparse\r\n+import csv\r\n+from itertools import chain, permutations\r\n+import math\r\n+#import matplotlib.pyplot as plt\r\n+#import numpy as np\r\n+from random import random\r\n+import sys\r\n+\r\n+DEBUG_OUTPUT=0\r\n+\r\n+##############################################################################\r\n+## Student code\r\n+def calc_global_joint_prob(model, variableValues):\r\n+  \"\"\"\r\n+  Calculate the global joint probability of a model for a specific set of values\r\n+  model: model object, see read_model_file() for specification\r\n+  variableValues: dictionary of boolean values, keys are variable names\r\n+  \"\"\"\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # You may assume variableValues is complete, i.e containes all variables in the model\r\n+  #   Thus, no marginalization is necessary\r\n+  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n+  #\r\n+  # You can find a complete descrition of the model object in the documentation of\r\n+  #   the read_model_file() function, BUT\r\n+  # All you will need is the list of variables: model.vars\r\n+  #\r\n+  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n+  #\r\n+  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n+  #\r\n+  # (Reference solution is 7 lines of code.)\r\n+  joint_prob = 1.0\r\n+\r\n+  for var in model.vars:\r\n+      parents = model.varDist[var].parents\r\n+      cond_vals = {parent: variableValues[parent] for parent in parents}\r\n+      cpt_entry = read_cpt(model, var, cond_vals)\r\n+\r\n+      if variableValues[var]:\r\n+          joint_prob *= cpt_entry\r\n+      else:\r\n+          joint_prob *= 1 - cpt_entry\r\n+\r\n+    return joint_prob\r\n+\r\n+def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+\r\n+  # This first attempt at probabilistic inference will use the brute-force (table)\r\n+  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n+  #\r\n+  # This requires the calculation of two joint probabilities based on the definition\r\n+  # of conditional probability:\r\n+  #                          Pr( Query & Evidence )\r\n+  #   Pr(Query | Evidence) = ----------------------\r\n+  #                              Pr( Evidence )\r\n+  #\r\n+  # Both of these joint probabilities can be calculated by going over every entry in\r\n+  # the global joint probability table and summing up the probabilities of those\r\n+  # entries that match what we're looking for\r\n+  \r\n+  def dict_issubset(d,sub):\r\n+    \"\"\"\r\n+    Returns True if every key,value pair in sub has a matching key and value in d\r\n+    Note: sub should not contain any entries with value None\r\n+    \"\"\"\r\n+    return all(d.get(key,None)==val for key,val in sub.items())\r\n+     \r\n+  pr_QE=0\r\n+  pr_E=0\r\n+  for jptEntry in truefalse_combination_iterator(model.vars):\r\n+    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # jptEntry will be a dictionary with a key for every variable in the model,\r\n+    #   and the loop will go over every possible combination of True/False for each variable\r\n+    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n+    #\r\n+    # Your task is to collect all the probabilities that match the evidence, and query\r\n+    #\r\n+    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n+    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n+    #\r\n+    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n+    #\r\n+    # (Reference solution is 4 lines of code.)\r\n+    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+  return pr_QE/pr_E\r\n+\r\n+def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+  \r\n+  # First step, we need to figure out what order we will calculate terms in and where\r\n+  # marginalization needs to happen.\r\n+  #\r\n+  # That said, though this is a part of the inference process that you need to know, it's a\r\n+  # bit tricky to get working in general, especially the optimization bits.\r\n+  #\r\n+  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n+  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n+  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n+  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n+  # For example, the formula on slide 20 would be represented as:\r\n+  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n+  # The formula on slide 21 would be:\r\n+  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n+  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n+  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n+  \r\n+  # Debug: Output a nicer version of the calculation order (inference formula)\r\n+  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n+  \r\n+  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n+  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n+  \r\n+  # Next step, implement the calculation\r\n+  #\r\n+  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n+  # and move on to implement the recurse_calc_query_exact_tree() function\r\n+  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n+  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n+  # and associated function and add your own calculation code here\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n+  #\r\n+  # Normalize this result to get true probability.\r\n+  #\r\n+  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n+  #\r\n+  # Refer to the example on slide 30.\r\n+  #\r\n+  # (Reference solution is 3 lines of code.)\r\n+  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n+  \"\"\"\r\n+  Recursiving process the summation tree \r\n+  \r\n+  model,queryVar,evidence: See calc_query_exact_tree()\r\n+  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n+    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n+  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n+  \"\"\"\r\n+  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n+\r\n+  # Your overall task in the function is to assign values to:\r\n+  #   prQ_T\r\n+  #   prQ_F\r\n+  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n+  # covering both cases where query=True and query=False.\r\n+\r\n+  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n+  if marginalize:\r\n+    #Summation term, need to branch over all possible values and continue calculation\r\n+    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n+    # calculation\r\n+    #\r\n+    # You will need to recurse for each element of the summation (i.e. each branch)\r\n+    # Then properly combine the results together\r\n+    #\r\n+    # Slides 26-28 show examples of resolving summations.\r\n+    #\r\n+    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n+    #   BUT remember to change it back to the original values when you are done!\r\n+    #   (The original value for unknown variables is None.)\r\n+    #\r\n+    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n+    #   example of how to make the recursive call(s)\r\n+    #\r\n+    # (Reference solution is 7 lines of code.)\r\n+    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+  else:\r\n+    #Probability term, calculate conditional probability for this variable and continue calculation\r\n+    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n+    if queryVar in model.varDist[var].parents:\r\n+      #Query variable is a condition for this term\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n+      #\r\n+      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n+      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n+      # consider both what happens when the query variable is True, and also when it is False.\r\n+      #\r\n+      # Copy from your code below and modify to deal with this additional element.\r\n+      #\r\n+      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 11 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+    elif var==queryVar:\r\n+      #This term is probability _for_ the Query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one second! (Atleast, I recommend this.)\r\n+      #\r\n+      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n+      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n+      # is False.\r\n+      #\r\n+      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n+      # \r\n+      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 5 additional lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+    else:\r\n+      #Simple term, no need to worry about query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one first! (It's the simplest of the three.)\r\n+      #\r\n+      # You need to get the conditional probability for this variable and correctly\r\n+      # combine it with the results of the recursive call above.\r\n+      #\r\n+      # Don't forget that this variable's value could be True or False!\r\n+      #\r\n+      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n+      #\r\n+      # (Reference solution is 5 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+    if len(remainingCalc)>1:\r\n+      #If there are still terms left, then recurse\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n+      \r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Update prQ_T, prQ_F with the results from the recursive call.\r\n+      #\r\n+      # How do you combine _factors_ together?\r\n+      #\r\n+      # (Reference solution is 2 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n+  \r\n+##############################################################################\r\n+## Support code\r\n+def read_cpt(model,varName,condVals):\r\n+  \"\"\"\r\n+  Read conditional probability for a specified variable with provided condition (parent) values\r\n+  Note, the value returned is conditional probability for variable being True\r\n+  \r\n+  Warning: If you get an index exception and referenced key has None in it, this means\r\n+    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n+  \r\n+  model: model object, see read_model_file() for specification\r\n+  varName: string, variable name to read probability for\r\n+  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n+              (Missing conditions will cause errors, extraneous values will be ignored)\r\n+  \"\"\"\r\n+  if varName not in model.varDist:\r\n+    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n+  varDist=model.varDist[varName]\r\n+  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n+  if key not in varDist.cpt:\r\n+    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n+  return varDist.cpt[key]\r\n+\r\n+def truefalse_combination_iterator(entries):\r\n+  \"\"\"\r\n+  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n+  \"\"\"\r\n+  entries=list(entries)\r\n+  entries.reverse()\r\n+  if len(entries)>30:\r\n+    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n+  for c in range(1<<len(entries)):\r\n+    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n+\r\n+def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n+  \"\"\"\r\n+  Create represention of terms in an inference calculation such as on slides 20-21\r\n+  \r\n+  Returns a list of (boolean,string) tuples where:\r\n+    (True,variable) represents a summation term where a variable needs to be marginalized\r\n+    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n+  \"\"\"\r\n+  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Naive solution\r\n+  #\r\n+  # model.varsDep already has variables in order of dependency...\r\n+  # So take that and insert summation terms any time we encounter a new hidden variable\r\n+  #\r\n+  # Downside is little optimization, likely to have many unnecessary terms\r\n+  if False:\r\n+    hiddenLeft=set(hiddenVars)\r\n+    seq=[]\r\n+    for v in model.varsDep:\r\n+      #Check if factor variable is a (unhandled) hidden variable\r\n+      if v in hiddenLeft:\r\n+        seq.append( (True,v) ) #If so, trigger a marginalization\r\n+        hiddenLeft.remove(v)   #And mark it as handled\r\n+      for p in model.varDist[v].parents:\r\n+        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n+        if p in hiddenLeft:\r\n+          seq.append( (True,p) )\r\n+          hiddenLeft.remove(p)\r\n+      seq.append( (False,v) ) #Then process the factor itself\r\n+    assert(len(hiddenLeft)==0)\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Arbitrary ordering\r\n+  #\r\n+  # What if we wanted to handle hidden variables in an arbitrary order?\r\n+  #\r\n+  # Possible, but we'll have to be careful where we put factors, after\r\n+  # all their dependencies are satisfied.\r\n+  def seq_from_hid_order(hOrd):\r\n+    #The trick to make this work is to first assign every\r\n+    #hidden variable a priority based on the order\r\n+    prio={h:i for i,h in enumerate(hOrd)}\r\n+    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n+    #Then rate each factor on the highest priority amongst its dependencies\r\n+    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n+    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n+    vOrd.sort()\r\n+    #All that's left is to turn it into the expected sequence format\r\n+    return list( (not nm,v) for _,nm,v in vOrd )\r\n+  \r\n+  #--------------------------------------------------------\r\n+  # Brute force best\r\n+  #\r\n+  # Now, where to get an ordering to use the above?\r\n+  #\r\n+  # We could brute force try every possible ordering...\r\n+  if True:\r\n+    bestSeq=None\r\n+    bestSeqCost=sys.maxsize\r\n+    for hOrd in permutations(hiddenVars):\r\n+      tSeq=seq_from_hid_order(hOrd)\r\n+      #Note, really should do below norm optimization here too\r\n+      \r\n+      #Now the tricky bit is to rate each ordering\r\n+      #We'll do it by doubling the cost of each factor every time\r\n+      #We cross a summation\r\n+      tot=0\r\n+      ct=1\r\n+      for m,v in tSeq:\r\n+        if m:\r\n+          ct*=2\r\n+        else:\r\n+          tot+=ct\r\n+      \r\n+      if tot<bestSeqCost:\r\n+        bestSeq=tSeq\r\n+        bestSeqCost=tot\r\n+    seq=bestSeq\r\n+  # But this will be very expensive for large models\r\n+  #--------------------------------------------------------\r\n+  # Greedy\r\n+  #\r\n+  # Alternately, we could apply a greedy approach.\r\n+  #\r\n+  # Some how rate each hidden variable on how expensive we think\r\n+  # it is, then put the most expensive ones earliest\r\n+  # ***TODO***\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Simple normalization optimization\r\n+  #\r\n+  # One thing we learned is that for a multiplicative term,\r\n+  # if it doesn't mention the query variable, then it's a\r\n+  # constant and can be handled via normalization (folded into alpha)\r\n+  #\r\n+  # This is non-trivial to detect for summation terms, but we\r\n+  # can easily do it for factors outside of any summation...\r\n+  if True:\r\n+    i=0\r\n+    while i<len(seq):\r\n+      m,v=seq[i]\r\n+      if m:\r\n+        break #Found first summation, quit\r\n+      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n+        #No mention of query variable, remove\r\n+        del seq[i]\r\n+      else:\r\n+        i+=1\r\n+  \r\n+  return seq\r\n+\r\n+def calc_query_approx(model,queryVar,queryVal,evidence):\r\n+  raise NotImplementedError()\r\n+\r\n+def generate_joint_prob_table(model):\r\n+  \"\"\"\r\n+  Output a joint probability table for the provided model\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  table=[]\r\n+  row=list(model.vars)\r\n+  row.append('Joint Pr')\r\n+  table.append(row)\r\n+  for varVals in truefalse_combination_iterator(model.vars):\r\n+    pr=calc_global_joint_prob(model,varVals)\r\n+    row=[varVals[x] for x in model.vars]\r\n+    row.append(pr)\r\n+    table.append(row)\r\n+  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+  return\r\n+\r\n+def read_model_file(filename):\r\n+  \"\"\"\r\n+  Returns model object with the following elements:\r\n+    vars : list of strings\r\n+      The list of variables the model describes\r\n+      In alphabetical order\r\n+    varsDep : list of strings\r\n+      Same contents as 'vars' but in dependency order (parents come before children)\r\n+    varDist : dict of objects\r\n+      Distribution information for each variable\r\n+      Dictionary key is variable name\r\n+      Object has the following elements:\r\n+        parents : set of strings\r\n+        children : set of strings\r\n+        cpt : dict of numbers\r\n+          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n+          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n+            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n+  Model file format is as follows:\r\n+    Basic file format is Comma-Separated Value (.csv)\r\n+    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n+    Tables are separated by atleast one empty line\r\n+    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n+    Each table:\r\n+      Starts with a header row containing variable names\r\n+        The last name is the variable whose cond probability is being described\r\n+        Any preceding names are considered to be parent variables\r\n+      Following rows contain True/False values for each parent and probability for main variable being true\r\n+      Any missing parent value combinations will be assumed to be probability 0.5\r\n+    Only Bernoulli/Boolean variables can be represented in this file format\r\n+  \"\"\"\r\n+  class ModelObj:\r\n+    def __init__(self):\r\n+      self.vars=[]\r\n+      self.varsDep=None\r\n+      self.varDist={}\r\n+\r\n+  class VarObj:\r\n+    def __init__(self, parents, children, cpt):\r\n+      self.parents = parents\r\n+      self.children = children\r\n+      self.cpt = cpt\r\n+\r\n+  model=ModelObj()\r\n+  #--------------------------------------------------------\r\n+  #Read data from file\r\n+  with open(filename, newline='') as csvfile:\r\n+    csvreader = csv.reader(csvfile)\r\n+    \r\n+    rowNum=0\r\n+    var=None\r\n+    varIdx=None\r\n+    parents=None\r\n+    cpt=None\r\n+    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n+      rowNum+=1\r\n+      srow=''.join(row).strip()\r\n+      if srow.startswith('#'):\r\n+        continue #Comment line, skip\r\n+      if len(srow)==0:\r\n+        #Empty line\r\n+        if var is not None:\r\n+          #End current table\r\n+          model.vars.append(var)\r\n+          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n+          #Wait for new table\r\n+          var=None\r\n+          varIdx=None\r\n+          parents=None\r\n+          cpt=None\r\n+      elif var is None:\r\n+        #Start new table\r\n+        if len(row)>1:\r\n+          parents=row[0:-1]\r\n+        else:\r\n+          parents=[]\r\n+        varIdx=len(row)-1\r\n+        var=row[varIdx]\r\n+        cpt={}\r\n+      else:\r\n+        #Add new entry to table\r\n+        if len(row)<varIdx+1:\r\n+          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n+        if len(parents)>0:\r\n+          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n+        else:\r\n+          key=frozenset()\r\n+        cpt[key]=float(row[-1])\r\n+  model.vars.sort()\r\n+  #--------------------------------------------------------\r\n+  # Check distributions for missing entries\r\n+  vCheck=frozenset(model.vars)\r\n+  for var in model.vars: #Make sure every mentioned variable has an entry\r\n+    for p in model.varDist[var].parents:\r\n+      if p not in vCheck:\r\n+        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n+  for var in model.vars: #Check every cpt for missing rows\r\n+    varDist=model.varDist[var]\r\n+    missingCnt=0\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      key=frozenset(((x,v) for x,v in varVals.items()))\r\n+      if key not in varDist.cpt:\r\n+        missingCnt+=1\r\n+        varDist.cpt[key]=0.5\r\n+    if missingCnt>0:\r\n+      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n+  #--------------------------------------------------------\r\n+  # Create children entries\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=set()\r\n+  for var in model.vars:\r\n+    for p in model.varDist[var].parents:\r\n+      model.varDist[p].children.add(var)\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n+  #--------------------------------------------------------\r\n+  # Create dependency ordering\r\n+  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n+  idx=0\r\n+  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n+  while idx<len(varsDep):\r\n+    var=varsDep[idx]\r\n+    for c in model.varDist[var].children:\r\n+      parentsLeft[c]-=1\r\n+      if parentsLeft[c]==0:\r\n+        #All parents have been visited, so dependencies of this child are met\r\n+        varsDep.append(c)\r\n+      elif parentsLeft[c]<0:\r\n+        #Repeat visit to a parent can only happen if a cycle exists\r\n+        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n+    idx+=1\r\n+  model.varsDep=varsDep\r\n+  #--------------------------------------------------------\r\n+  return model\r\n+\r\n+def print_model(model):\r\n+  \"\"\"\r\n+  Print a model object back out in pretty form\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  for v in model.vars:\r\n+    varDist=model.varDist[v]\r\n+    print('--------------------------------------------------')\r\n+    print('Variable:',v)\r\n+    print('--------------------------------------------------')\r\n+    print('Children:',', '.join(varDist.children))\r\n+    \r\n+    table=[]\r\n+    row=list(varDist.parents)\r\n+    row.append('P({0}=T|...)'.format(v))\r\n+    table.append(row)\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      pr=read_cpt(model,v,varVals)\r\n+      row=[varVals[x] for x in varDist.parents]\r\n+      row.append(pr)\r\n+      table.append(row)\r\n+    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+    print(\"\")\r\n+    \r\n+##############################################################################\r\n+## Main functions\r\n+def main(args):\r\n+  global DEBUG_OUTPUT\r\n+  if args.debug:\r\n+    DEBUG_OUTPUT=1\r\n+  #Argument checking plus additional parsing\r\n+  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in table mode')\r\n+  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in print mode')\r\n+  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n+    error('Argument --query required in inference modes')\r\n+  elif args.query is not None:\r\n+    if '=' not in args.query:\r\n+      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n+    s=args.query.split('=')\r\n+    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n+  if args.evidence is None:\r\n+    args.evidence=[]\r\n+  else:\r\n+    ev=[]\r\n+    for e in args.evidence:\r\n+      if '=' not in e:\r\n+        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n+      s=e.split('=')\r\n+      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n+    args.evidence={ var:val for var,val in ev }\r\n+\r\n+  print('Reading model from',args.model)\r\n+  model=read_model_file(args.model)\r\n+\r\n+  if args.mode=='table':\r\n+    generate_joint_prob_table(model)\r\n+  elif args.mode=='print':\r\n+    print_model(model)\r\n+  else:\r\n+    #One of the inference modes\r\n+    #Check inputs against model\r\n+    if args.query[0] not in model.vars:\r\n+      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n+    for var,val in args.evidence.items():\r\n+      if var not in model.vars:\r\n+        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n+    #Output problem setup\r\n+    print(\"Inference mode:\",args.mode)\r\n+    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n+    if len(args.evidence)==0:\r\n+      print(\"No evidence\")\r\n+    else:\r\n+      print(\"Evidence:\")\r\n+      for var,val in args.evidence.items():\r\n+        print(\"  '{0}' is {1}\".format(var,val))\r\n+\r\n+    #Run inference\r\n+    pr=None\r\n+    if args.mode=='brute':\r\n+      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n+    elif args.mode=='tree':\r\n+      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n+    else: #args.mode=='approx'\r\n+      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n+    print('Probability is',pr)\r\n+\r\n+  return\r\n+\r\n+def error(msg):\r\n+  print(msg)\r\n+  sys.exit(1)\r\n+  return\r\n+\r\n+if __name__ == '__main__':\r\n+  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n+  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n+  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n+  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n+  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n+  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n+  args = parser.parse_args()\r\n+  error=lambda msg : parser.error(msg)\r\n+  main(args)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1699507540334,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,684 @@\n+import argparse\r\n+import csv\r\n+from itertools import chain, permutations\r\n+import math\r\n+#import matplotlib.pyplot as plt\r\n+#import numpy as np\r\n+from random import random\r\n+import sys\r\n+\r\n+DEBUG_OUTPUT=0\r\n+\r\n+##############################################################################\r\n+## Student code\r\n+def calc_global_joint_prob(model, variableValues):\r\n+  \"\"\"\r\n+  Calculate the global joint probability of a model for a specific set of values\r\n+  model: model object, see read_model_file() for specification\r\n+  variableValues: dictionary of boolean values, keys are variable names\r\n+  \"\"\"\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # You may assume variableValues is complete, i.e containes all variables in the model\r\n+  #   Thus, no marginalization is necessary\r\n+  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n+  #\r\n+  # You can find a complete descrition of the model object in the documentation of\r\n+  #   the read_model_file() function, BUT\r\n+  # All you will need is the list of variables: model.vars\r\n+  #\r\n+  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n+  #\r\n+  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n+  #\r\n+  # (Reference solution is 7 lines of code.)\r\n+  joint_prob = 1.0\r\n+\r\n+  for var in model.vars:\r\n+      parents = model.varDist[var].parents\r\n+      cond_vals = {parent: variableValues[parent] for parent in parents}\r\n+      cpt_entry = read_cpt(model, var, cond_vals)\r\n+\r\n+      if variableValues[var]:\r\n+          joint_prob *= cpt_entry\r\n+      else:\r\n+          joint_prob *= 1 - cpt_entry\r\n+\r\n+  return joint_prob\r\n+\r\n+def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+\r\n+  # This first attempt at probabilistic inference will use the brute-force (table)\r\n+  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n+  #\r\n+  # This requires the calculation of two joint probabilities based on the definition\r\n+  # of conditional probability:\r\n+  #                          Pr( Query & Evidence )\r\n+  #   Pr(Query | Evidence) = ----------------------\r\n+  #                              Pr( Evidence )\r\n+  #\r\n+  # Both of these joint probabilities can be calculated by going over every entry in\r\n+  # the global joint probability table and summing up the probabilities of those\r\n+  # entries that match what we're looking for\r\n+  \r\n+  def dict_issubset(d,sub):\r\n+    \"\"\"\r\n+    Returns True if every key,value pair in sub has a matching key and value in d\r\n+    Note: sub should not contain any entries with value None\r\n+    \"\"\"\r\n+    return all(d.get(key,None)==val for key,val in sub.items())\r\n+     \r\n+  pr_QE=0\r\n+  pr_E=0\r\n+  for jptEntry in truefalse_combination_iterator(model.vars):\r\n+    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # jptEntry will be a dictionary with a key for every variable in the model,\r\n+    #   and the loop will go over every possible combination of True/False for each variable\r\n+    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n+    #\r\n+    # Your task is to collect all the probabilities that match the evidence, and query\r\n+    #\r\n+    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n+    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n+    #\r\n+    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n+    #\r\n+    # (Reference solution is 4 lines of code.)\r\n+    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+  return pr_QE/pr_E\r\n+\r\n+def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+  \r\n+  # First step, we need to figure out what order we will calculate terms in and where\r\n+  # marginalization needs to happen.\r\n+  #\r\n+  # That said, though this is a part of the inference process that you need to know, it's a\r\n+  # bit tricky to get working in general, especially the optimization bits.\r\n+  #\r\n+  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n+  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n+  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n+  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n+  # For example, the formula on slide 20 would be represented as:\r\n+  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n+  # The formula on slide 21 would be:\r\n+  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n+  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n+  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n+  \r\n+  # Debug: Output a nicer version of the calculation order (inference formula)\r\n+  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n+  \r\n+  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n+  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n+  \r\n+  # Next step, implement the calculation\r\n+  #\r\n+  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n+  # and move on to implement the recurse_calc_query_exact_tree() function\r\n+  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n+  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n+  # and associated function and add your own calculation code here\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n+  #\r\n+  # Normalize this result to get true probability.\r\n+  #\r\n+  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n+  #\r\n+  # Refer to the example on slide 30.\r\n+  #\r\n+  # (Reference solution is 3 lines of code.)\r\n+  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n+  \"\"\"\r\n+  Recursiving process the summation tree \r\n+  \r\n+  model,queryVar,evidence: See calc_query_exact_tree()\r\n+  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n+    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n+  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n+  \"\"\"\r\n+  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n+\r\n+  # Your overall task in the function is to assign values to:\r\n+  #   prQ_T\r\n+  #   prQ_F\r\n+  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n+  # covering both cases where query=True and query=False.\r\n+\r\n+  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n+  if marginalize:\r\n+    #Summation term, need to branch over all possible values and continue calculation\r\n+    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n+    # calculation\r\n+    #\r\n+    # You will need to recurse for each element of the summation (i.e. each branch)\r\n+    # Then properly combine the results together\r\n+    #\r\n+    # Slides 26-28 show examples of resolving summations.\r\n+    #\r\n+    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n+    #   BUT remember to change it back to the original values when you are done!\r\n+    #   (The original value for unknown variables is None.)\r\n+    #\r\n+    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n+    #   example of how to make the recursive call(s)\r\n+    #\r\n+    # (Reference solution is 7 lines of code.)\r\n+    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+  else:\r\n+    #Probability term, calculate conditional probability for this variable and continue calculation\r\n+    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n+    if queryVar in model.varDist[var].parents:\r\n+      #Query variable is a condition for this term\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n+      #\r\n+      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n+      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n+      # consider both what happens when the query variable is True, and also when it is False.\r\n+      #\r\n+      # Copy from your code below and modify to deal with this additional element.\r\n+      #\r\n+      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 11 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+    elif var==queryVar:\r\n+      #This term is probability _for_ the Query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one second! (Atleast, I recommend this.)\r\n+      #\r\n+      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n+      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n+      # is False.\r\n+      #\r\n+      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n+      # \r\n+      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 5 additional lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+    else:\r\n+      #Simple term, no need to worry about query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one first! (It's the simplest of the three.)\r\n+      #\r\n+      # You need to get the conditional probability for this variable and correctly\r\n+      # combine it with the results of the recursive call above.\r\n+      #\r\n+      # Don't forget that this variable's value could be True or False!\r\n+      #\r\n+      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n+      #\r\n+      # (Reference solution is 5 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+    if len(remainingCalc)>1:\r\n+      #If there are still terms left, then recurse\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n+      \r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Update prQ_T, prQ_F with the results from the recursive call.\r\n+      #\r\n+      # How do you combine _factors_ together?\r\n+      #\r\n+      # (Reference solution is 2 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n+  \r\n+##############################################################################\r\n+## Support code\r\n+def read_cpt(model,varName,condVals):\r\n+  \"\"\"\r\n+  Read conditional probability for a specified variable with provided condition (parent) values\r\n+  Note, the value returned is conditional probability for variable being True\r\n+  \r\n+  Warning: If you get an index exception and referenced key has None in it, this means\r\n+    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n+  \r\n+  model: model object, see read_model_file() for specification\r\n+  varName: string, variable name to read probability for\r\n+  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n+              (Missing conditions will cause errors, extraneous values will be ignored)\r\n+  \"\"\"\r\n+  if varName not in model.varDist:\r\n+    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n+  varDist=model.varDist[varName]\r\n+  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n+  if key not in varDist.cpt:\r\n+    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n+  return varDist.cpt[key]\r\n+\r\n+def truefalse_combination_iterator(entries):\r\n+  \"\"\"\r\n+  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n+  \"\"\"\r\n+  entries=list(entries)\r\n+  entries.reverse()\r\n+  if len(entries)>30:\r\n+    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n+  for c in range(1<<len(entries)):\r\n+    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n+\r\n+def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n+  \"\"\"\r\n+  Create represention of terms in an inference calculation such as on slides 20-21\r\n+  \r\n+  Returns a list of (boolean,string) tuples where:\r\n+    (True,variable) represents a summation term where a variable needs to be marginalized\r\n+    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n+  \"\"\"\r\n+  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Naive solution\r\n+  #\r\n+  # model.varsDep already has variables in order of dependency...\r\n+  # So take that and insert summation terms any time we encounter a new hidden variable\r\n+  #\r\n+  # Downside is little optimization, likely to have many unnecessary terms\r\n+  if False:\r\n+    hiddenLeft=set(hiddenVars)\r\n+    seq=[]\r\n+    for v in model.varsDep:\r\n+      #Check if factor variable is a (unhandled) hidden variable\r\n+      if v in hiddenLeft:\r\n+        seq.append( (True,v) ) #If so, trigger a marginalization\r\n+        hiddenLeft.remove(v)   #And mark it as handled\r\n+      for p in model.varDist[v].parents:\r\n+        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n+        if p in hiddenLeft:\r\n+          seq.append( (True,p) )\r\n+          hiddenLeft.remove(p)\r\n+      seq.append( (False,v) ) #Then process the factor itself\r\n+    assert(len(hiddenLeft)==0)\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Arbitrary ordering\r\n+  #\r\n+  # What if we wanted to handle hidden variables in an arbitrary order?\r\n+  #\r\n+  # Possible, but we'll have to be careful where we put factors, after\r\n+  # all their dependencies are satisfied.\r\n+  def seq_from_hid_order(hOrd):\r\n+    #The trick to make this work is to first assign every\r\n+    #hidden variable a priority based on the order\r\n+    prio={h:i for i,h in enumerate(hOrd)}\r\n+    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n+    #Then rate each factor on the highest priority amongst its dependencies\r\n+    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n+    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n+    vOrd.sort()\r\n+    #All that's left is to turn it into the expected sequence format\r\n+    return list( (not nm,v) for _,nm,v in vOrd )\r\n+  \r\n+  #--------------------------------------------------------\r\n+  # Brute force best\r\n+  #\r\n+  # Now, where to get an ordering to use the above?\r\n+  #\r\n+  # We could brute force try every possible ordering...\r\n+  if True:\r\n+    bestSeq=None\r\n+    bestSeqCost=sys.maxsize\r\n+    for hOrd in permutations(hiddenVars):\r\n+      tSeq=seq_from_hid_order(hOrd)\r\n+      #Note, really should do below norm optimization here too\r\n+      \r\n+      #Now the tricky bit is to rate each ordering\r\n+      #We'll do it by doubling the cost of each factor every time\r\n+      #We cross a summation\r\n+      tot=0\r\n+      ct=1\r\n+      for m,v in tSeq:\r\n+        if m:\r\n+          ct*=2\r\n+        else:\r\n+          tot+=ct\r\n+      \r\n+      if tot<bestSeqCost:\r\n+        bestSeq=tSeq\r\n+        bestSeqCost=tot\r\n+    seq=bestSeq\r\n+  # But this will be very expensive for large models\r\n+  #--------------------------------------------------------\r\n+  # Greedy\r\n+  #\r\n+  # Alternately, we could apply a greedy approach.\r\n+  #\r\n+  # Some how rate each hidden variable on how expensive we think\r\n+  # it is, then put the most expensive ones earliest\r\n+  # ***TODO***\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Simple normalization optimization\r\n+  #\r\n+  # One thing we learned is that for a multiplicative term,\r\n+  # if it doesn't mention the query variable, then it's a\r\n+  # constant and can be handled via normalization (folded into alpha)\r\n+  #\r\n+  # This is non-trivial to detect for summation terms, but we\r\n+  # can easily do it for factors outside of any summation...\r\n+  if True:\r\n+    i=0\r\n+    while i<len(seq):\r\n+      m,v=seq[i]\r\n+      if m:\r\n+        break #Found first summation, quit\r\n+      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n+        #No mention of query variable, remove\r\n+        del seq[i]\r\n+      else:\r\n+        i+=1\r\n+  \r\n+  return seq\r\n+\r\n+def calc_query_approx(model,queryVar,queryVal,evidence):\r\n+  raise NotImplementedError()\r\n+\r\n+def generate_joint_prob_table(model):\r\n+  \"\"\"\r\n+  Output a joint probability table for the provided model\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  table=[]\r\n+  row=list(model.vars)\r\n+  row.append('Joint Pr')\r\n+  table.append(row)\r\n+  for varVals in truefalse_combination_iterator(model.vars):\r\n+    pr=calc_global_joint_prob(model,varVals)\r\n+    row=[varVals[x] for x in model.vars]\r\n+    row.append(pr)\r\n+    table.append(row)\r\n+  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+  return\r\n+\r\n+def read_model_file(filename):\r\n+  \"\"\"\r\n+  Returns model object with the following elements:\r\n+    vars : list of strings\r\n+      The list of variables the model describes\r\n+      In alphabetical order\r\n+    varsDep : list of strings\r\n+      Same contents as 'vars' but in dependency order (parents come before children)\r\n+    varDist : dict of objects\r\n+      Distribution information for each variable\r\n+      Dictionary key is variable name\r\n+      Object has the following elements:\r\n+        parents : set of strings\r\n+        children : set of strings\r\n+        cpt : dict of numbers\r\n+          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n+          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n+            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n+  Model file format is as follows:\r\n+    Basic file format is Comma-Separated Value (.csv)\r\n+    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n+    Tables are separated by atleast one empty line\r\n+    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n+    Each table:\r\n+      Starts with a header row containing variable names\r\n+        The last name is the variable whose cond probability is being described\r\n+        Any preceding names are considered to be parent variables\r\n+      Following rows contain True/False values for each parent and probability for main variable being true\r\n+      Any missing parent value combinations will be assumed to be probability 0.5\r\n+    Only Bernoulli/Boolean variables can be represented in this file format\r\n+  \"\"\"\r\n+  class ModelObj:\r\n+    def __init__(self):\r\n+      self.vars=[]\r\n+      self.varsDep=None\r\n+      self.varDist={}\r\n+\r\n+  class VarObj:\r\n+    def __init__(self, parents, children, cpt):\r\n+      self.parents = parents\r\n+      self.children = children\r\n+      self.cpt = cpt\r\n+\r\n+  model=ModelObj()\r\n+  #--------------------------------------------------------\r\n+  #Read data from file\r\n+  with open(filename, newline='') as csvfile:\r\n+    csvreader = csv.reader(csvfile)\r\n+    \r\n+    rowNum=0\r\n+    var=None\r\n+    varIdx=None\r\n+    parents=None\r\n+    cpt=None\r\n+    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n+      rowNum+=1\r\n+      srow=''.join(row).strip()\r\n+      if srow.startswith('#'):\r\n+        continue #Comment line, skip\r\n+      if len(srow)==0:\r\n+        #Empty line\r\n+        if var is not None:\r\n+          #End current table\r\n+          model.vars.append(var)\r\n+          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n+          #Wait for new table\r\n+          var=None\r\n+          varIdx=None\r\n+          parents=None\r\n+          cpt=None\r\n+      elif var is None:\r\n+        #Start new table\r\n+        if len(row)>1:\r\n+          parents=row[0:-1]\r\n+        else:\r\n+          parents=[]\r\n+        varIdx=len(row)-1\r\n+        var=row[varIdx]\r\n+        cpt={}\r\n+      else:\r\n+        #Add new entry to table\r\n+        if len(row)<varIdx+1:\r\n+          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n+        if len(parents)>0:\r\n+          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n+        else:\r\n+          key=frozenset()\r\n+        cpt[key]=float(row[-1])\r\n+  model.vars.sort()\r\n+  #--------------------------------------------------------\r\n+  # Check distributions for missing entries\r\n+  vCheck=frozenset(model.vars)\r\n+  for var in model.vars: #Make sure every mentioned variable has an entry\r\n+    for p in model.varDist[var].parents:\r\n+      if p not in vCheck:\r\n+        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n+  for var in model.vars: #Check every cpt for missing rows\r\n+    varDist=model.varDist[var]\r\n+    missingCnt=0\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      key=frozenset(((x,v) for x,v in varVals.items()))\r\n+      if key not in varDist.cpt:\r\n+        missingCnt+=1\r\n+        varDist.cpt[key]=0.5\r\n+    if missingCnt>0:\r\n+      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n+  #--------------------------------------------------------\r\n+  # Create children entries\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=set()\r\n+  for var in model.vars:\r\n+    for p in model.varDist[var].parents:\r\n+      model.varDist[p].children.add(var)\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n+  #--------------------------------------------------------\r\n+  # Create dependency ordering\r\n+  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n+  idx=0\r\n+  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n+  while idx<len(varsDep):\r\n+    var=varsDep[idx]\r\n+    for c in model.varDist[var].children:\r\n+      parentsLeft[c]-=1\r\n+      if parentsLeft[c]==0:\r\n+        #All parents have been visited, so dependencies of this child are met\r\n+        varsDep.append(c)\r\n+      elif parentsLeft[c]<0:\r\n+        #Repeat visit to a parent can only happen if a cycle exists\r\n+        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n+    idx+=1\r\n+  model.varsDep=varsDep\r\n+  #--------------------------------------------------------\r\n+  return model\r\n+\r\n+def print_model(model):\r\n+  \"\"\"\r\n+  Print a model object back out in pretty form\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  for v in model.vars:\r\n+    varDist=model.varDist[v]\r\n+    print('--------------------------------------------------')\r\n+    print('Variable:',v)\r\n+    print('--------------------------------------------------')\r\n+    print('Children:',', '.join(varDist.children))\r\n+    \r\n+    table=[]\r\n+    row=list(varDist.parents)\r\n+    row.append('P({0}=T|...)'.format(v))\r\n+    table.append(row)\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      pr=read_cpt(model,v,varVals)\r\n+      row=[varVals[x] for x in varDist.parents]\r\n+      row.append(pr)\r\n+      table.append(row)\r\n+    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+    print(\"\")\r\n+    \r\n+##############################################################################\r\n+## Main functions\r\n+def main(args):\r\n+  global DEBUG_OUTPUT\r\n+  if args.debug:\r\n+    DEBUG_OUTPUT=1\r\n+  #Argument checking plus additional parsing\r\n+  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in table mode')\r\n+  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in print mode')\r\n+  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n+    error('Argument --query required in inference modes')\r\n+  elif args.query is not None:\r\n+    if '=' not in args.query:\r\n+      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n+    s=args.query.split('=')\r\n+    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n+  if args.evidence is None:\r\n+    args.evidence=[]\r\n+  else:\r\n+    ev=[]\r\n+    for e in args.evidence:\r\n+      if '=' not in e:\r\n+        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n+      s=e.split('=')\r\n+      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n+    args.evidence={ var:val for var,val in ev }\r\n+\r\n+  print('Reading model from',args.model)\r\n+  model=read_model_file(args.model)\r\n+\r\n+  if args.mode=='table':\r\n+    generate_joint_prob_table(model)\r\n+  elif args.mode=='print':\r\n+    print_model(model)\r\n+  else:\r\n+    #One of the inference modes\r\n+    #Check inputs against model\r\n+    if args.query[0] not in model.vars:\r\n+      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n+    for var,val in args.evidence.items():\r\n+      if var not in model.vars:\r\n+        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n+    #Output problem setup\r\n+    print(\"Inference mode:\",args.mode)\r\n+    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n+    if len(args.evidence)==0:\r\n+      print(\"No evidence\")\r\n+    else:\r\n+      print(\"Evidence:\")\r\n+      for var,val in args.evidence.items():\r\n+        print(\"  '{0}' is {1}\".format(var,val))\r\n+\r\n+    #Run inference\r\n+    pr=None\r\n+    if args.mode=='brute':\r\n+      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n+    elif args.mode=='tree':\r\n+      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n+    else: #args.mode=='approx'\r\n+      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n+    print('Probability is',pr)\r\n+\r\n+  return\r\n+\r\n+def error(msg):\r\n+  print(msg)\r\n+  sys.exit(1)\r\n+  return\r\n+\r\n+if __name__ == '__main__':\r\n+  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n+  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n+  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n+  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n+  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n+  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n+  args = parser.parse_args()\r\n+  error=lambda msg : parser.error(msg)\r\n+  main(args)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1699507644935,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -69,693 +69,28 @@\n   #\r\n   # Both of these joint probabilities can be calculated by going over every entry in\r\n   # the global joint probability table and summing up the probabilities of those\r\n   # entries that match what we're looking for\r\n-  \r\n-  def dict_issubset(d,sub):\r\n-    \"\"\"\r\n-    Returns True if every key,value pair in sub has a matching key and value in d\r\n-    Note: sub should not contain any entries with value None\r\n-    \"\"\"\r\n-    return all(d.get(key,None)==val for key,val in sub.items())\r\n-     \r\n-  pr_QE=0\r\n-  pr_E=0\r\n-  for jptEntry in truefalse_combination_iterator(model.vars):\r\n-    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n+  joint_prob_table = {}\r\n+  hidden_vars = [var for var in model.vars if var != queryVar and var not in evidence]\r\n \r\n-    # YOUR CODE HERE\r\n-    #\r\n-    # jptEntry will be a dictionary with a key for every variable in the model,\r\n-    #   and the loop will go over every possible combination of True/False for each variable\r\n-    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n-    #\r\n-    # Your task is to collect all the probabilities that match the evidence, and query\r\n-    #\r\n-    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n-    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n-    #\r\n-    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n-    #\r\n-    # (Reference solution is 4 lines of code.)\r\n-    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+  for assignment in product([True, False], repeat=len(hidden_vars)):\r\n+      variable_values = dict(zip(hidden_vars, assignment))\r\n+      variable_values.update(evidence)\r\n+      variable_values[queryVar] = queryVal\r\n+      joint_prob_table[tuple(variable_values.items())] = calc_global_joint_prob(model, variable_values)\r\n \r\n-  return pr_QE/pr_E\r\n+    # Calculate the numerator (joint probability of query variable and evidence)\r\n+  query_evidence_entry = {queryVar: queryVal, **evidence}\r\n+  numerator = joint_prob_table[tuple(query_evidence_entry.items())]\r\n \r\n-def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n-  \"\"\"\r\n-  Calculate posterior probability for a given variable\r\n+    # Calculate the denominator (sum of joint probabilities for all possible values of the query variable)\r\n+  denominator = sum(joint_prob for key, joint_prob in joint_prob_table.items() if key[0][0] == queryVar)\r\n \r\n-  model: model object, see read_model_file() for specification\r\n-  queryVar: string, query variable name\r\n-  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n-  evidence: dictionary of boolean values, where keys are evidence variable names\r\n-            (Any variable not listed as query or evidence is assumed to be hidden)\r\n-  \"\"\"\r\n-  \r\n-  # First step, we need to figure out what order we will calculate terms in and where\r\n-  # marginalization needs to happen.\r\n-  #\r\n-  # That said, though this is a part of the inference process that you need to know, it's a\r\n-  # bit tricky to get working in general, especially the optimization bits.\r\n-  #\r\n-  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n-  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n-  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n-  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n-  # For example, the formula on slide 20 would be represented as:\r\n-  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n-  # The formula on slide 21 would be:\r\n-  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n-  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n-  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n-  \r\n-  # Debug: Output a nicer version of the calculation order (inference formula)\r\n-  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n-  \r\n-  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n-  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n-  \r\n-  # Next step, implement the calculation\r\n-  #\r\n-  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n-  # and move on to implement the recurse_calc_query_exact_tree() function\r\n-  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n-  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n-  # and associated function and add your own calculation code here\r\n-  \r\n-  # YOUR CODE HERE\r\n-  #\r\n-  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n-  #\r\n-  # Normalize this result to get true probability.\r\n-  #\r\n-  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n-  #\r\n-  # Refer to the example on slide 30.\r\n-  #\r\n-  # (Reference solution is 3 lines of code.)\r\n-  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+    # Calculate and return the posterior probability\r\n+  posterior_prob = numerator / denominator\r\n+  return posterior_prob\r\n \r\n-def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n-  \"\"\"\r\n-  Recursiving process the summation tree \r\n-  \r\n-  model,queryVar,evidence: See calc_query_exact_tree()\r\n-  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n-    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n-  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n-  \"\"\"\r\n-  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n-\r\n-  # Your overall task in the function is to assign values to:\r\n-  #   prQ_T\r\n-  #   prQ_F\r\n-  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n-  # covering both cases where query=True and query=False.\r\n-\r\n-  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n-  if marginalize:\r\n-    #Summation term, need to branch over all possible values and continue calculation\r\n-    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n-\r\n-    # YOUR CODE HERE\r\n-    #\r\n-    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n-    # calculation\r\n-    #\r\n-    # You will need to recurse for each element of the summation (i.e. each branch)\r\n-    # Then properly combine the results together\r\n-    #\r\n-    # Slides 26-28 show examples of resolving summations.\r\n-    #\r\n-    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n-    #   BUT remember to change it back to the original values when you are done!\r\n-    #   (The original value for unknown variables is None.)\r\n-    #\r\n-    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n-    #   example of how to make the recursive call(s)\r\n-    #\r\n-    # (Reference solution is 7 lines of code.)\r\n-    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-  else:\r\n-    #Probability term, calculate conditional probability for this variable and continue calculation\r\n-    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n-    if queryVar in model.varDist[var].parents:\r\n-      #Query variable is a condition for this term\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n-      #\r\n-      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n-      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n-      # consider both what happens when the query variable is True, and also when it is False.\r\n-      #\r\n-      # Copy from your code below and modify to deal with this additional element.\r\n-      #\r\n-      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n-      #\r\n-      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n-      #   BUT remember to change it back to the original values when you are done!\r\n-      #\r\n-      # (Reference solution is 11 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-    elif var==queryVar:\r\n-      #This term is probability _for_ the Query variable\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one second! (Atleast, I recommend this.)\r\n-      #\r\n-      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n-      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n-      # is False.\r\n-      #\r\n-      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n-      # \r\n-      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n-      #\r\n-      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n-      #   BUT remember to change it back to the original values when you are done!\r\n-      #\r\n-      # (Reference solution is 5 additional lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-    else:\r\n-      #Simple term, no need to worry about query variable\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one first! (It's the simplest of the three.)\r\n-      #\r\n-      # You need to get the conditional probability for this variable and correctly\r\n-      # combine it with the results of the recursive call above.\r\n-      #\r\n-      # Don't forget that this variable's value could be True or False!\r\n-      #\r\n-      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n-      #\r\n-      # (Reference solution is 5 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-    if len(remainingCalc)>1:\r\n-      #If there are still terms left, then recurse\r\n-      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n-      \r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Update prQ_T, prQ_F with the results from the recursive call.\r\n-      #\r\n-      # How do you combine _factors_ together?\r\n-      #\r\n-      # (Reference solution is 2 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n-  \r\n-##############################################################################\r\n-## Support code\r\n-def read_cpt(model,varName,condVals):\r\n-  \"\"\"\r\n-  Read conditional probability for a specified variable with provided condition (parent) values\r\n-  Note, the value returned is conditional probability for variable being True\r\n-  \r\n-  Warning: If you get an index exception and referenced key has None in it, this means\r\n-    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n-  \r\n-  model: model object, see read_model_file() for specification\r\n-  varName: string, variable name to read probability for\r\n-  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n-              (Missing conditions will cause errors, extraneous values will be ignored)\r\n-  \"\"\"\r\n-  if varName not in model.varDist:\r\n-    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n-  varDist=model.varDist[varName]\r\n-  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n-  if key not in varDist.cpt:\r\n-    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n-  return varDist.cpt[key]\r\n-\r\n-def truefalse_combination_iterator(entries):\r\n-  \"\"\"\r\n-  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n-  \"\"\"\r\n-  entries=list(entries)\r\n-  entries.reverse()\r\n-  if len(entries)>30:\r\n-    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n-  for c in range(1<<len(entries)):\r\n-    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n-\r\n-def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n-  \"\"\"\r\n-  Create represention of terms in an inference calculation such as on slides 20-21\r\n-  \r\n-  Returns a list of (boolean,string) tuples where:\r\n-    (True,variable) represents a summation term where a variable needs to be marginalized\r\n-    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n-  \"\"\"\r\n-  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Naive solution\r\n-  #\r\n-  # model.varsDep already has variables in order of dependency...\r\n-  # So take that and insert summation terms any time we encounter a new hidden variable\r\n-  #\r\n-  # Downside is little optimization, likely to have many unnecessary terms\r\n-  if False:\r\n-    hiddenLeft=set(hiddenVars)\r\n-    seq=[]\r\n-    for v in model.varsDep:\r\n-      #Check if factor variable is a (unhandled) hidden variable\r\n-      if v in hiddenLeft:\r\n-        seq.append( (True,v) ) #If so, trigger a marginalization\r\n-        hiddenLeft.remove(v)   #And mark it as handled\r\n-      for p in model.varDist[v].parents:\r\n-        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n-        if p in hiddenLeft:\r\n-          seq.append( (True,p) )\r\n-          hiddenLeft.remove(p)\r\n-      seq.append( (False,v) ) #Then process the factor itself\r\n-    assert(len(hiddenLeft)==0)\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Arbitrary ordering\r\n-  #\r\n-  # What if we wanted to handle hidden variables in an arbitrary order?\r\n-  #\r\n-  # Possible, but we'll have to be careful where we put factors, after\r\n-  # all their dependencies are satisfied.\r\n-  def seq_from_hid_order(hOrd):\r\n-    #The trick to make this work is to first assign every\r\n-    #hidden variable a priority based on the order\r\n-    prio={h:i for i,h in enumerate(hOrd)}\r\n-    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n-    #Then rate each factor on the highest priority amongst its dependencies\r\n-    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n-    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n-    vOrd.sort()\r\n-    #All that's left is to turn it into the expected sequence format\r\n-    return list( (not nm,v) for _,nm,v in vOrd )\r\n-  \r\n-  #--------------------------------------------------------\r\n-  # Brute force best\r\n-  #\r\n-  # Now, where to get an ordering to use the above?\r\n-  #\r\n-  # We could brute force try every possible ordering...\r\n-  if True:\r\n-    bestSeq=None\r\n-    bestSeqCost=sys.maxsize\r\n-    for hOrd in permutations(hiddenVars):\r\n-      tSeq=seq_from_hid_order(hOrd)\r\n-      #Note, really should do below norm optimization here too\r\n-      \r\n-      #Now the tricky bit is to rate each ordering\r\n-      #We'll do it by doubling the cost of each factor every time\r\n-      #We cross a summation\r\n-      tot=0\r\n-      ct=1\r\n-      for m,v in tSeq:\r\n-        if m:\r\n-          ct*=2\r\n-        else:\r\n-          tot+=ct\r\n-      \r\n-      if tot<bestSeqCost:\r\n-        bestSeq=tSeq\r\n-        bestSeqCost=tot\r\n-    seq=bestSeq\r\n-  # But this will be very expensive for large models\r\n-  #--------------------------------------------------------\r\n-  # Greedy\r\n-  #\r\n-  # Alternately, we could apply a greedy approach.\r\n-  #\r\n-  # Some how rate each hidden variable on how expensive we think\r\n-  # it is, then put the most expensive ones earliest\r\n-  # ***TODO***\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Simple normalization optimization\r\n-  #\r\n-  # One thing we learned is that for a multiplicative term,\r\n-  # if it doesn't mention the query variable, then it's a\r\n-  # constant and can be handled via normalization (folded into alpha)\r\n-  #\r\n-  # This is non-trivial to detect for summation terms, but we\r\n-  # can easily do it for factors outside of any summation...\r\n-  if True:\r\n-    i=0\r\n-    while i<len(seq):\r\n-      m,v=seq[i]\r\n-      if m:\r\n-        break #Found first summation, quit\r\n-      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n-        #No mention of query variable, remove\r\n-        del seq[i]\r\n-      else:\r\n-        i+=1\r\n-  \r\n-  return seq\r\n-\r\n-def calc_query_approx(model,queryVar,queryVal,evidence):\r\n-  raise NotImplementedError()\r\n-\r\n-def generate_joint_prob_table(model):\r\n-  \"\"\"\r\n-  Output a joint probability table for the provided model\r\n-  \"\"\"\r\n-  from tabulate import tabulate\r\n-  table=[]\r\n-  row=list(model.vars)\r\n-  row.append('Joint Pr')\r\n-  table.append(row)\r\n-  for varVals in truefalse_combination_iterator(model.vars):\r\n-    pr=calc_global_joint_prob(model,varVals)\r\n-    row=[varVals[x] for x in model.vars]\r\n-    row.append(pr)\r\n-    table.append(row)\r\n-  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n-  return\r\n-\r\n-def read_model_file(filename):\r\n-  \"\"\"\r\n-  Returns model object with the following elements:\r\n-    vars : list of strings\r\n-      The list of variables the model describes\r\n-      In alphabetical order\r\n-    varsDep : list of strings\r\n-      Same contents as 'vars' but in dependency order (parents come before children)\r\n-    varDist : dict of objects\r\n-      Distribution information for each variable\r\n-      Dictionary key is variable name\r\n-      Object has the following elements:\r\n-        parents : set of strings\r\n-        children : set of strings\r\n-        cpt : dict of numbers\r\n-          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n-          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n-            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n-  Model file format is as follows:\r\n-    Basic file format is Comma-Separated Value (.csv)\r\n-    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n-    Tables are separated by atleast one empty line\r\n-    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n-    Each table:\r\n-      Starts with a header row containing variable names\r\n-        The last name is the variable whose cond probability is being described\r\n-        Any preceding names are considered to be parent variables\r\n-      Following rows contain True/False values for each parent and probability for main variable being true\r\n-      Any missing parent value combinations will be assumed to be probability 0.5\r\n-    Only Bernoulli/Boolean variables can be represented in this file format\r\n-  \"\"\"\r\n-  class ModelObj:\r\n-    def __init__(self):\r\n-      self.vars=[]\r\n-      self.varsDep=None\r\n-      self.varDist={}\r\n-\r\n-  class VarObj:\r\n-    def __init__(self, parents, children, cpt):\r\n-      self.parents = parents\r\n-      self.children = children\r\n-      self.cpt = cpt\r\n-\r\n-  model=ModelObj()\r\n-  #--------------------------------------------------------\r\n-  #Read data from file\r\n-  with open(filename, newline='') as csvfile:\r\n-    csvreader = csv.reader(csvfile)\r\n-    \r\n-    rowNum=0\r\n-    var=None\r\n-    varIdx=None\r\n-    parents=None\r\n-    cpt=None\r\n-    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n-      rowNum+=1\r\n-      srow=''.join(row).strip()\r\n-      if srow.startswith('#'):\r\n-        continue #Comment line, skip\r\n-      if len(srow)==0:\r\n-        #Empty line\r\n-        if var is not None:\r\n-          #End current table\r\n-          model.vars.append(var)\r\n-          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n-          #Wait for new table\r\n-          var=None\r\n-          varIdx=None\r\n-          parents=None\r\n-          cpt=None\r\n-      elif var is None:\r\n-        #Start new table\r\n-        if len(row)>1:\r\n-          parents=row[0:-1]\r\n-        else:\r\n-          parents=[]\r\n-        varIdx=len(row)-1\r\n-        var=row[varIdx]\r\n-        cpt={}\r\n-      else:\r\n-        #Add new entry to table\r\n-        if len(row)<varIdx+1:\r\n-          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n-        if len(parents)>0:\r\n-          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n-        else:\r\n-          key=frozenset()\r\n-        cpt[key]=float(row[-1])\r\n-  model.vars.sort()\r\n-  #--------------------------------------------------------\r\n-  # Check distributions for missing entries\r\n-  vCheck=frozenset(model.vars)\r\n-  for var in model.vars: #Make sure every mentioned variable has an entry\r\n-    for p in model.varDist[var].parents:\r\n-      if p not in vCheck:\r\n-        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n-  for var in model.vars: #Check every cpt for missing rows\r\n-    varDist=model.varDist[var]\r\n-    missingCnt=0\r\n-    for varVals in truefalse_combination_iterator(varDist.parents):\r\n-      key=frozenset(((x,v) for x,v in varVals.items()))\r\n-      if key not in varDist.cpt:\r\n-        missingCnt+=1\r\n-        varDist.cpt[key]=0.5\r\n-    if missingCnt>0:\r\n-      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n-  #--------------------------------------------------------\r\n-  # Create children entries\r\n-  for var in model.vars:\r\n-    model.varDist[var].children=set()\r\n-  for var in model.vars:\r\n-    for p in model.varDist[var].parents:\r\n-      model.varDist[p].children.add(var)\r\n-  for var in model.vars:\r\n-    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n-  #--------------------------------------------------------\r\n-  # Create dependency ordering\r\n-  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n-  idx=0\r\n-  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n-  while idx<len(varsDep):\r\n-    var=varsDep[idx]\r\n-    for c in model.varDist[var].children:\r\n-      parentsLeft[c]-=1\r\n-      if parentsLeft[c]==0:\r\n-        #All parents have been visited, so dependencies of this child are met\r\n-        varsDep.append(c)\r\n-      elif parentsLeft[c]<0:\r\n-        #Repeat visit to a parent can only happen if a cycle exists\r\n-        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n-    idx+=1\r\n-  model.varsDep=varsDep\r\n-  #--------------------------------------------------------\r\n-  return model\r\n-\r\n-def print_model(model):\r\n-  \"\"\"\r\n-  Print a model object back out in pretty form\r\n-  \"\"\"\r\n-  from tabulate import tabulate\r\n-  for v in model.vars:\r\n-    varDist=model.varDist[v]\r\n-    print('--------------------------------------------------')\r\n-    print('Variable:',v)\r\n-    print('--------------------------------------------------')\r\n-    print('Children:',', '.join(varDist.children))\r\n-    \r\n-    table=[]\r\n-    row=list(varDist.parents)\r\n-    row.append('P({0}=T|...)'.format(v))\r\n-    table.append(row)\r\n-    for varVals in truefalse_combination_iterator(varDist.parents):\r\n-      pr=read_cpt(model,v,varVals)\r\n-      row=[varVals[x] for x in varDist.parents]\r\n-      row.append(pr)\r\n-      table.append(row)\r\n-    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n-    print(\"\")\r\n-    \r\n-##############################################################################\r\n-## Main functions\r\n-def main(args):\r\n-  global DEBUG_OUTPUT\r\n-  if args.debug:\r\n-    DEBUG_OUTPUT=1\r\n-  #Argument checking plus additional parsing\r\n-  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n-    error('Arguments --query and --evidence not allowed in table mode')\r\n-  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n-    error('Arguments --query and --evidence not allowed in print mode')\r\n-  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n-    error('Argument --query required in inference modes')\r\n-  elif args.query is not None:\r\n-    if '=' not in args.query:\r\n-      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n-    s=args.query.split('=')\r\n-    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n-  if args.evidence is None:\r\n-    args.evidence=[]\r\n-  else:\r\n-    ev=[]\r\n-    for e in args.evidence:\r\n-      if '=' not in e:\r\n-        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n-      s=e.split('=')\r\n-      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n-    args.evidence={ var:val for var,val in ev }\r\n-\r\n-  print('Reading model from',args.model)\r\n-  model=read_model_file(args.model)\r\n-\r\n-  if args.mode=='table':\r\n-    generate_joint_prob_table(model)\r\n-  elif args.mode=='print':\r\n-    print_model(model)\r\n-  else:\r\n-    #One of the inference modes\r\n-    #Check inputs against model\r\n-    if args.query[0] not in model.vars:\r\n-      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n-    for var,val in args.evidence.items():\r\n-      if var not in model.vars:\r\n-        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n-    #Output problem setup\r\n-    print(\"Inference mode:\",args.mode)\r\n-    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n-    if len(args.evidence)==0:\r\n-      print(\"No evidence\")\r\n-    else:\r\n-      print(\"Evidence:\")\r\n-      for var,val in args.evidence.items():\r\n-        print(\"  '{0}' is {1}\".format(var,val))\r\n-\r\n-    #Run inference\r\n-    pr=None\r\n-    if args.mode=='brute':\r\n-      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n-    elif args.mode=='tree':\r\n-      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n-    else: #args.mode=='approx'\r\n-      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n-    print('Probability is',pr)\r\n-\r\n-  return\r\n-\r\n-def error(msg):\r\n-  print(msg)\r\n-  sys.exit(1)\r\n-  return\r\n-\r\n-if __name__ == '__main__':\r\n-  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n-  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n-  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n-  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n-  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n-  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n-  args = parser.parse_args()\r\n-  error=lambda msg : parser.error(msg)\r\n-  main(args)\n-import argparse\r\n-import csv\r\n-from itertools import chain, permutations\r\n-import math\r\n-#import matplotlib.pyplot as plt\r\n-#import numpy as np\r\n-from random import random\r\n-import sys\r\n-\r\n-DEBUG_OUTPUT=0\r\n-\r\n-##############################################################################\r\n-## Student code\r\n-def calc_global_joint_prob(model, variableValues):\r\n-  \"\"\"\r\n-  Calculate the global joint probability of a model for a specific set of values\r\n-  model: model object, see read_model_file() for specification\r\n-  variableValues: dictionary of boolean values, keys are variable names\r\n-  \"\"\"\r\n-  \r\n-  # YOUR CODE HERE\r\n-  #\r\n-  # You may assume variableValues is complete, i.e containes all variables in the model\r\n-  #   Thus, no marginalization is necessary\r\n-  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n-  #\r\n-  # You can find a complete descrition of the model object in the documentation of\r\n-  #   the read_model_file() function, BUT\r\n-  # All you will need is the list of variables: model.vars\r\n-  #\r\n-  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n-  #\r\n-  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n-  #\r\n-  # (Reference solution is 7 lines of code.)\r\n-  joint_prob = 1.0\r\n-\r\n-  for var in model.vars:\r\n-      parents = model.varDist[var].parents\r\n-      cond_vals = {parent: variableValues[parent] for parent in parents}\r\n-      cpt_entry = read_cpt(model, var, cond_vals)\r\n-\r\n-      if variableValues[var]:\r\n-          joint_prob *= cpt_entry\r\n-      else:\r\n-          joint_prob *= 1 - cpt_entry\r\n-\r\n-    return joint_prob\r\n-\r\n-def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n-  \"\"\"\r\n-  Calculate posterior probability for a given variable\r\n-\r\n-  model: model object, see read_model_file() for specification\r\n-  queryVar: string, query variable name\r\n-  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n-  evidence: dictionary of boolean values, where keys are evidence variable names\r\n-            (Any variable not listed as query or evidence is assumed to be hidden)\r\n-  \"\"\"\r\n-\r\n-  # This first attempt at probabilistic inference will use the brute-force (table)\r\n-  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n-  #\r\n-  # This requires the calculation of two joint probabilities based on the definition\r\n-  # of conditional probability:\r\n-  #                          Pr( Query & Evidence )\r\n-  #   Pr(Query | Evidence) = ----------------------\r\n-  #                              Pr( Evidence )\r\n-  #\r\n-  # Both of these joint probabilities can be calculated by going over every entry in\r\n-  # the global joint probability table and summing up the probabilities of those\r\n-  # entries that match what we're looking for\r\n-  \r\n   def dict_issubset(d,sub):\r\n     \"\"\"\r\n     Returns True if every key,value pair in sub has a matching key and value in d\r\n     Note: sub should not contain any entries with value None\r\n@@ -1364,689 +699,5 @@\n   parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n   parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n   args = parser.parse_args()\r\n   error=lambda msg : parser.error(msg)\r\n-  main(args)\n-import argparse\r\n-import csv\r\n-from itertools import chain, permutations\r\n-import math\r\n-#import matplotlib.pyplot as plt\r\n-#import numpy as np\r\n-from random import random\r\n-import sys\r\n-\r\n-DEBUG_OUTPUT=0\r\n-\r\n-##############################################################################\r\n-## Student code\r\n-def calc_global_joint_prob(model, variableValues):\r\n-  \"\"\"\r\n-  Calculate the global joint probability of a model for a specific set of values\r\n-  model: model object, see read_model_file() for specification\r\n-  variableValues: dictionary of boolean values, keys are variable names\r\n-  \"\"\"\r\n-  \r\n-  # YOUR CODE HERE\r\n-  #\r\n-  # You may assume variableValues is complete, i.e containes all variables in the model\r\n-  #   Thus, no marginalization is necessary\r\n-  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n-  #\r\n-  # You can find a complete descrition of the model object in the documentation of\r\n-  #   the read_model_file() function, BUT\r\n-  # All you will need is the list of variables: model.vars\r\n-  #\r\n-  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n-  #\r\n-  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n-  #\r\n-  # (Reference solution is 7 lines of code.)\r\n-  joint_prob = 1.0\r\n-\r\n-    for var in model.vars:\r\n-        parents = model.varDist[var].parents\r\n-        cond_vals = {parent: variableValues[parent] for parent in parents}\r\n-        cpt_entry = read_cpt(model, var, cond_vals)\r\n-\r\n-        if variableValues[var]:\r\n-            joint_prob *= cpt_entry\r\n-        else:\r\n-            joint_prob *= 1 - cpt_entry\r\n-\r\n-    return joint_prob\r\n-\r\n-def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n-  \"\"\"\r\n-  Calculate posterior probability for a given variable\r\n-\r\n-  model: model object, see read_model_file() for specification\r\n-  queryVar: string, query variable name\r\n-  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n-  evidence: dictionary of boolean values, where keys are evidence variable names\r\n-            (Any variable not listed as query or evidence is assumed to be hidden)\r\n-  \"\"\"\r\n-\r\n-  # This first attempt at probabilistic inference will use the brute-force (table)\r\n-  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n-  #\r\n-  # This requires the calculation of two joint probabilities based on the definition\r\n-  # of conditional probability:\r\n-  #                          Pr( Query & Evidence )\r\n-  #   Pr(Query | Evidence) = ----------------------\r\n-  #                              Pr( Evidence )\r\n-  #\r\n-  # Both of these joint probabilities can be calculated by going over every entry in\r\n-  # the global joint probability table and summing up the probabilities of those\r\n-  # entries that match what we're looking for\r\n-  \r\n-  def dict_issubset(d,sub):\r\n-    \"\"\"\r\n-    Returns True if every key,value pair in sub has a matching key and value in d\r\n-    Note: sub should not contain any entries with value None\r\n-    \"\"\"\r\n-    return all(d.get(key,None)==val for key,val in sub.items())\r\n-     \r\n-  pr_QE=0\r\n-  pr_E=0\r\n-  for jptEntry in truefalse_combination_iterator(model.vars):\r\n-    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n-\r\n-    # YOUR CODE HERE\r\n-    #\r\n-    # jptEntry will be a dictionary with a key for every variable in the model,\r\n-    #   and the loop will go over every possible combination of True/False for each variable\r\n-    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n-    #\r\n-    # Your task is to collect all the probabilities that match the evidence, and query\r\n-    #\r\n-    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n-    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n-    #\r\n-    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n-    #\r\n-    # (Reference solution is 4 lines of code.)\r\n-    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-  return pr_QE/pr_E\r\n-\r\n-def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n-  \"\"\"\r\n-  Calculate posterior probability for a given variable\r\n-\r\n-  model: model object, see read_model_file() for specification\r\n-  queryVar: string, query variable name\r\n-  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n-  evidence: dictionary of boolean values, where keys are evidence variable names\r\n-            (Any variable not listed as query or evidence is assumed to be hidden)\r\n-  \"\"\"\r\n-  \r\n-  # First step, we need to figure out what order we will calculate terms in and where\r\n-  # marginalization needs to happen.\r\n-  #\r\n-  # That said, though this is a part of the inference process that you need to know, it's a\r\n-  # bit tricky to get working in general, especially the optimization bits.\r\n-  #\r\n-  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n-  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n-  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n-  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n-  # For example, the formula on slide 20 would be represented as:\r\n-  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n-  # The formula on slide 21 would be:\r\n-  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n-  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n-  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n-  \r\n-  # Debug: Output a nicer version of the calculation order (inference formula)\r\n-  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n-  \r\n-  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n-  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n-  \r\n-  # Next step, implement the calculation\r\n-  #\r\n-  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n-  # and move on to implement the recurse_calc_query_exact_tree() function\r\n-  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n-  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n-  # and associated function and add your own calculation code here\r\n-  \r\n-  # YOUR CODE HERE\r\n-  #\r\n-  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n-  #\r\n-  # Normalize this result to get true probability.\r\n-  #\r\n-  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n-  #\r\n-  # Refer to the example on slide 30.\r\n-  #\r\n-  # (Reference solution is 3 lines of code.)\r\n-  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n-  \"\"\"\r\n-  Recursiving process the summation tree \r\n-  \r\n-  model,queryVar,evidence: See calc_query_exact_tree()\r\n-  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n-    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n-  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n-  \"\"\"\r\n-  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n-\r\n-  # Your overall task in the function is to assign values to:\r\n-  #   prQ_T\r\n-  #   prQ_F\r\n-  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n-  # covering both cases where query=True and query=False.\r\n-\r\n-  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n-  if marginalize:\r\n-    #Summation term, need to branch over all possible values and continue calculation\r\n-    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n-\r\n-    # YOUR CODE HERE\r\n-    #\r\n-    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n-    # calculation\r\n-    #\r\n-    # You will need to recurse for each element of the summation (i.e. each branch)\r\n-    # Then properly combine the results together\r\n-    #\r\n-    # Slides 26-28 show examples of resolving summations.\r\n-    #\r\n-    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n-    #   BUT remember to change it back to the original values when you are done!\r\n-    #   (The original value for unknown variables is None.)\r\n-    #\r\n-    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n-    #   example of how to make the recursive call(s)\r\n-    #\r\n-    # (Reference solution is 7 lines of code.)\r\n-    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-  else:\r\n-    #Probability term, calculate conditional probability for this variable and continue calculation\r\n-    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n-    if queryVar in model.varDist[var].parents:\r\n-      #Query variable is a condition for this term\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n-      #\r\n-      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n-      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n-      # consider both what happens when the query variable is True, and also when it is False.\r\n-      #\r\n-      # Copy from your code below and modify to deal with this additional element.\r\n-      #\r\n-      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n-      #\r\n-      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n-      #   BUT remember to change it back to the original values when you are done!\r\n-      #\r\n-      # (Reference solution is 11 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-    elif var==queryVar:\r\n-      #This term is probability _for_ the Query variable\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one second! (Atleast, I recommend this.)\r\n-      #\r\n-      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n-      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n-      # is False.\r\n-      #\r\n-      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n-      # \r\n-      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n-      #\r\n-      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n-      #   BUT remember to change it back to the original values when you are done!\r\n-      #\r\n-      # (Reference solution is 5 additional lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-    else:\r\n-      #Simple term, no need to worry about query variable\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one first! (It's the simplest of the three.)\r\n-      #\r\n-      # You need to get the conditional probability for this variable and correctly\r\n-      # combine it with the results of the recursive call above.\r\n-      #\r\n-      # Don't forget that this variable's value could be True or False!\r\n-      #\r\n-      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n-      #\r\n-      # (Reference solution is 5 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-    if len(remainingCalc)>1:\r\n-      #If there are still terms left, then recurse\r\n-      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n-      \r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Update prQ_T, prQ_F with the results from the recursive call.\r\n-      #\r\n-      # How do you combine _factors_ together?\r\n-      #\r\n-      # (Reference solution is 2 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n-  \r\n-##############################################################################\r\n-## Support code\r\n-def read_cpt(model,varName,condVals):\r\n-  \"\"\"\r\n-  Read conditional probability for a specified variable with provided condition (parent) values\r\n-  Note, the value returned is conditional probability for variable being True\r\n-  \r\n-  Warning: If you get an index exception and referenced key has None in it, this means\r\n-    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n-  \r\n-  model: model object, see read_model_file() for specification\r\n-  varName: string, variable name to read probability for\r\n-  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n-              (Missing conditions will cause errors, extraneous values will be ignored)\r\n-  \"\"\"\r\n-  if varName not in model.varDist:\r\n-    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n-  varDist=model.varDist[varName]\r\n-  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n-  if key not in varDist.cpt:\r\n-    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n-  return varDist.cpt[key]\r\n-\r\n-def truefalse_combination_iterator(entries):\r\n-  \"\"\"\r\n-  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n-  \"\"\"\r\n-  entries=list(entries)\r\n-  entries.reverse()\r\n-  if len(entries)>30:\r\n-    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n-  for c in range(1<<len(entries)):\r\n-    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n-\r\n-def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n-  \"\"\"\r\n-  Create represention of terms in an inference calculation such as on slides 20-21\r\n-  \r\n-  Returns a list of (boolean,string) tuples where:\r\n-    (True,variable) represents a summation term where a variable needs to be marginalized\r\n-    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n-  \"\"\"\r\n-  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Naive solution\r\n-  #\r\n-  # model.varsDep already has variables in order of dependency...\r\n-  # So take that and insert summation terms any time we encounter a new hidden variable\r\n-  #\r\n-  # Downside is little optimization, likely to have many unnecessary terms\r\n-  if False:\r\n-    hiddenLeft=set(hiddenVars)\r\n-    seq=[]\r\n-    for v in model.varsDep:\r\n-      #Check if factor variable is a (unhandled) hidden variable\r\n-      if v in hiddenLeft:\r\n-        seq.append( (True,v) ) #If so, trigger a marginalization\r\n-        hiddenLeft.remove(v)   #And mark it as handled\r\n-      for p in model.varDist[v].parents:\r\n-        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n-        if p in hiddenLeft:\r\n-          seq.append( (True,p) )\r\n-          hiddenLeft.remove(p)\r\n-      seq.append( (False,v) ) #Then process the factor itself\r\n-    assert(len(hiddenLeft)==0)\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Arbitrary ordering\r\n-  #\r\n-  # What if we wanted to handle hidden variables in an arbitrary order?\r\n-  #\r\n-  # Possible, but we'll have to be careful where we put factors, after\r\n-  # all their dependencies are satisfied.\r\n-  def seq_from_hid_order(hOrd):\r\n-    #The trick to make this work is to first assign every\r\n-    #hidden variable a priority based on the order\r\n-    prio={h:i for i,h in enumerate(hOrd)}\r\n-    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n-    #Then rate each factor on the highest priority amongst its dependencies\r\n-    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n-    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n-    vOrd.sort()\r\n-    #All that's left is to turn it into the expected sequence format\r\n-    return list( (not nm,v) for _,nm,v in vOrd )\r\n-  \r\n-  #--------------------------------------------------------\r\n-  # Brute force best\r\n-  #\r\n-  # Now, where to get an ordering to use the above?\r\n-  #\r\n-  # We could brute force try every possible ordering...\r\n-  if True:\r\n-    bestSeq=None\r\n-    bestSeqCost=sys.maxsize\r\n-    for hOrd in permutations(hiddenVars):\r\n-      tSeq=seq_from_hid_order(hOrd)\r\n-      #Note, really should do below norm optimization here too\r\n-      \r\n-      #Now the tricky bit is to rate each ordering\r\n-      #We'll do it by doubling the cost of each factor every time\r\n-      #We cross a summation\r\n-      tot=0\r\n-      ct=1\r\n-      for m,v in tSeq:\r\n-        if m:\r\n-          ct*=2\r\n-        else:\r\n-          tot+=ct\r\n-      \r\n-      if tot<bestSeqCost:\r\n-        bestSeq=tSeq\r\n-        bestSeqCost=tot\r\n-    seq=bestSeq\r\n-  # But this will be very expensive for large models\r\n-  #--------------------------------------------------------\r\n-  # Greedy\r\n-  #\r\n-  # Alternately, we could apply a greedy approach.\r\n-  #\r\n-  # Some how rate each hidden variable on how expensive we think\r\n-  # it is, then put the most expensive ones earliest\r\n-  # ***TODO***\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Simple normalization optimization\r\n-  #\r\n-  # One thing we learned is that for a multiplicative term,\r\n-  # if it doesn't mention the query variable, then it's a\r\n-  # constant and can be handled via normalization (folded into alpha)\r\n-  #\r\n-  # This is non-trivial to detect for summation terms, but we\r\n-  # can easily do it for factors outside of any summation...\r\n-  if True:\r\n-    i=0\r\n-    while i<len(seq):\r\n-      m,v=seq[i]\r\n-      if m:\r\n-        break #Found first summation, quit\r\n-      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n-        #No mention of query variable, remove\r\n-        del seq[i]\r\n-      else:\r\n-        i+=1\r\n-  \r\n-  return seq\r\n-\r\n-def calc_query_approx(model,queryVar,queryVal,evidence):\r\n-  raise NotImplementedError()\r\n-\r\n-def generate_joint_prob_table(model):\r\n-  \"\"\"\r\n-  Output a joint probability table for the provided model\r\n-  \"\"\"\r\n-  from tabulate import tabulate\r\n-  table=[]\r\n-  row=list(model.vars)\r\n-  row.append('Joint Pr')\r\n-  table.append(row)\r\n-  for varVals in truefalse_combination_iterator(model.vars):\r\n-    pr=calc_global_joint_prob(model,varVals)\r\n-    row=[varVals[x] for x in model.vars]\r\n-    row.append(pr)\r\n-    table.append(row)\r\n-  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n-  return\r\n-\r\n-def read_model_file(filename):\r\n-  \"\"\"\r\n-  Returns model object with the following elements:\r\n-    vars : list of strings\r\n-      The list of variables the model describes\r\n-      In alphabetical order\r\n-    varsDep : list of strings\r\n-      Same contents as 'vars' but in dependency order (parents come before children)\r\n-    varDist : dict of objects\r\n-      Distribution information for each variable\r\n-      Dictionary key is variable name\r\n-      Object has the following elements:\r\n-        parents : set of strings\r\n-        children : set of strings\r\n-        cpt : dict of numbers\r\n-          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n-          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n-            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n-  Model file format is as follows:\r\n-    Basic file format is Comma-Separated Value (.csv)\r\n-    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n-    Tables are separated by atleast one empty line\r\n-    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n-    Each table:\r\n-      Starts with a header row containing variable names\r\n-        The last name is the variable whose cond probability is being described\r\n-        Any preceding names are considered to be parent variables\r\n-      Following rows contain True/False values for each parent and probability for main variable being true\r\n-      Any missing parent value combinations will be assumed to be probability 0.5\r\n-    Only Bernoulli/Boolean variables can be represented in this file format\r\n-  \"\"\"\r\n-  class ModelObj:\r\n-    def __init__(self):\r\n-      self.vars=[]\r\n-      self.varsDep=None\r\n-      self.varDist={}\r\n-\r\n-  class VarObj:\r\n-    def __init__(self, parents, children, cpt):\r\n-      self.parents = parents\r\n-      self.children = children\r\n-      self.cpt = cpt\r\n-\r\n-  model=ModelObj()\r\n-  #--------------------------------------------------------\r\n-  #Read data from file\r\n-  with open(filename, newline='') as csvfile:\r\n-    csvreader = csv.reader(csvfile)\r\n-    \r\n-    rowNum=0\r\n-    var=None\r\n-    varIdx=None\r\n-    parents=None\r\n-    cpt=None\r\n-    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n-      rowNum+=1\r\n-      srow=''.join(row).strip()\r\n-      if srow.startswith('#'):\r\n-        continue #Comment line, skip\r\n-      if len(srow)==0:\r\n-        #Empty line\r\n-        if var is not None:\r\n-          #End current table\r\n-          model.vars.append(var)\r\n-          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n-          #Wait for new table\r\n-          var=None\r\n-          varIdx=None\r\n-          parents=None\r\n-          cpt=None\r\n-      elif var is None:\r\n-        #Start new table\r\n-        if len(row)>1:\r\n-          parents=row[0:-1]\r\n-        else:\r\n-          parents=[]\r\n-        varIdx=len(row)-1\r\n-        var=row[varIdx]\r\n-        cpt={}\r\n-      else:\r\n-        #Add new entry to table\r\n-        if len(row)<varIdx+1:\r\n-          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n-        if len(parents)>0:\r\n-          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n-        else:\r\n-          key=frozenset()\r\n-        cpt[key]=float(row[-1])\r\n-  model.vars.sort()\r\n-  #--------------------------------------------------------\r\n-  # Check distributions for missing entries\r\n-  vCheck=frozenset(model.vars)\r\n-  for var in model.vars: #Make sure every mentioned variable has an entry\r\n-    for p in model.varDist[var].parents:\r\n-      if p not in vCheck:\r\n-        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n-  for var in model.vars: #Check every cpt for missing rows\r\n-    varDist=model.varDist[var]\r\n-    missingCnt=0\r\n-    for varVals in truefalse_combination_iterator(varDist.parents):\r\n-      key=frozenset(((x,v) for x,v in varVals.items()))\r\n-      if key not in varDist.cpt:\r\n-        missingCnt+=1\r\n-        varDist.cpt[key]=0.5\r\n-    if missingCnt>0:\r\n-      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n-  #--------------------------------------------------------\r\n-  # Create children entries\r\n-  for var in model.vars:\r\n-    model.varDist[var].children=set()\r\n-  for var in model.vars:\r\n-    for p in model.varDist[var].parents:\r\n-      model.varDist[p].children.add(var)\r\n-  for var in model.vars:\r\n-    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n-  #--------------------------------------------------------\r\n-  # Create dependency ordering\r\n-  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n-  idx=0\r\n-  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n-  while idx<len(varsDep):\r\n-    var=varsDep[idx]\r\n-    for c in model.varDist[var].children:\r\n-      parentsLeft[c]-=1\r\n-      if parentsLeft[c]==0:\r\n-        #All parents have been visited, so dependencies of this child are met\r\n-        varsDep.append(c)\r\n-      elif parentsLeft[c]<0:\r\n-        #Repeat visit to a parent can only happen if a cycle exists\r\n-        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n-    idx+=1\r\n-  model.varsDep=varsDep\r\n-  #--------------------------------------------------------\r\n-  return model\r\n-\r\n-def print_model(model):\r\n-  \"\"\"\r\n-  Print a model object back out in pretty form\r\n-  \"\"\"\r\n-  from tabulate import tabulate\r\n-  for v in model.vars:\r\n-    varDist=model.varDist[v]\r\n-    print('--------------------------------------------------')\r\n-    print('Variable:',v)\r\n-    print('--------------------------------------------------')\r\n-    print('Children:',', '.join(varDist.children))\r\n-    \r\n-    table=[]\r\n-    row=list(varDist.parents)\r\n-    row.append('P({0}=T|...)'.format(v))\r\n-    table.append(row)\r\n-    for varVals in truefalse_combination_iterator(varDist.parents):\r\n-      pr=read_cpt(model,v,varVals)\r\n-      row=[varVals[x] for x in varDist.parents]\r\n-      row.append(pr)\r\n-      table.append(row)\r\n-    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n-    print(\"\")\r\n-    \r\n-##############################################################################\r\n-## Main functions\r\n-def main(args):\r\n-  global DEBUG_OUTPUT\r\n-  if args.debug:\r\n-    DEBUG_OUTPUT=1\r\n-  #Argument checking plus additional parsing\r\n-  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n-    error('Arguments --query and --evidence not allowed in table mode')\r\n-  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n-    error('Arguments --query and --evidence not allowed in print mode')\r\n-  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n-    error('Argument --query required in inference modes')\r\n-  elif args.query is not None:\r\n-    if '=' not in args.query:\r\n-      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n-    s=args.query.split('=')\r\n-    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n-  if args.evidence is None:\r\n-    args.evidence=[]\r\n-  else:\r\n-    ev=[]\r\n-    for e in args.evidence:\r\n-      if '=' not in e:\r\n-        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n-      s=e.split('=')\r\n-      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n-    args.evidence={ var:val for var,val in ev }\r\n-\r\n-  print('Reading model from',args.model)\r\n-  model=read_model_file(args.model)\r\n-\r\n-  if args.mode=='table':\r\n-    generate_joint_prob_table(model)\r\n-  elif args.mode=='print':\r\n-    print_model(model)\r\n-  else:\r\n-    #One of the inference modes\r\n-    #Check inputs against model\r\n-    if args.query[0] not in model.vars:\r\n-      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n-    for var,val in args.evidence.items():\r\n-      if var not in model.vars:\r\n-        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n-    #Output problem setup\r\n-    print(\"Inference mode:\",args.mode)\r\n-    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n-    if len(args.evidence)==0:\r\n-      print(\"No evidence\")\r\n-    else:\r\n-      print(\"Evidence:\")\r\n-      for var,val in args.evidence.items():\r\n-        print(\"  '{0}' is {1}\".format(var,val))\r\n-\r\n-    #Run inference\r\n-    pr=None\r\n-    if args.mode=='brute':\r\n-      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n-    elif args.mode=='tree':\r\n-      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n-    else: #args.mode=='approx'\r\n-      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n-    print('Probability is',pr)\r\n-\r\n-  return\r\n-\r\n-def error(msg):\r\n-  print(msg)\r\n-  sys.exit(1)\r\n-  return\r\n-\r\n-if __name__ == '__main__':\r\n-  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n-  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n-  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n-  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n-  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n-  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n-  args = parser.parse_args()\r\n-  error=lambda msg : parser.error(msg)\r\n   main(args)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1699507791330,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,7 @@\n import argparse\r\n import csv\r\n-from itertools import chain, permutations\r\n+from itertools import chain, permutations, product\r\n import math\r\n #import matplotlib.pyplot as plt\r\n #import numpy as np\r\n from random import random\r\n"
                },
                {
                    "date": 1699507905548,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -69,26 +69,23 @@\n   #\r\n   # Both of these joint probabilities can be calculated by going over every entry in\r\n   # the global joint probability table and summing up the probabilities of those\r\n   # entries that match what we're looking for\r\n-  joint_prob_table = {}\r\n-  hidden_vars = [var for var in model.vars if var != queryVar and var not in evidence]\r\n+  joint_prob_table = calc_global_joint_prob(model, evidence)\r\n \r\n-  for assignment in product([True, False], repeat=len(hidden_vars)):\r\n-      variable_values = dict(zip(hidden_vars, assignment))\r\n-      variable_values.update(evidence)\r\n-      variable_values[queryVar] = queryVal\r\n-      joint_prob_table[tuple(variable_values.items())] = calc_global_joint_prob(model, variable_values)\r\n-\r\n-    # Calculate the numerator (joint probability of query variable and evidence)\r\n-  query_evidence_entry = {queryVar: queryVal, **evidence}\r\n+    # Step 2: Calculate the numerator (joint probability with both query variable and evidence)\r\n+  query_evidence_entry = evidence.copy()\r\n+  query_evidence_entry[queryVar] = queryVal\r\n   numerator = joint_prob_table[tuple(query_evidence_entry.items())]\r\n \r\n-    # Calculate the denominator (sum of joint probabilities for all possible values of the query variable)\r\n-  denominator = sum(joint_prob for key, joint_prob in joint_prob_table.items() if key[0][0] == queryVar)\r\n+    # Step 3: Calculate the denominator (sum of joint probabilities with different values of the query variable)\r\n+  denominator = sum(\r\n+      joint_prob_table[tuple(entry.items())] for entry in joint_prob_table if entry[queryVar] == queryVal\r\n+  )\r\n \r\n-    # Calculate and return the posterior probability\r\n+    # Step 4: Calculate the posterior probability\r\n   posterior_prob = numerator / denominator\r\n+\r\n   return posterior_prob\r\n \r\n   def dict_issubset(d,sub):\r\n     \"\"\"\r\n"
                },
                {
                    "date": 1699508365276,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,7 @@\n import argparse\r\n import csv\r\n-from itertools import chain, permutations, product\r\n+from itertools import chain, permutations\r\n import math\r\n #import matplotlib.pyplot as plt\r\n #import numpy as np\r\n from random import random\r\n@@ -69,24 +69,29 @@\n   #\r\n   # Both of these joint probabilities can be calculated by going over every entry in\r\n   # the global joint probability table and summing up the probabilities of those\r\n   # entries that match what we're looking for\r\n-  joint_prob_table = calc_global_joint_prob(model, evidence)\r\n+  joint_probabilities = generate_joint_prob_table(model)\r\n \r\n-    # Step 2: Calculate the numerator (joint probability with both query variable and evidence)\r\n-  query_evidence_entry = evidence.copy()\r\n-  query_evidence_entry[queryVar] = queryVal\r\n-  numerator = joint_prob_table[tuple(query_evidence_entry.items())]\r\n+    # Initialize variables for the numerator and denominator of the conditional probability\r\n+  numerator = 0\r\n+  denominator = 0\r\n \r\n-    # Step 3: Calculate the denominator (sum of joint probabilities with different values of the query variable)\r\n-  denominator = sum(\r\n-      joint_prob_table[tuple(entry.items())] for entry in joint_prob_table if entry[queryVar] == queryVal\r\n-  )\r\n+    # Iterate through all entries in the joint probabilities table\r\n+  for entry, joint_probability in joint_probabilities.items():\r\n+        # Check if the entry satisfies the evidence conditions\r\n+      if dict_issubset(entry, evidence):\r\n+            # Increment the denominator by the joint probability\r\n+          denominator += joint_probability\r\n \r\n-    # Step 4: Calculate the posterior probability\r\n-  posterior_prob = numerator / denominator\r\n+            # Check if the entry satisfies the query conditions\r\n+      if entry[queryVar] == queryVal:\r\n+                # Increment the numerator by the joint probability\r\n+          numerator += joint_probability\r\n \r\n-  return posterior_prob\r\n+    # Calculate and return the posterior probability\r\n+  posterior_probability = numerator / denominator if denominator != 0 else 0\r\n+  return posterior_probability\r\n \r\n   def dict_issubset(d,sub):\r\n     \"\"\"\r\n     Returns True if every key,value pair in sub has a matching key and value in d\r\n"
                },
                {
                    "date": 1699508594779,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -13,12 +13,12 @@\n ## Student code\r\n def calc_global_joint_prob(model, variableValues):\r\n   \"\"\"\r\n   Calculate the global joint probability of a model for a specific set of values\r\n+  \r\n   model: model object, see read_model_file() for specification\r\n   variableValues: dictionary of boolean values, keys are variable names\r\n   \"\"\"\r\n-  \r\n   # YOUR CODE HERE\r\n   #\r\n   # You may assume variableValues is complete, i.e containes all variables in the model\r\n   #   Thus, no marginalization is necessary\r\n@@ -46,8 +46,9 @@\n           joint_prob *= 1 - cpt_entry\r\n \r\n   return joint_prob\r\n \r\n+\r\n def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n   \"\"\"\r\n   Calculate posterior probability for a given variable\r\n \r\n@@ -69,30 +70,9 @@\n   #\r\n   # Both of these joint probabilities can be calculated by going over every entry in\r\n   # the global joint probability table and summing up the probabilities of those\r\n   # entries that match what we're looking for\r\n-  joint_probabilities = generate_joint_prob_table(model)\r\n-\r\n-    # Initialize variables for the numerator and denominator of the conditional probability\r\n-  numerator = 0\r\n-  denominator = 0\r\n-\r\n-    # Iterate through all entries in the joint probabilities table\r\n-  for entry, joint_probability in joint_probabilities.items():\r\n-        # Check if the entry satisfies the evidence conditions\r\n-      if dict_issubset(entry, evidence):\r\n-            # Increment the denominator by the joint probability\r\n-          denominator += joint_probability\r\n-\r\n-            # Check if the entry satisfies the query conditions\r\n-      if entry[queryVar] == queryVal:\r\n-                # Increment the numerator by the joint probability\r\n-          numerator += joint_probability\r\n-\r\n-    # Calculate and return the posterior probability\r\n-  posterior_probability = numerator / denominator if denominator != 0 else 0\r\n-  return posterior_probability\r\n-\r\n+  \r\n   def dict_issubset(d,sub):\r\n     \"\"\"\r\n     Returns True if every key,value pair in sub has a matching key and value in d\r\n     Note: sub should not contain any entries with value None\r\n"
                },
                {
                    "date": 1699508862603,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,691 @@\n+import argparse\r\n+import csv\r\n+from itertools import chain, permutations\r\n+import math\r\n+#import matplotlib.pyplot as plt\r\n+#import numpy as np\r\n+from random import random\r\n+import sys\r\n+\r\n+DEBUG_OUTPUT=0\r\n+\r\n+##############################################################################\r\n+## Student code\r\n+def calc_global_joint_prob(model, variableValues):\r\n+  \"\"\"\r\n+  Calculate the global joint probability of a model for a specific set of values\r\n+  model: model object, see read_model_file() for specification\r\n+  variableValues: dictionary of boolean values, keys are variable names\r\n+  \"\"\"\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # You may assume variableValues is complete, i.e containes all variables in the model\r\n+  #   Thus, no marginalization is necessary\r\n+  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n+  #\r\n+  # You can find a complete descrition of the model object in the documentation of\r\n+  #   the read_model_file() function, BUT\r\n+  # All you will need is the list of variables: model.vars\r\n+  #\r\n+  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n+  #\r\n+  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n+  #\r\n+  # (Reference solution is 7 lines of code.)\r\n+  joint_prob = 1.0\r\n+\r\n+  for var in model.vars:\r\n+      parents = model.varDist[var].parents\r\n+      cond_vals = {parent: variableValues[parent] for parent in parents}\r\n+      cpt_entry = read_cpt(model, var, cond_vals)\r\n+\r\n+      if variableValues[var]:\r\n+          joint_prob *= cpt_entry\r\n+      else:\r\n+          joint_prob *= 1 - cpt_entry\r\n+\r\n+  return joint_prob\r\n+\r\n+def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+\r\n+  # This first attempt at probabilistic inference will use the brute-force (table)\r\n+  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n+  #\r\n+  # This requires the calculation of two joint probabilities based on the definition\r\n+  # of conditional probability:\r\n+  #                          Pr( Query & Evidence )\r\n+  #   Pr(Query | Evidence) = ----------------------\r\n+  #                              Pr( Evidence )\r\n+  #\r\n+  # Both of these joint probabilities can be calculated by going over every entry in\r\n+  # the global joint probability table and summing up the probabilities of those\r\n+  # entries that match what we're looking for\r\n+  \r\n+  def dict_issubset(d,sub):\r\n+    \"\"\"\r\n+    Returns True if every key,value pair in sub has a matching key and value in d\r\n+    Note: sub should not contain any entries with value None\r\n+    \"\"\"\r\n+    return all(d.get(key,None)==val for key,val in sub.items())\r\n+     \r\n+  pr_QE=0\r\n+  pr_E=0\r\n+  for jptEntry in truefalse_combination_iterator(model.vars):\r\n+    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # jptEntry will be a dictionary with a key for every variable in the model,\r\n+    #   and the loop will go over every possible combination of True/False for each variable\r\n+    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n+    #\r\n+    # Your task is to collect all the probabilities that match the evidence, and query\r\n+    #\r\n+    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n+    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n+    #\r\n+    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n+    #\r\n+    # (Reference solution is 4 lines of code.)\r\n+    if dict_issubset(jptEntry, evidence):\r\n+            # Increment the joint probability with both query variable and evidence\r\n+            pr_QE += pr_entry\r\n+\r\n+            # Check if the entry satisfies only the evidence (for denominator)\r\n+            if jptEntry[queryVar] == queryVal:\r\n+                pr_E += pr_entry\r\n+\r\n+\r\n+  return pr_QE/pr_E\r\n+\r\n+def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+  \r\n+  # First step, we need to figure out what order we will calculate terms in and where\r\n+  # marginalization needs to happen.\r\n+  #\r\n+  # That said, though this is a part of the inference process that you need to know, it's a\r\n+  # bit tricky to get working in general, especially the optimization bits.\r\n+  #\r\n+  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n+  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n+  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n+  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n+  # For example, the formula on slide 20 would be represented as:\r\n+  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n+  # The formula on slide 21 would be:\r\n+  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n+  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n+  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n+  \r\n+  # Debug: Output a nicer version of the calculation order (inference formula)\r\n+  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n+  \r\n+  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n+  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n+  \r\n+  # Next step, implement the calculation\r\n+  #\r\n+  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n+  # and move on to implement the recurse_calc_query_exact_tree() function\r\n+  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n+  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n+  # and associated function and add your own calculation code here\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n+  #\r\n+  # Normalize this result to get true probability.\r\n+  #\r\n+  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n+  #\r\n+  # Refer to the example on slide 30.\r\n+  #\r\n+  # (Reference solution is 3 lines of code.)\r\n+  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n+  \"\"\"\r\n+  Recursiving process the summation tree \r\n+  \r\n+  model,queryVar,evidence: See calc_query_exact_tree()\r\n+  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n+    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n+  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n+  \"\"\"\r\n+  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n+\r\n+  # Your overall task in the function is to assign values to:\r\n+  #   prQ_T\r\n+  #   prQ_F\r\n+  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n+  # covering both cases where query=True and query=False.\r\n+\r\n+  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n+  if marginalize:\r\n+    #Summation term, need to branch over all possible values and continue calculation\r\n+    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n+    # calculation\r\n+    #\r\n+    # You will need to recurse for each element of the summation (i.e. each branch)\r\n+    # Then properly combine the results together\r\n+    #\r\n+    # Slides 26-28 show examples of resolving summations.\r\n+    #\r\n+    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n+    #   BUT remember to change it back to the original values when you are done!\r\n+    #   (The original value for unknown variables is None.)\r\n+    #\r\n+    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n+    #   example of how to make the recursive call(s)\r\n+    #\r\n+    # (Reference solution is 7 lines of code.)\r\n+    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+  else:\r\n+    #Probability term, calculate conditional probability for this variable and continue calculation\r\n+    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n+    if queryVar in model.varDist[var].parents:\r\n+      #Query variable is a condition for this term\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n+      #\r\n+      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n+      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n+      # consider both what happens when the query variable is True, and also when it is False.\r\n+      #\r\n+      # Copy from your code below and modify to deal with this additional element.\r\n+      #\r\n+      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 11 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+    elif var==queryVar:\r\n+      #This term is probability _for_ the Query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one second! (Atleast, I recommend this.)\r\n+      #\r\n+      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n+      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n+      # is False.\r\n+      #\r\n+      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n+      # \r\n+      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 5 additional lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+    else:\r\n+      #Simple term, no need to worry about query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one first! (It's the simplest of the three.)\r\n+      #\r\n+      # You need to get the conditional probability for this variable and correctly\r\n+      # combine it with the results of the recursive call above.\r\n+      #\r\n+      # Don't forget that this variable's value could be True or False!\r\n+      #\r\n+      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n+      #\r\n+      # (Reference solution is 5 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+    if len(remainingCalc)>1:\r\n+      #If there are still terms left, then recurse\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n+      \r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Update prQ_T, prQ_F with the results from the recursive call.\r\n+      #\r\n+      # How do you combine _factors_ together?\r\n+      #\r\n+      # (Reference solution is 2 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n+  \r\n+##############################################################################\r\n+## Support code\r\n+def read_cpt(model,varName,condVals):\r\n+  \"\"\"\r\n+  Read conditional probability for a specified variable with provided condition (parent) values\r\n+  Note, the value returned is conditional probability for variable being True\r\n+  \r\n+  Warning: If you get an index exception and referenced key has None in it, this means\r\n+    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n+  \r\n+  model: model object, see read_model_file() for specification\r\n+  varName: string, variable name to read probability for\r\n+  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n+              (Missing conditions will cause errors, extraneous values will be ignored)\r\n+  \"\"\"\r\n+  if varName not in model.varDist:\r\n+    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n+  varDist=model.varDist[varName]\r\n+  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n+  if key not in varDist.cpt:\r\n+    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n+  return varDist.cpt[key]\r\n+\r\n+def truefalse_combination_iterator(entries):\r\n+  \"\"\"\r\n+  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n+  \"\"\"\r\n+  entries=list(entries)\r\n+  entries.reverse()\r\n+  if len(entries)>30:\r\n+    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n+  for c in range(1<<len(entries)):\r\n+    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n+\r\n+def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n+  \"\"\"\r\n+  Create represention of terms in an inference calculation such as on slides 20-21\r\n+  \r\n+  Returns a list of (boolean,string) tuples where:\r\n+    (True,variable) represents a summation term where a variable needs to be marginalized\r\n+    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n+  \"\"\"\r\n+  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Naive solution\r\n+  #\r\n+  # model.varsDep already has variables in order of dependency...\r\n+  # So take that and insert summation terms any time we encounter a new hidden variable\r\n+  #\r\n+  # Downside is little optimization, likely to have many unnecessary terms\r\n+  if False:\r\n+    hiddenLeft=set(hiddenVars)\r\n+    seq=[]\r\n+    for v in model.varsDep:\r\n+      #Check if factor variable is a (unhandled) hidden variable\r\n+      if v in hiddenLeft:\r\n+        seq.append( (True,v) ) #If so, trigger a marginalization\r\n+        hiddenLeft.remove(v)   #And mark it as handled\r\n+      for p in model.varDist[v].parents:\r\n+        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n+        if p in hiddenLeft:\r\n+          seq.append( (True,p) )\r\n+          hiddenLeft.remove(p)\r\n+      seq.append( (False,v) ) #Then process the factor itself\r\n+    assert(len(hiddenLeft)==0)\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Arbitrary ordering\r\n+  #\r\n+  # What if we wanted to handle hidden variables in an arbitrary order?\r\n+  #\r\n+  # Possible, but we'll have to be careful where we put factors, after\r\n+  # all their dependencies are satisfied.\r\n+  def seq_from_hid_order(hOrd):\r\n+    #The trick to make this work is to first assign every\r\n+    #hidden variable a priority based on the order\r\n+    prio={h:i for i,h in enumerate(hOrd)}\r\n+    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n+    #Then rate each factor on the highest priority amongst its dependencies\r\n+    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n+    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n+    vOrd.sort()\r\n+    #All that's left is to turn it into the expected sequence format\r\n+    return list( (not nm,v) for _,nm,v in vOrd )\r\n+  \r\n+  #--------------------------------------------------------\r\n+  # Brute force best\r\n+  #\r\n+  # Now, where to get an ordering to use the above?\r\n+  #\r\n+  # We could brute force try every possible ordering...\r\n+  if True:\r\n+    bestSeq=None\r\n+    bestSeqCost=sys.maxsize\r\n+    for hOrd in permutations(hiddenVars):\r\n+      tSeq=seq_from_hid_order(hOrd)\r\n+      #Note, really should do below norm optimization here too\r\n+      \r\n+      #Now the tricky bit is to rate each ordering\r\n+      #We'll do it by doubling the cost of each factor every time\r\n+      #We cross a summation\r\n+      tot=0\r\n+      ct=1\r\n+      for m,v in tSeq:\r\n+        if m:\r\n+          ct*=2\r\n+        else:\r\n+          tot+=ct\r\n+      \r\n+      if tot<bestSeqCost:\r\n+        bestSeq=tSeq\r\n+        bestSeqCost=tot\r\n+    seq=bestSeq\r\n+  # But this will be very expensive for large models\r\n+  #--------------------------------------------------------\r\n+  # Greedy\r\n+  #\r\n+  # Alternately, we could apply a greedy approach.\r\n+  #\r\n+  # Some how rate each hidden variable on how expensive we think\r\n+  # it is, then put the most expensive ones earliest\r\n+  # ***TODO***\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Simple normalization optimization\r\n+  #\r\n+  # One thing we learned is that for a multiplicative term,\r\n+  # if it doesn't mention the query variable, then it's a\r\n+  # constant and can be handled via normalization (folded into alpha)\r\n+  #\r\n+  # This is non-trivial to detect for summation terms, but we\r\n+  # can easily do it for factors outside of any summation...\r\n+  if True:\r\n+    i=0\r\n+    while i<len(seq):\r\n+      m,v=seq[i]\r\n+      if m:\r\n+        break #Found first summation, quit\r\n+      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n+        #No mention of query variable, remove\r\n+        del seq[i]\r\n+      else:\r\n+        i+=1\r\n+  \r\n+  return seq\r\n+\r\n+def calc_query_approx(model,queryVar,queryVal,evidence):\r\n+  raise NotImplementedError()\r\n+\r\n+def generate_joint_prob_table(model):\r\n+  \"\"\"\r\n+  Output a joint probability table for the provided model\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  table=[]\r\n+  row=list(model.vars)\r\n+  row.append('Joint Pr')\r\n+  table.append(row)\r\n+  for varVals in truefalse_combination_iterator(model.vars):\r\n+    pr=calc_global_joint_prob(model,varVals)\r\n+    row=[varVals[x] for x in model.vars]\r\n+    row.append(pr)\r\n+    table.append(row)\r\n+  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+  return\r\n+\r\n+def read_model_file(filename):\r\n+  \"\"\"\r\n+  Returns model object with the following elements:\r\n+    vars : list of strings\r\n+      The list of variables the model describes\r\n+      In alphabetical order\r\n+    varsDep : list of strings\r\n+      Same contents as 'vars' but in dependency order (parents come before children)\r\n+    varDist : dict of objects\r\n+      Distribution information for each variable\r\n+      Dictionary key is variable name\r\n+      Object has the following elements:\r\n+        parents : set of strings\r\n+        children : set of strings\r\n+        cpt : dict of numbers\r\n+          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n+          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n+            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n+  Model file format is as follows:\r\n+    Basic file format is Comma-Separated Value (.csv)\r\n+    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n+    Tables are separated by atleast one empty line\r\n+    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n+    Each table:\r\n+      Starts with a header row containing variable names\r\n+        The last name is the variable whose cond probability is being described\r\n+        Any preceding names are considered to be parent variables\r\n+      Following rows contain True/False values for each parent and probability for main variable being true\r\n+      Any missing parent value combinations will be assumed to be probability 0.5\r\n+    Only Bernoulli/Boolean variables can be represented in this file format\r\n+  \"\"\"\r\n+  class ModelObj:\r\n+    def __init__(self):\r\n+      self.vars=[]\r\n+      self.varsDep=None\r\n+      self.varDist={}\r\n+\r\n+  class VarObj:\r\n+    def __init__(self, parents, children, cpt):\r\n+      self.parents = parents\r\n+      self.children = children\r\n+      self.cpt = cpt\r\n+\r\n+  model=ModelObj()\r\n+  #--------------------------------------------------------\r\n+  #Read data from file\r\n+  with open(filename, newline='') as csvfile:\r\n+    csvreader = csv.reader(csvfile)\r\n+    \r\n+    rowNum=0\r\n+    var=None\r\n+    varIdx=None\r\n+    parents=None\r\n+    cpt=None\r\n+    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n+      rowNum+=1\r\n+      srow=''.join(row).strip()\r\n+      if srow.startswith('#'):\r\n+        continue #Comment line, skip\r\n+      if len(srow)==0:\r\n+        #Empty line\r\n+        if var is not None:\r\n+          #End current table\r\n+          model.vars.append(var)\r\n+          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n+          #Wait for new table\r\n+          var=None\r\n+          varIdx=None\r\n+          parents=None\r\n+          cpt=None\r\n+      elif var is None:\r\n+        #Start new table\r\n+        if len(row)>1:\r\n+          parents=row[0:-1]\r\n+        else:\r\n+          parents=[]\r\n+        varIdx=len(row)-1\r\n+        var=row[varIdx]\r\n+        cpt={}\r\n+      else:\r\n+        #Add new entry to table\r\n+        if len(row)<varIdx+1:\r\n+          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n+        if len(parents)>0:\r\n+          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n+        else:\r\n+          key=frozenset()\r\n+        cpt[key]=float(row[-1])\r\n+  model.vars.sort()\r\n+  #--------------------------------------------------------\r\n+  # Check distributions for missing entries\r\n+  vCheck=frozenset(model.vars)\r\n+  for var in model.vars: #Make sure every mentioned variable has an entry\r\n+    for p in model.varDist[var].parents:\r\n+      if p not in vCheck:\r\n+        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n+  for var in model.vars: #Check every cpt for missing rows\r\n+    varDist=model.varDist[var]\r\n+    missingCnt=0\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      key=frozenset(((x,v) for x,v in varVals.items()))\r\n+      if key not in varDist.cpt:\r\n+        missingCnt+=1\r\n+        varDist.cpt[key]=0.5\r\n+    if missingCnt>0:\r\n+      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n+  #--------------------------------------------------------\r\n+  # Create children entries\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=set()\r\n+  for var in model.vars:\r\n+    for p in model.varDist[var].parents:\r\n+      model.varDist[p].children.add(var)\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n+  #--------------------------------------------------------\r\n+  # Create dependency ordering\r\n+  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n+  idx=0\r\n+  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n+  while idx<len(varsDep):\r\n+    var=varsDep[idx]\r\n+    for c in model.varDist[var].children:\r\n+      parentsLeft[c]-=1\r\n+      if parentsLeft[c]==0:\r\n+        #All parents have been visited, so dependencies of this child are met\r\n+        varsDep.append(c)\r\n+      elif parentsLeft[c]<0:\r\n+        #Repeat visit to a parent can only happen if a cycle exists\r\n+        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n+    idx+=1\r\n+  model.varsDep=varsDep\r\n+  #--------------------------------------------------------\r\n+  return model\r\n+\r\n+def print_model(model):\r\n+  \"\"\"\r\n+  Print a model object back out in pretty form\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  for v in model.vars:\r\n+    varDist=model.varDist[v]\r\n+    print('--------------------------------------------------')\r\n+    print('Variable:',v)\r\n+    print('--------------------------------------------------')\r\n+    print('Children:',', '.join(varDist.children))\r\n+    \r\n+    table=[]\r\n+    row=list(varDist.parents)\r\n+    row.append('P({0}=T|...)'.format(v))\r\n+    table.append(row)\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      pr=read_cpt(model,v,varVals)\r\n+      row=[varVals[x] for x in varDist.parents]\r\n+      row.append(pr)\r\n+      table.append(row)\r\n+    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+    print(\"\")\r\n+    \r\n+##############################################################################\r\n+## Main functions\r\n+def main(args):\r\n+  global DEBUG_OUTPUT\r\n+  if args.debug:\r\n+    DEBUG_OUTPUT=1\r\n+  #Argument checking plus additional parsing\r\n+  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in table mode')\r\n+  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in print mode')\r\n+  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n+    error('Argument --query required in inference modes')\r\n+  elif args.query is not None:\r\n+    if '=' not in args.query:\r\n+      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n+    s=args.query.split('=')\r\n+    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n+  if args.evidence is None:\r\n+    args.evidence=[]\r\n+  else:\r\n+    ev=[]\r\n+    for e in args.evidence:\r\n+      if '=' not in e:\r\n+        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n+      s=e.split('=')\r\n+      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n+    args.evidence={ var:val for var,val in ev }\r\n+\r\n+  print('Reading model from',args.model)\r\n+  model=read_model_file(args.model)\r\n+\r\n+  if args.mode=='table':\r\n+    generate_joint_prob_table(model)\r\n+  elif args.mode=='print':\r\n+    print_model(model)\r\n+  else:\r\n+    #One of the inference modes\r\n+    #Check inputs against model\r\n+    if args.query[0] not in model.vars:\r\n+      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n+    for var,val in args.evidence.items():\r\n+      if var not in model.vars:\r\n+        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n+    #Output problem setup\r\n+    print(\"Inference mode:\",args.mode)\r\n+    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n+    if len(args.evidence)==0:\r\n+      print(\"No evidence\")\r\n+    else:\r\n+      print(\"Evidence:\")\r\n+      for var,val in args.evidence.items():\r\n+        print(\"  '{0}' is {1}\".format(var,val))\r\n+\r\n+    #Run inference\r\n+    pr=None\r\n+    if args.mode=='brute':\r\n+      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n+    elif args.mode=='tree':\r\n+      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n+    else: #args.mode=='approx'\r\n+      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n+    print('Probability is',pr)\r\n+\r\n+  return\r\n+\r\n+def error(msg):\r\n+  print(msg)\r\n+  sys.exit(1)\r\n+  return\r\n+\r\n+if __name__ == '__main__':\r\n+  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n+  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n+  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n+  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n+  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n+  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n+  args = parser.parse_args()\r\n+  error=lambda msg : parser.error(msg)\r\n+  main(args)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1699508990480,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -160,695 +160,14 @@\n   #\r\n   # Refer to the example on slide 30.\r\n   #\r\n   # (Reference solution is 3 lines of code.)\r\n-  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+  normalization_factor = prQ_T + prQ_F\r\n+  prQ_T /= normalization_factor\r\n+  prQ_F /= normalization_factor\r\n \r\n-def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n-  \"\"\"\r\n-  Recursiving process the summation tree \r\n-  \r\n-  model,queryVar,evidence: See calc_query_exact_tree()\r\n-  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n-    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n-  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n-  \"\"\"\r\n-  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n+  return prQ_T if queryVal else prQ_F\r\n \r\n-  # Your overall task in the function is to assign values to:\r\n-  #   prQ_T\r\n-  #   prQ_F\r\n-  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n-  # covering both cases where query=True and query=False.\r\n-\r\n-  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n-  if marginalize:\r\n-    #Summation term, need to branch over all possible values and continue calculation\r\n-    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n-\r\n-    # YOUR CODE HERE\r\n-    #\r\n-    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n-    # calculation\r\n-    #\r\n-    # You will need to recurse for each element of the summation (i.e. each branch)\r\n-    # Then properly combine the results together\r\n-    #\r\n-    # Slides 26-28 show examples of resolving summations.\r\n-    #\r\n-    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n-    #   BUT remember to change it back to the original values when you are done!\r\n-    #   (The original value for unknown variables is None.)\r\n-    #\r\n-    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n-    #   example of how to make the recursive call(s)\r\n-    #\r\n-    # (Reference solution is 7 lines of code.)\r\n-    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-  else:\r\n-    #Probability term, calculate conditional probability for this variable and continue calculation\r\n-    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n-    if queryVar in model.varDist[var].parents:\r\n-      #Query variable is a condition for this term\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n-      #\r\n-      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n-      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n-      # consider both what happens when the query variable is True, and also when it is False.\r\n-      #\r\n-      # Copy from your code below and modify to deal with this additional element.\r\n-      #\r\n-      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n-      #\r\n-      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n-      #   BUT remember to change it back to the original values when you are done!\r\n-      #\r\n-      # (Reference solution is 11 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-    elif var==queryVar:\r\n-      #This term is probability _for_ the Query variable\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one second! (Atleast, I recommend this.)\r\n-      #\r\n-      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n-      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n-      # is False.\r\n-      #\r\n-      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n-      # \r\n-      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n-      #\r\n-      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n-      #   BUT remember to change it back to the original values when you are done!\r\n-      #\r\n-      # (Reference solution is 5 additional lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-    else:\r\n-      #Simple term, no need to worry about query variable\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one first! (It's the simplest of the three.)\r\n-      #\r\n-      # You need to get the conditional probability for this variable and correctly\r\n-      # combine it with the results of the recursive call above.\r\n-      #\r\n-      # Don't forget that this variable's value could be True or False!\r\n-      #\r\n-      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n-      #\r\n-      # (Reference solution is 5 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-    if len(remainingCalc)>1:\r\n-      #If there are still terms left, then recurse\r\n-      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n-      \r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Update prQ_T, prQ_F with the results from the recursive call.\r\n-      #\r\n-      # How do you combine _factors_ together?\r\n-      #\r\n-      # (Reference solution is 2 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n-  \r\n-##############################################################################\r\n-## Support code\r\n-def read_cpt(model,varName,condVals):\r\n-  \"\"\"\r\n-  Read conditional probability for a specified variable with provided condition (parent) values\r\n-  Note, the value returned is conditional probability for variable being True\r\n-  \r\n-  Warning: If you get an index exception and referenced key has None in it, this means\r\n-    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n-  \r\n-  model: model object, see read_model_file() for specification\r\n-  varName: string, variable name to read probability for\r\n-  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n-              (Missing conditions will cause errors, extraneous values will be ignored)\r\n-  \"\"\"\r\n-  if varName not in model.varDist:\r\n-    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n-  varDist=model.varDist[varName]\r\n-  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n-  if key not in varDist.cpt:\r\n-    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n-  return varDist.cpt[key]\r\n-\r\n-def truefalse_combination_iterator(entries):\r\n-  \"\"\"\r\n-  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n-  \"\"\"\r\n-  entries=list(entries)\r\n-  entries.reverse()\r\n-  if len(entries)>30:\r\n-    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n-  for c in range(1<<len(entries)):\r\n-    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n-\r\n-def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n-  \"\"\"\r\n-  Create represention of terms in an inference calculation such as on slides 20-21\r\n-  \r\n-  Returns a list of (boolean,string) tuples where:\r\n-    (True,variable) represents a summation term where a variable needs to be marginalized\r\n-    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n-  \"\"\"\r\n-  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Naive solution\r\n-  #\r\n-  # model.varsDep already has variables in order of dependency...\r\n-  # So take that and insert summation terms any time we encounter a new hidden variable\r\n-  #\r\n-  # Downside is little optimization, likely to have many unnecessary terms\r\n-  if False:\r\n-    hiddenLeft=set(hiddenVars)\r\n-    seq=[]\r\n-    for v in model.varsDep:\r\n-      #Check if factor variable is a (unhandled) hidden variable\r\n-      if v in hiddenLeft:\r\n-        seq.append( (True,v) ) #If so, trigger a marginalization\r\n-        hiddenLeft.remove(v)   #And mark it as handled\r\n-      for p in model.varDist[v].parents:\r\n-        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n-        if p in hiddenLeft:\r\n-          seq.append( (True,p) )\r\n-          hiddenLeft.remove(p)\r\n-      seq.append( (False,v) ) #Then process the factor itself\r\n-    assert(len(hiddenLeft)==0)\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Arbitrary ordering\r\n-  #\r\n-  # What if we wanted to handle hidden variables in an arbitrary order?\r\n-  #\r\n-  # Possible, but we'll have to be careful where we put factors, after\r\n-  # all their dependencies are satisfied.\r\n-  def seq_from_hid_order(hOrd):\r\n-    #The trick to make this work is to first assign every\r\n-    #hidden variable a priority based on the order\r\n-    prio={h:i for i,h in enumerate(hOrd)}\r\n-    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n-    #Then rate each factor on the highest priority amongst its dependencies\r\n-    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n-    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n-    vOrd.sort()\r\n-    #All that's left is to turn it into the expected sequence format\r\n-    return list( (not nm,v) for _,nm,v in vOrd )\r\n-  \r\n-  #--------------------------------------------------------\r\n-  # Brute force best\r\n-  #\r\n-  # Now, where to get an ordering to use the above?\r\n-  #\r\n-  # We could brute force try every possible ordering...\r\n-  if True:\r\n-    bestSeq=None\r\n-    bestSeqCost=sys.maxsize\r\n-    for hOrd in permutations(hiddenVars):\r\n-      tSeq=seq_from_hid_order(hOrd)\r\n-      #Note, really should do below norm optimization here too\r\n-      \r\n-      #Now the tricky bit is to rate each ordering\r\n-      #We'll do it by doubling the cost of each factor every time\r\n-      #We cross a summation\r\n-      tot=0\r\n-      ct=1\r\n-      for m,v in tSeq:\r\n-        if m:\r\n-          ct*=2\r\n-        else:\r\n-          tot+=ct\r\n-      \r\n-      if tot<bestSeqCost:\r\n-        bestSeq=tSeq\r\n-        bestSeqCost=tot\r\n-    seq=bestSeq\r\n-  # But this will be very expensive for large models\r\n-  #--------------------------------------------------------\r\n-  # Greedy\r\n-  #\r\n-  # Alternately, we could apply a greedy approach.\r\n-  #\r\n-  # Some how rate each hidden variable on how expensive we think\r\n-  # it is, then put the most expensive ones earliest\r\n-  # ***TODO***\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Simple normalization optimization\r\n-  #\r\n-  # One thing we learned is that for a multiplicative term,\r\n-  # if it doesn't mention the query variable, then it's a\r\n-  # constant and can be handled via normalization (folded into alpha)\r\n-  #\r\n-  # This is non-trivial to detect for summation terms, but we\r\n-  # can easily do it for factors outside of any summation...\r\n-  if True:\r\n-    i=0\r\n-    while i<len(seq):\r\n-      m,v=seq[i]\r\n-      if m:\r\n-        break #Found first summation, quit\r\n-      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n-        #No mention of query variable, remove\r\n-        del seq[i]\r\n-      else:\r\n-        i+=1\r\n-  \r\n-  return seq\r\n-\r\n-def calc_query_approx(model,queryVar,queryVal,evidence):\r\n-  raise NotImplementedError()\r\n-\r\n-def generate_joint_prob_table(model):\r\n-  \"\"\"\r\n-  Output a joint probability table for the provided model\r\n-  \"\"\"\r\n-  from tabulate import tabulate\r\n-  table=[]\r\n-  row=list(model.vars)\r\n-  row.append('Joint Pr')\r\n-  table.append(row)\r\n-  for varVals in truefalse_combination_iterator(model.vars):\r\n-    pr=calc_global_joint_prob(model,varVals)\r\n-    row=[varVals[x] for x in model.vars]\r\n-    row.append(pr)\r\n-    table.append(row)\r\n-  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n-  return\r\n-\r\n-def read_model_file(filename):\r\n-  \"\"\"\r\n-  Returns model object with the following elements:\r\n-    vars : list of strings\r\n-      The list of variables the model describes\r\n-      In alphabetical order\r\n-    varsDep : list of strings\r\n-      Same contents as 'vars' but in dependency order (parents come before children)\r\n-    varDist : dict of objects\r\n-      Distribution information for each variable\r\n-      Dictionary key is variable name\r\n-      Object has the following elements:\r\n-        parents : set of strings\r\n-        children : set of strings\r\n-        cpt : dict of numbers\r\n-          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n-          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n-            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n-  Model file format is as follows:\r\n-    Basic file format is Comma-Separated Value (.csv)\r\n-    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n-    Tables are separated by atleast one empty line\r\n-    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n-    Each table:\r\n-      Starts with a header row containing variable names\r\n-        The last name is the variable whose cond probability is being described\r\n-        Any preceding names are considered to be parent variables\r\n-      Following rows contain True/False values for each parent and probability for main variable being true\r\n-      Any missing parent value combinations will be assumed to be probability 0.5\r\n-    Only Bernoulli/Boolean variables can be represented in this file format\r\n-  \"\"\"\r\n-  class ModelObj:\r\n-    def __init__(self):\r\n-      self.vars=[]\r\n-      self.varsDep=None\r\n-      self.varDist={}\r\n-\r\n-  class VarObj:\r\n-    def __init__(self, parents, children, cpt):\r\n-      self.parents = parents\r\n-      self.children = children\r\n-      self.cpt = cpt\r\n-\r\n-  model=ModelObj()\r\n-  #--------------------------------------------------------\r\n-  #Read data from file\r\n-  with open(filename, newline='') as csvfile:\r\n-    csvreader = csv.reader(csvfile)\r\n-    \r\n-    rowNum=0\r\n-    var=None\r\n-    varIdx=None\r\n-    parents=None\r\n-    cpt=None\r\n-    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n-      rowNum+=1\r\n-      srow=''.join(row).strip()\r\n-      if srow.startswith('#'):\r\n-        continue #Comment line, skip\r\n-      if len(srow)==0:\r\n-        #Empty line\r\n-        if var is not None:\r\n-          #End current table\r\n-          model.vars.append(var)\r\n-          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n-          #Wait for new table\r\n-          var=None\r\n-          varIdx=None\r\n-          parents=None\r\n-          cpt=None\r\n-      elif var is None:\r\n-        #Start new table\r\n-        if len(row)>1:\r\n-          parents=row[0:-1]\r\n-        else:\r\n-          parents=[]\r\n-        varIdx=len(row)-1\r\n-        var=row[varIdx]\r\n-        cpt={}\r\n-      else:\r\n-        #Add new entry to table\r\n-        if len(row)<varIdx+1:\r\n-          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n-        if len(parents)>0:\r\n-          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n-        else:\r\n-          key=frozenset()\r\n-        cpt[key]=float(row[-1])\r\n-  model.vars.sort()\r\n-  #--------------------------------------------------------\r\n-  # Check distributions for missing entries\r\n-  vCheck=frozenset(model.vars)\r\n-  for var in model.vars: #Make sure every mentioned variable has an entry\r\n-    for p in model.varDist[var].parents:\r\n-      if p not in vCheck:\r\n-        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n-  for var in model.vars: #Check every cpt for missing rows\r\n-    varDist=model.varDist[var]\r\n-    missingCnt=0\r\n-    for varVals in truefalse_combination_iterator(varDist.parents):\r\n-      key=frozenset(((x,v) for x,v in varVals.items()))\r\n-      if key not in varDist.cpt:\r\n-        missingCnt+=1\r\n-        varDist.cpt[key]=0.5\r\n-    if missingCnt>0:\r\n-      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n-  #--------------------------------------------------------\r\n-  # Create children entries\r\n-  for var in model.vars:\r\n-    model.varDist[var].children=set()\r\n-  for var in model.vars:\r\n-    for p in model.varDist[var].parents:\r\n-      model.varDist[p].children.add(var)\r\n-  for var in model.vars:\r\n-    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n-  #--------------------------------------------------------\r\n-  # Create dependency ordering\r\n-  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n-  idx=0\r\n-  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n-  while idx<len(varsDep):\r\n-    var=varsDep[idx]\r\n-    for c in model.varDist[var].children:\r\n-      parentsLeft[c]-=1\r\n-      if parentsLeft[c]==0:\r\n-        #All parents have been visited, so dependencies of this child are met\r\n-        varsDep.append(c)\r\n-      elif parentsLeft[c]<0:\r\n-        #Repeat visit to a parent can only happen if a cycle exists\r\n-        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n-    idx+=1\r\n-  model.varsDep=varsDep\r\n-  #--------------------------------------------------------\r\n-  return model\r\n-\r\n-def print_model(model):\r\n-  \"\"\"\r\n-  Print a model object back out in pretty form\r\n-  \"\"\"\r\n-  from tabulate import tabulate\r\n-  for v in model.vars:\r\n-    varDist=model.varDist[v]\r\n-    print('--------------------------------------------------')\r\n-    print('Variable:',v)\r\n-    print('--------------------------------------------------')\r\n-    print('Children:',', '.join(varDist.children))\r\n-    \r\n-    table=[]\r\n-    row=list(varDist.parents)\r\n-    row.append('P({0}=T|...)'.format(v))\r\n-    table.append(row)\r\n-    for varVals in truefalse_combination_iterator(varDist.parents):\r\n-      pr=read_cpt(model,v,varVals)\r\n-      row=[varVals[x] for x in varDist.parents]\r\n-      row.append(pr)\r\n-      table.append(row)\r\n-    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n-    print(\"\")\r\n-    \r\n-##############################################################################\r\n-## Main functions\r\n-def main(args):\r\n-  global DEBUG_OUTPUT\r\n-  if args.debug:\r\n-    DEBUG_OUTPUT=1\r\n-  #Argument checking plus additional parsing\r\n-  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n-    error('Arguments --query and --evidence not allowed in table mode')\r\n-  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n-    error('Arguments --query and --evidence not allowed in print mode')\r\n-  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n-    error('Argument --query required in inference modes')\r\n-  elif args.query is not None:\r\n-    if '=' not in args.query:\r\n-      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n-    s=args.query.split('=')\r\n-    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n-  if args.evidence is None:\r\n-    args.evidence=[]\r\n-  else:\r\n-    ev=[]\r\n-    for e in args.evidence:\r\n-      if '=' not in e:\r\n-        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n-      s=e.split('=')\r\n-      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n-    args.evidence={ var:val for var,val in ev }\r\n-\r\n-  print('Reading model from',args.model)\r\n-  model=read_model_file(args.model)\r\n-\r\n-  if args.mode=='table':\r\n-    generate_joint_prob_table(model)\r\n-  elif args.mode=='print':\r\n-    print_model(model)\r\n-  else:\r\n-    #One of the inference modes\r\n-    #Check inputs against model\r\n-    if args.query[0] not in model.vars:\r\n-      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n-    for var,val in args.evidence.items():\r\n-      if var not in model.vars:\r\n-        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n-    #Output problem setup\r\n-    print(\"Inference mode:\",args.mode)\r\n-    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n-    if len(args.evidence)==0:\r\n-      print(\"No evidence\")\r\n-    else:\r\n-      print(\"Evidence:\")\r\n-      for var,val in args.evidence.items():\r\n-        print(\"  '{0}' is {1}\".format(var,val))\r\n-\r\n-    #Run inference\r\n-    pr=None\r\n-    if args.mode=='brute':\r\n-      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n-    elif args.mode=='tree':\r\n-      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n-    else: #args.mode=='approx'\r\n-      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n-    print('Probability is',pr)\r\n-\r\n-  return\r\n-\r\n-def error(msg):\r\n-  print(msg)\r\n-  sys.exit(1)\r\n-  return\r\n-\r\n-if __name__ == '__main__':\r\n-  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n-  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n-  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n-  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n-  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n-  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n-  args = parser.parse_args()\r\n-  error=lambda msg : parser.error(msg)\r\n-  main(args)\n-import argparse\r\n-import csv\r\n-from itertools import chain, permutations\r\n-import math\r\n-#import matplotlib.pyplot as plt\r\n-#import numpy as np\r\n-from random import random\r\n-import sys\r\n-\r\n-DEBUG_OUTPUT=0\r\n-\r\n-##############################################################################\r\n-## Student code\r\n-def calc_global_joint_prob(model, variableValues):\r\n-  \"\"\"\r\n-  Calculate the global joint probability of a model for a specific set of values\r\n-  \r\n-  model: model object, see read_model_file() for specification\r\n-  variableValues: dictionary of boolean values, keys are variable names\r\n-  \"\"\"\r\n-  # YOUR CODE HERE\r\n-  #\r\n-  # You may assume variableValues is complete, i.e containes all variables in the model\r\n-  #   Thus, no marginalization is necessary\r\n-  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n-  #\r\n-  # You can find a complete descrition of the model object in the documentation of\r\n-  #   the read_model_file() function, BUT\r\n-  # All you will need is the list of variables: model.vars\r\n-  #\r\n-  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n-  #\r\n-  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n-  #\r\n-  # (Reference solution is 7 lines of code.)\r\n-  joint_prob = 1.0\r\n-\r\n-  for var in model.vars:\r\n-      parents = model.varDist[var].parents\r\n-      cond_vals = {parent: variableValues[parent] for parent in parents}\r\n-      cpt_entry = read_cpt(model, var, cond_vals)\r\n-\r\n-      if variableValues[var]:\r\n-          joint_prob *= cpt_entry\r\n-      else:\r\n-          joint_prob *= 1 - cpt_entry\r\n-\r\n-  return joint_prob\r\n-\r\n-\r\n-def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n-  \"\"\"\r\n-  Calculate posterior probability for a given variable\r\n-\r\n-  model: model object, see read_model_file() for specification\r\n-  queryVar: string, query variable name\r\n-  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n-  evidence: dictionary of boolean values, where keys are evidence variable names\r\n-            (Any variable not listed as query or evidence is assumed to be hidden)\r\n-  \"\"\"\r\n-\r\n-  # This first attempt at probabilistic inference will use the brute-force (table)\r\n-  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n-  #\r\n-  # This requires the calculation of two joint probabilities based on the definition\r\n-  # of conditional probability:\r\n-  #                          Pr( Query & Evidence )\r\n-  #   Pr(Query | Evidence) = ----------------------\r\n-  #                              Pr( Evidence )\r\n-  #\r\n-  # Both of these joint probabilities can be calculated by going over every entry in\r\n-  # the global joint probability table and summing up the probabilities of those\r\n-  # entries that match what we're looking for\r\n-  \r\n-  def dict_issubset(d,sub):\r\n-    \"\"\"\r\n-    Returns True if every key,value pair in sub has a matching key and value in d\r\n-    Note: sub should not contain any entries with value None\r\n-    \"\"\"\r\n-    return all(d.get(key,None)==val for key,val in sub.items())\r\n-     \r\n-  pr_QE=0\r\n-  pr_E=0\r\n-  for jptEntry in truefalse_combination_iterator(model.vars):\r\n-    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n-\r\n-    # YOUR CODE HERE\r\n-    #\r\n-    # jptEntry will be a dictionary with a key for every variable in the model,\r\n-    #   and the loop will go over every possible combination of True/False for each variable\r\n-    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n-    #\r\n-    # Your task is to collect all the probabilities that match the evidence, and query\r\n-    #\r\n-    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n-    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n-    #\r\n-    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n-    #\r\n-    # (Reference solution is 4 lines of code.)\r\n-    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-  return pr_QE/pr_E\r\n-\r\n-def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n-  \"\"\"\r\n-  Calculate posterior probability for a given variable\r\n-\r\n-  model: model object, see read_model_file() for specification\r\n-  queryVar: string, query variable name\r\n-  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n-  evidence: dictionary of boolean values, where keys are evidence variable names\r\n-            (Any variable not listed as query or evidence is assumed to be hidden)\r\n-  \"\"\"\r\n-  \r\n-  # First step, we need to figure out what order we will calculate terms in and where\r\n-  # marginalization needs to happen.\r\n-  #\r\n-  # That said, though this is a part of the inference process that you need to know, it's a\r\n-  # bit tricky to get working in general, especially the optimization bits.\r\n-  #\r\n-  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n-  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n-  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n-  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n-  # For example, the formula on slide 20 would be represented as:\r\n-  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n-  # The formula on slide 21 would be:\r\n-  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n-  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n-  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n-  \r\n-  # Debug: Output a nicer version of the calculation order (inference formula)\r\n-  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n-  \r\n-  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n-  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n-  \r\n-  # Next step, implement the calculation\r\n-  #\r\n-  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n-  # and move on to implement the recurse_calc_query_exact_tree() function\r\n-  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n-  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n-  # and associated function and add your own calculation code here\r\n-  \r\n-  # YOUR CODE HERE\r\n-  #\r\n-  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n-  #\r\n-  # Normalize this result to get true probability.\r\n-  #\r\n-  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n-  #\r\n-  # Refer to the example on slide 30.\r\n-  #\r\n-  # (Reference solution is 3 lines of code.)\r\n-  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n   \"\"\"\r\n   Recursiving process the summation tree \r\n   \r\n"
                },
                {
                    "date": 1699509574187,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -160,14 +160,10 @@\n   #\r\n   # Refer to the example on slide 30.\r\n   #\r\n   # (Reference solution is 3 lines of code.)\r\n-  normalization_factor = prQ_T + prQ_F\r\n-  prQ_T /= normalization_factor\r\n-  prQ_F /= normalization_factor\r\n+  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n \r\n-  return prQ_T if queryVal else prQ_F\r\n-\r\n def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n   \"\"\"\r\n   Recursiving process the summation tree \r\n   \r\n@@ -206,9 +202,18 @@\n     # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n     #   example of how to make the recursive call(s)\r\n     #\r\n     # (Reference solution is 7 lines of code.)\r\n-    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+    variableValues_copy = variableValues.copy()  # Make a copy to handle both cases\r\n+    variableValues_copy[var] = True\r\n+    prQ_T_true, _ = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues_copy, remainingCalc)\r\n+\r\n+    variableValues_copy[var] = False\r\n+    _, prQ_F_false = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues_copy, remainingCalc)\r\n+\r\n+    # Combine the results for both cases\r\n+    prQ_T = prQ_T_true\r\n+    prQ_F = prQ_F_false\r\n   else:\r\n     #Probability term, calculate conditional probability for this variable and continue calculation\r\n     prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n     if queryVar in model.varDist[var].parents:\r\n@@ -230,9 +235,19 @@\n       # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n       #   BUT remember to change it back to the original values when you are done!\r\n       #\r\n       # (Reference solution is 11 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+      variableValues_copy_true = variableValues.copy()  # Make a copy to handle both cases\r\n+      variableValues_copy_true[var] = True\r\n+      prQ_T_true, _ = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues_copy_true, remainingCalc)\r\n+\r\n+      variableValues_copy_false = variableValues.copy()  # Make a copy to handle both cases\r\n+      variableValues_copy_false[var] = False\r\n+      _, prQ_F_false = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues_copy_false, remainingCalc)\r\n+\r\n+        # Combine the results for both cases\r\n+      prQ_T *= prQ_T_true\r\n+      prQ_F *= prQ_F_false\r\n     elif var==queryVar:\r\n       #This term is probability _for_ the Query variable\r\n       if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n \r\n@@ -251,9 +266,14 @@\n       # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n       #   BUT remember to change it back to the original values when you are done!\r\n       #\r\n       # (Reference solution is 5 additional lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+      variableValues_copy = variableValues.copy()  # Make a copy to handle both cases\r\n+      variableValues_copy[var] = True\r\n+      prQ_T = model.varDist[var].P(**variableValues_copy)\r\n+\r\n+      variableValues_copy[var] = False\r\n+      prQ_F = model.varDist[var].P(**variableValues_copy)\r\n     else:\r\n       #Simple term, no need to worry about query variable\r\n       if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n \r\n@@ -268,10 +288,18 @@\n       #\r\n       # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n       #\r\n       # (Reference solution is 5 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+      pr_var_true = model.varDist[var].P(**variableValues, **{var: True})\r\n+      pr_var_false = model.varDist[var].P(**variableValues, **{var: False})\r\n \r\n+      # Combine it with the results of the recursive call above\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+      # Update prQ_T, prQ_F with the results from the recursive call\r\n+      prQ_T = pr_var_true * prR_T\r\n+      prQ_F = pr_var_false * prR_F\r\n+\r\n     if len(remainingCalc)>1:\r\n       #If there are still terms left, then recurse\r\n       prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n       \r\n"
                },
                {
                    "date": 1699509613758,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -160,10 +160,15 @@\n   #\r\n   # Refer to the example on slide 30.\r\n   #\r\n   # (Reference solution is 3 lines of code.)\r\n-  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+  prQ_total = prQ_T + prQ_F\r\n+  prQ_T /= prQ_total\r\n+  prQ_F /= prQ_total\r\n \r\n+  # Return the probability based on the query value\r\n+  return prQ_T if queryVal else prQ_F\r\n+\r\n def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n   \"\"\"\r\n   Recursiving process the summation tree \r\n   \r\n"
                },
                {
                    "date": 1699509908517,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,765 @@\n+import argparse\r\n+import csv\r\n+from itertools import chain, permutations\r\n+import math\r\n+#import matplotlib.pyplot as plt\r\n+#import numpy as np\r\n+from random import random\r\n+import sys\r\n+\r\n+DEBUG_OUTPUT=0\r\n+\r\n+##############################################################################\r\n+## Student code\r\n+def calc_global_joint_prob(model, variableValues):\r\n+  \"\"\"\r\n+  Calculate the global joint probability of a model for a specific set of values\r\n+  model: model object, see read_model_file() for specification\r\n+  variableValues: dictionary of boolean values, keys are variable names\r\n+  \"\"\"\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # You may assume variableValues is complete, i.e containes all variables in the model\r\n+  #   Thus, no marginalization is necessary\r\n+  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n+  #\r\n+  # You can find a complete descrition of the model object in the documentation of\r\n+  #   the read_model_file() function, BUT\r\n+  # All you will need is the list of variables: model.vars\r\n+  #\r\n+  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n+  #\r\n+  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n+  #\r\n+  # (Reference solution is 7 lines of code.)\r\n+  joint_prob = 1.0\r\n+\r\n+  for var in model.vars:\r\n+      parents = model.varDist[var].parents\r\n+      cond_vals = {parent: variableValues[parent] for parent in parents}\r\n+      cpt_entry = read_cpt(model, var, cond_vals)\r\n+\r\n+      if variableValues[var]:\r\n+          joint_prob *= cpt_entry\r\n+      else:\r\n+          joint_prob *= 1 - cpt_entry\r\n+\r\n+  return joint_prob\r\n+\r\n+def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+\r\n+  # This first attempt at probabilistic inference will use the brute-force (table)\r\n+  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n+  #\r\n+  # This requires the calculation of two joint probabilities based on the definition\r\n+  # of conditional probability:\r\n+  #                          Pr( Query & Evidence )\r\n+  #   Pr(Query | Evidence) = ----------------------\r\n+  #                              Pr( Evidence )\r\n+  #\r\n+  # Both of these joint probabilities can be calculated by going over every entry in\r\n+  # the global joint probability table and summing up the probabilities of those\r\n+  # entries that match what we're looking for\r\n+  \r\n+  def dict_issubset(d,sub):\r\n+    \"\"\"\r\n+    Returns True if every key,value pair in sub has a matching key and value in d\r\n+    Note: sub should not contain any entries with value None\r\n+    \"\"\"\r\n+    return all(d.get(key,None)==val for key,val in sub.items())\r\n+     \r\n+  pr_QE=0\r\n+  pr_E=0\r\n+  for jptEntry in truefalse_combination_iterator(model.vars):\r\n+    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # jptEntry will be a dictionary with a key for every variable in the model,\r\n+    #   and the loop will go over every possible combination of True/False for each variable\r\n+    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n+    #\r\n+    # Your task is to collect all the probabilities that match the evidence, and query\r\n+    #\r\n+    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n+    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n+    #\r\n+    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n+    #\r\n+    # (Reference solution is 4 lines of code.)\r\n+    if dict_issubset(jptEntry, evidence):\r\n+            # Increment the joint probability with both query variable and evidence\r\n+            pr_QE += pr_entry\r\n+\r\n+            # Check if the entry satisfies only the evidence (for denominator)\r\n+            if jptEntry[queryVar] == queryVal:\r\n+                pr_E += pr_entry\r\n+\r\n+\r\n+  return pr_QE/pr_E\r\n+\r\n+def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+  \r\n+  # First step, we need to figure out what order we will calculate terms in and where\r\n+  # marginalization needs to happen.\r\n+  #\r\n+  # That said, though this is a part of the inference process that you need to know, it's a\r\n+  # bit tricky to get working in general, especially the optimization bits.\r\n+  #\r\n+  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n+  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n+  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n+  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n+  # For example, the formula on slide 20 would be represented as:\r\n+  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n+  # The formula on slide 21 would be:\r\n+  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n+  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n+  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n+  \r\n+  # Debug: Output a nicer version of the calculation order (inference formula)\r\n+  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n+  \r\n+  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n+  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n+  \r\n+  # Next step, implement the calculation\r\n+  #\r\n+  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n+  # and move on to implement the recurse_calc_query_exact_tree() function\r\n+  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n+  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n+  # and associated function and add your own calculation code here\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n+  #\r\n+  # Normalize this result to get true probability.\r\n+  #\r\n+  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n+  #\r\n+  # Refer to the example on slide 30.\r\n+  #\r\n+  # (Reference solution is 3 lines of code.)\r\n+  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n+  \"\"\"\r\n+  Recursiving process the summation tree \r\n+  \r\n+  model,queryVar,evidence: See calc_query_exact_tree()\r\n+  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n+    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n+  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n+  \"\"\"\r\n+  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n+\r\n+  # Your overall task in the function is to assign values to:\r\n+  #   prQ_T\r\n+  #   prQ_F\r\n+  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n+  # covering both cases where query=True and query=False.\r\n+\r\n+  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n+  if marginalize:\r\n+    #Summation term, need to branch over all possible values and continue calculation\r\n+    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n+    # calculation\r\n+    #\r\n+    # You will need to recurse for each element of the summation (i.e. each branch)\r\n+    # Then properly combine the results together\r\n+    #\r\n+    # Slides 26-28 show examples of resolving summations.\r\n+    #\r\n+    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n+    #   BUT remember to change it back to the original values when you are done!\r\n+    #   (The original value for unknown variables is None.)\r\n+    #\r\n+    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n+    #   example of how to make the recursive call(s)\r\n+    #\r\n+    # (Reference solution is 7 lines of code.)\r\n+    for value in [True, False]:\r\n+      # Update the variable value for the current branch\r\n+      variableValues[var] = value\r\n+\r\n+      # Recursively calculate the next term\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+      # Combine the results for both True and False cases\r\n+      prQ_T += prR_T\r\n+      prQ_F += prR_F\r\n+\r\n+      # Reset the variable value to None for the next iteration\r\n+      variableValues[var] = None\r\n+\r\n+    # Normalize the results after processing all branches\r\n+    prQ_total = prQ_T + prQ_F\r\n+    prQ_T /= prQ_total\r\n+    prQ_F /= prQ_total\r\n+  else:\r\n+    #Probability term, calculate conditional probability for this variable and continue calculation\r\n+    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n+    if queryVar in model.varDist[var].parents:\r\n+      #Query variable is a condition for this term\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n+      #\r\n+      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n+      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n+      # consider both what happens when the query variable is True, and also when it is False.\r\n+      #\r\n+      # Copy from your code below and modify to deal with this additional element.\r\n+      #\r\n+      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 11 lines of code.)\r\n+      variableValues[var] = True\r\n+\r\n+      # Recursively calculate the next term\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+      # Combine the results for the True case\r\n+      prQ_T *= prR_T\r\n+\r\n+      # Reset the variable value to None for the next iteration\r\n+      variableValues[var] = None\r\n+\r\n+      # Update the variable value for the False case\r\n+      variableValues[var] = False\r\n+\r\n+      # Recursively calculate the next term\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+      # Combine the results for the False case\r\n+      prQ_F *= prR_F\r\n+\r\n+      # Reset the variable value to None for the next iteration\r\n+      variableValues[var] = None\r\n+    elif var==queryVar:\r\n+      #This term is probability _for_ the Query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one second! (Atleast, I recommend this.)\r\n+      #\r\n+      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n+      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n+      # is False.\r\n+      #\r\n+      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n+      # \r\n+      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 5 additional lines of code.)\r\n+      variableValues[var] = True\r\n+\r\n+      # Recursively calculate the next term\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+      # Combine the results for the True case\r\n+      prQ_T *= prR_T\r\n+\r\n+      # Reset the variable value to None for the next iteration\r\n+      variableValues[var] = None\r\n+\r\n+      # Update the variable value for the False case\r\n+      variableValues[var] = False\r\n+\r\n+      # Recursively calculate the next term\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+      # Combine the results for the False case\r\n+      prQ_F *= prR_F\r\n+\r\n+      # Reset the variable value to None for the next iteration\r\n+      variableValues[var] = None\r\n+    else:\r\n+      #Simple term, no need to worry about query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one first! (It's the simplest of the three.)\r\n+      #\r\n+      # You need to get the conditional probability for this variable and correctly\r\n+      # combine it with the results of the recursive call above.\r\n+      #\r\n+      # Don't forget that this variable's value could be True or False!\r\n+      #\r\n+      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n+      #\r\n+      # (Reference solution is 5 lines of code.)\r\n+      variableValues[var] = True\r\n+\r\n+      # Get the conditional probability for the True case\r\n+      prQ_T *= model.varDist[var].table[tuple(variableValues[parent] for parent in model.varDist[var].parents)]\r\n+\r\n+      # Reset the variable value to None for the next iteration\r\n+      variableValues[var] = None\r\n+\r\n+      # Update the variable value for the False case\r\n+      variableValues[var] = False\r\n+\r\n+      # Get the conditional probability for the False case\r\n+      prQ_F *= model.varDist[var].table[tuple(variableValues[parent] for parent in model.varDist[var].parents)]\r\n+\r\n+      # Reset the variable value to None for the next iteration\r\n+      variableValues[var] = None\r\n+\r\n+    if len(remainingCalc)>1:\r\n+      #If there are still terms left, then recurse\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n+      \r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Update prQ_T, prQ_F with the results from the recursive call.\r\n+      #\r\n+      # How do you combine _factors_ together?\r\n+      #\r\n+      # (Reference solution is 2 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n+  \r\n+##############################################################################\r\n+## Support code\r\n+def read_cpt(model,varName,condVals):\r\n+  \"\"\"\r\n+  Read conditional probability for a specified variable with provided condition (parent) values\r\n+  Note, the value returned is conditional probability for variable being True\r\n+  \r\n+  Warning: If you get an index exception and referenced key has None in it, this means\r\n+    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n+  \r\n+  model: model object, see read_model_file() for specification\r\n+  varName: string, variable name to read probability for\r\n+  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n+              (Missing conditions will cause errors, extraneous values will be ignored)\r\n+  \"\"\"\r\n+  if varName not in model.varDist:\r\n+    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n+  varDist=model.varDist[varName]\r\n+  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n+  if key not in varDist.cpt:\r\n+    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n+  return varDist.cpt[key]\r\n+\r\n+def truefalse_combination_iterator(entries):\r\n+  \"\"\"\r\n+  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n+  \"\"\"\r\n+  entries=list(entries)\r\n+  entries.reverse()\r\n+  if len(entries)>30:\r\n+    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n+  for c in range(1<<len(entries)):\r\n+    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n+\r\n+def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n+  \"\"\"\r\n+  Create represention of terms in an inference calculation such as on slides 20-21\r\n+  \r\n+  Returns a list of (boolean,string) tuples where:\r\n+    (True,variable) represents a summation term where a variable needs to be marginalized\r\n+    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n+  \"\"\"\r\n+  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Naive solution\r\n+  #\r\n+  # model.varsDep already has variables in order of dependency...\r\n+  # So take that and insert summation terms any time we encounter a new hidden variable\r\n+  #\r\n+  # Downside is little optimization, likely to have many unnecessary terms\r\n+  if False:\r\n+    hiddenLeft=set(hiddenVars)\r\n+    seq=[]\r\n+    for v in model.varsDep:\r\n+      #Check if factor variable is a (unhandled) hidden variable\r\n+      if v in hiddenLeft:\r\n+        seq.append( (True,v) ) #If so, trigger a marginalization\r\n+        hiddenLeft.remove(v)   #And mark it as handled\r\n+      for p in model.varDist[v].parents:\r\n+        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n+        if p in hiddenLeft:\r\n+          seq.append( (True,p) )\r\n+          hiddenLeft.remove(p)\r\n+      seq.append( (False,v) ) #Then process the factor itself\r\n+    assert(len(hiddenLeft)==0)\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Arbitrary ordering\r\n+  #\r\n+  # What if we wanted to handle hidden variables in an arbitrary order?\r\n+  #\r\n+  # Possible, but we'll have to be careful where we put factors, after\r\n+  # all their dependencies are satisfied.\r\n+  def seq_from_hid_order(hOrd):\r\n+    #The trick to make this work is to first assign every\r\n+    #hidden variable a priority based on the order\r\n+    prio={h:i for i,h in enumerate(hOrd)}\r\n+    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n+    #Then rate each factor on the highest priority amongst its dependencies\r\n+    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n+    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n+    vOrd.sort()\r\n+    #All that's left is to turn it into the expected sequence format\r\n+    return list( (not nm,v) for _,nm,v in vOrd )\r\n+  \r\n+  #--------------------------------------------------------\r\n+  # Brute force best\r\n+  #\r\n+  # Now, where to get an ordering to use the above?\r\n+  #\r\n+  # We could brute force try every possible ordering...\r\n+  if True:\r\n+    bestSeq=None\r\n+    bestSeqCost=sys.maxsize\r\n+    for hOrd in permutations(hiddenVars):\r\n+      tSeq=seq_from_hid_order(hOrd)\r\n+      #Note, really should do below norm optimization here too\r\n+      \r\n+      #Now the tricky bit is to rate each ordering\r\n+      #We'll do it by doubling the cost of each factor every time\r\n+      #We cross a summation\r\n+      tot=0\r\n+      ct=1\r\n+      for m,v in tSeq:\r\n+        if m:\r\n+          ct*=2\r\n+        else:\r\n+          tot+=ct\r\n+      \r\n+      if tot<bestSeqCost:\r\n+        bestSeq=tSeq\r\n+        bestSeqCost=tot\r\n+    seq=bestSeq\r\n+  # But this will be very expensive for large models\r\n+  #--------------------------------------------------------\r\n+  # Greedy\r\n+  #\r\n+  # Alternately, we could apply a greedy approach.\r\n+  #\r\n+  # Some how rate each hidden variable on how expensive we think\r\n+  # it is, then put the most expensive ones earliest\r\n+  # ***TODO***\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Simple normalization optimization\r\n+  #\r\n+  # One thing we learned is that for a multiplicative term,\r\n+  # if it doesn't mention the query variable, then it's a\r\n+  # constant and can be handled via normalization (folded into alpha)\r\n+  #\r\n+  # This is non-trivial to detect for summation terms, but we\r\n+  # can easily do it for factors outside of any summation...\r\n+  if True:\r\n+    i=0\r\n+    while i<len(seq):\r\n+      m,v=seq[i]\r\n+      if m:\r\n+        break #Found first summation, quit\r\n+      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n+        #No mention of query variable, remove\r\n+        del seq[i]\r\n+      else:\r\n+        i+=1\r\n+  \r\n+  return seq\r\n+\r\n+def calc_query_approx(model,queryVar,queryVal,evidence):\r\n+  raise NotImplementedError()\r\n+\r\n+def generate_joint_prob_table(model):\r\n+  \"\"\"\r\n+  Output a joint probability table for the provided model\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  table=[]\r\n+  row=list(model.vars)\r\n+  row.append('Joint Pr')\r\n+  table.append(row)\r\n+  for varVals in truefalse_combination_iterator(model.vars):\r\n+    pr=calc_global_joint_prob(model,varVals)\r\n+    row=[varVals[x] for x in model.vars]\r\n+    row.append(pr)\r\n+    table.append(row)\r\n+  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+  return\r\n+\r\n+def read_model_file(filename):\r\n+  \"\"\"\r\n+  Returns model object with the following elements:\r\n+    vars : list of strings\r\n+      The list of variables the model describes\r\n+      In alphabetical order\r\n+    varsDep : list of strings\r\n+      Same contents as 'vars' but in dependency order (parents come before children)\r\n+    varDist : dict of objects\r\n+      Distribution information for each variable\r\n+      Dictionary key is variable name\r\n+      Object has the following elements:\r\n+        parents : set of strings\r\n+        children : set of strings\r\n+        cpt : dict of numbers\r\n+          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n+          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n+            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n+  Model file format is as follows:\r\n+    Basic file format is Comma-Separated Value (.csv)\r\n+    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n+    Tables are separated by atleast one empty line\r\n+    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n+    Each table:\r\n+      Starts with a header row containing variable names\r\n+        The last name is the variable whose cond probability is being described\r\n+        Any preceding names are considered to be parent variables\r\n+      Following rows contain True/False values for each parent and probability for main variable being true\r\n+      Any missing parent value combinations will be assumed to be probability 0.5\r\n+    Only Bernoulli/Boolean variables can be represented in this file format\r\n+  \"\"\"\r\n+  class ModelObj:\r\n+    def __init__(self):\r\n+      self.vars=[]\r\n+      self.varsDep=None\r\n+      self.varDist={}\r\n+\r\n+  class VarObj:\r\n+    def __init__(self, parents, children, cpt):\r\n+      self.parents = parents\r\n+      self.children = children\r\n+      self.cpt = cpt\r\n+\r\n+  model=ModelObj()\r\n+  #--------------------------------------------------------\r\n+  #Read data from file\r\n+  with open(filename, newline='') as csvfile:\r\n+    csvreader = csv.reader(csvfile)\r\n+    \r\n+    rowNum=0\r\n+    var=None\r\n+    varIdx=None\r\n+    parents=None\r\n+    cpt=None\r\n+    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n+      rowNum+=1\r\n+      srow=''.join(row).strip()\r\n+      if srow.startswith('#'):\r\n+        continue #Comment line, skip\r\n+      if len(srow)==0:\r\n+        #Empty line\r\n+        if var is not None:\r\n+          #End current table\r\n+          model.vars.append(var)\r\n+          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n+          #Wait for new table\r\n+          var=None\r\n+          varIdx=None\r\n+          parents=None\r\n+          cpt=None\r\n+      elif var is None:\r\n+        #Start new table\r\n+        if len(row)>1:\r\n+          parents=row[0:-1]\r\n+        else:\r\n+          parents=[]\r\n+        varIdx=len(row)-1\r\n+        var=row[varIdx]\r\n+        cpt={}\r\n+      else:\r\n+        #Add new entry to table\r\n+        if len(row)<varIdx+1:\r\n+          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n+        if len(parents)>0:\r\n+          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n+        else:\r\n+          key=frozenset()\r\n+        cpt[key]=float(row[-1])\r\n+  model.vars.sort()\r\n+  #--------------------------------------------------------\r\n+  # Check distributions for missing entries\r\n+  vCheck=frozenset(model.vars)\r\n+  for var in model.vars: #Make sure every mentioned variable has an entry\r\n+    for p in model.varDist[var].parents:\r\n+      if p not in vCheck:\r\n+        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n+  for var in model.vars: #Check every cpt for missing rows\r\n+    varDist=model.varDist[var]\r\n+    missingCnt=0\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      key=frozenset(((x,v) for x,v in varVals.items()))\r\n+      if key not in varDist.cpt:\r\n+        missingCnt+=1\r\n+        varDist.cpt[key]=0.5\r\n+    if missingCnt>0:\r\n+      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n+  #--------------------------------------------------------\r\n+  # Create children entries\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=set()\r\n+  for var in model.vars:\r\n+    for p in model.varDist[var].parents:\r\n+      model.varDist[p].children.add(var)\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n+  #--------------------------------------------------------\r\n+  # Create dependency ordering\r\n+  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n+  idx=0\r\n+  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n+  while idx<len(varsDep):\r\n+    var=varsDep[idx]\r\n+    for c in model.varDist[var].children:\r\n+      parentsLeft[c]-=1\r\n+      if parentsLeft[c]==0:\r\n+        #All parents have been visited, so dependencies of this child are met\r\n+        varsDep.append(c)\r\n+      elif parentsLeft[c]<0:\r\n+        #Repeat visit to a parent can only happen if a cycle exists\r\n+        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n+    idx+=1\r\n+  model.varsDep=varsDep\r\n+  #--------------------------------------------------------\r\n+  return model\r\n+\r\n+def print_model(model):\r\n+  \"\"\"\r\n+  Print a model object back out in pretty form\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  for v in model.vars:\r\n+    varDist=model.varDist[v]\r\n+    print('--------------------------------------------------')\r\n+    print('Variable:',v)\r\n+    print('--------------------------------------------------')\r\n+    print('Children:',', '.join(varDist.children))\r\n+    \r\n+    table=[]\r\n+    row=list(varDist.parents)\r\n+    row.append('P({0}=T|...)'.format(v))\r\n+    table.append(row)\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      pr=read_cpt(model,v,varVals)\r\n+      row=[varVals[x] for x in varDist.parents]\r\n+      row.append(pr)\r\n+      table.append(row)\r\n+    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+    print(\"\")\r\n+    \r\n+##############################################################################\r\n+## Main functions\r\n+def main(args):\r\n+  global DEBUG_OUTPUT\r\n+  if args.debug:\r\n+    DEBUG_OUTPUT=1\r\n+  #Argument checking plus additional parsing\r\n+  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in table mode')\r\n+  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in print mode')\r\n+  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n+    error('Argument --query required in inference modes')\r\n+  elif args.query is not None:\r\n+    if '=' not in args.query:\r\n+      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n+    s=args.query.split('=')\r\n+    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n+  if args.evidence is None:\r\n+    args.evidence=[]\r\n+  else:\r\n+    ev=[]\r\n+    for e in args.evidence:\r\n+      if '=' not in e:\r\n+        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n+      s=e.split('=')\r\n+      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n+    args.evidence={ var:val for var,val in ev }\r\n+\r\n+  print('Reading model from',args.model)\r\n+  model=read_model_file(args.model)\r\n+\r\n+  if args.mode=='table':\r\n+    generate_joint_prob_table(model)\r\n+  elif args.mode=='print':\r\n+    print_model(model)\r\n+  else:\r\n+    #One of the inference modes\r\n+    #Check inputs against model\r\n+    if args.query[0] not in model.vars:\r\n+      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n+    for var,val in args.evidence.items():\r\n+      if var not in model.vars:\r\n+        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n+    #Output problem setup\r\n+    print(\"Inference mode:\",args.mode)\r\n+    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n+    if len(args.evidence)==0:\r\n+      print(\"No evidence\")\r\n+    else:\r\n+      print(\"Evidence:\")\r\n+      for var,val in args.evidence.items():\r\n+        print(\"  '{0}' is {1}\".format(var,val))\r\n+\r\n+    #Run inference\r\n+    pr=None\r\n+    if args.mode=='brute':\r\n+      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n+    elif args.mode=='tree':\r\n+      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n+    else: #args.mode=='approx'\r\n+      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n+    print('Probability is',pr)\r\n+\r\n+  return\r\n+\r\n+def error(msg):\r\n+  print(msg)\r\n+  sys.exit(1)\r\n+  return\r\n+\r\n+if __name__ == '__main__':\r\n+  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n+  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n+  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n+  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n+  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n+  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n+  args = parser.parse_args()\r\n+  error=lambda msg : parser.error(msg)\r\n+  main(args)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1699510068637,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -160,10 +160,15 @@\n   #\r\n   # Refer to the example on slide 30.\r\n   #\r\n   # (Reference solution is 3 lines of code.)\r\n-  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+  prQ_total = prQ_T + prQ_F\r\n+  prQ_T /= prQ_total\r\n+  prQ_F /= prQ_total\r\n \r\n+  # Return the probability that answers the query (i.e., queryVal could be True or False)\r\n+  return prQ_T if queryVal else prQ_F\r\n+\r\n def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n   \"\"\"\r\n   Recursiving process the summation tree \r\n   \r\n@@ -761,733 +766,5 @@\n   parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n   parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n   args = parser.parse_args()\r\n   error=lambda msg : parser.error(msg)\r\n-  main(args)\n-import argparse\r\n-import csv\r\n-from itertools import chain, permutations\r\n-import math\r\n-#import matplotlib.pyplot as plt\r\n-#import numpy as np\r\n-from random import random\r\n-import sys\r\n-\r\n-DEBUG_OUTPUT=0\r\n-\r\n-##############################################################################\r\n-## Student code\r\n-def calc_global_joint_prob(model, variableValues):\r\n-  \"\"\"\r\n-  Calculate the global joint probability of a model for a specific set of values\r\n-  model: model object, see read_model_file() for specification\r\n-  variableValues: dictionary of boolean values, keys are variable names\r\n-  \"\"\"\r\n-  \r\n-  # YOUR CODE HERE\r\n-  #\r\n-  # You may assume variableValues is complete, i.e containes all variables in the model\r\n-  #   Thus, no marginalization is necessary\r\n-  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n-  #\r\n-  # You can find a complete descrition of the model object in the documentation of\r\n-  #   the read_model_file() function, BUT\r\n-  # All you will need is the list of variables: model.vars\r\n-  #\r\n-  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n-  #\r\n-  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n-  #\r\n-  # (Reference solution is 7 lines of code.)\r\n-  joint_prob = 1.0\r\n-\r\n-  for var in model.vars:\r\n-      parents = model.varDist[var].parents\r\n-      cond_vals = {parent: variableValues[parent] for parent in parents}\r\n-      cpt_entry = read_cpt(model, var, cond_vals)\r\n-\r\n-      if variableValues[var]:\r\n-          joint_prob *= cpt_entry\r\n-      else:\r\n-          joint_prob *= 1 - cpt_entry\r\n-\r\n-  return joint_prob\r\n-\r\n-def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n-  \"\"\"\r\n-  Calculate posterior probability for a given variable\r\n-\r\n-  model: model object, see read_model_file() for specification\r\n-  queryVar: string, query variable name\r\n-  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n-  evidence: dictionary of boolean values, where keys are evidence variable names\r\n-            (Any variable not listed as query or evidence is assumed to be hidden)\r\n-  \"\"\"\r\n-\r\n-  # This first attempt at probabilistic inference will use the brute-force (table)\r\n-  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n-  #\r\n-  # This requires the calculation of two joint probabilities based on the definition\r\n-  # of conditional probability:\r\n-  #                          Pr( Query & Evidence )\r\n-  #   Pr(Query | Evidence) = ----------------------\r\n-  #                              Pr( Evidence )\r\n-  #\r\n-  # Both of these joint probabilities can be calculated by going over every entry in\r\n-  # the global joint probability table and summing up the probabilities of those\r\n-  # entries that match what we're looking for\r\n-  \r\n-  def dict_issubset(d,sub):\r\n-    \"\"\"\r\n-    Returns True if every key,value pair in sub has a matching key and value in d\r\n-    Note: sub should not contain any entries with value None\r\n-    \"\"\"\r\n-    return all(d.get(key,None)==val for key,val in sub.items())\r\n-     \r\n-  pr_QE=0\r\n-  pr_E=0\r\n-  for jptEntry in truefalse_combination_iterator(model.vars):\r\n-    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n-\r\n-    # YOUR CODE HERE\r\n-    #\r\n-    # jptEntry will be a dictionary with a key for every variable in the model,\r\n-    #   and the loop will go over every possible combination of True/False for each variable\r\n-    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n-    #\r\n-    # Your task is to collect all the probabilities that match the evidence, and query\r\n-    #\r\n-    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n-    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n-    #\r\n-    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n-    #\r\n-    # (Reference solution is 4 lines of code.)\r\n-    if dict_issubset(jptEntry, evidence):\r\n-            # Increment the joint probability with both query variable and evidence\r\n-            pr_QE += pr_entry\r\n-\r\n-            # Check if the entry satisfies only the evidence (for denominator)\r\n-            if jptEntry[queryVar] == queryVal:\r\n-                pr_E += pr_entry\r\n-\r\n-\r\n-  return pr_QE/pr_E\r\n-\r\n-def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n-  \"\"\"\r\n-  Calculate posterior probability for a given variable\r\n-\r\n-  model: model object, see read_model_file() for specification\r\n-  queryVar: string, query variable name\r\n-  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n-  evidence: dictionary of boolean values, where keys are evidence variable names\r\n-            (Any variable not listed as query or evidence is assumed to be hidden)\r\n-  \"\"\"\r\n-  \r\n-  # First step, we need to figure out what order we will calculate terms in and where\r\n-  # marginalization needs to happen.\r\n-  #\r\n-  # That said, though this is a part of the inference process that you need to know, it's a\r\n-  # bit tricky to get working in general, especially the optimization bits.\r\n-  #\r\n-  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n-  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n-  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n-  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n-  # For example, the formula on slide 20 would be represented as:\r\n-  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n-  # The formula on slide 21 would be:\r\n-  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n-  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n-  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n-  \r\n-  # Debug: Output a nicer version of the calculation order (inference formula)\r\n-  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n-  \r\n-  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n-  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n-  \r\n-  # Next step, implement the calculation\r\n-  #\r\n-  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n-  # and move on to implement the recurse_calc_query_exact_tree() function\r\n-  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n-  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n-  # and associated function and add your own calculation code here\r\n-  \r\n-  # YOUR CODE HERE\r\n-  #\r\n-  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n-  #\r\n-  # Normalize this result to get true probability.\r\n-  #\r\n-  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n-  #\r\n-  # Refer to the example on slide 30.\r\n-  #\r\n-  # (Reference solution is 3 lines of code.)\r\n-  prQ_total = prQ_T + prQ_F\r\n-  prQ_T /= prQ_total\r\n-  prQ_F /= prQ_total\r\n-\r\n-  # Return the probability based on the query value\r\n-  return prQ_T if queryVal else prQ_F\r\n-\r\n-def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n-  \"\"\"\r\n-  Recursiving process the summation tree \r\n-  \r\n-  model,queryVar,evidence: See calc_query_exact_tree()\r\n-  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n-    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n-  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n-  \"\"\"\r\n-  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n-\r\n-  # Your overall task in the function is to assign values to:\r\n-  #   prQ_T\r\n-  #   prQ_F\r\n-  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n-  # covering both cases where query=True and query=False.\r\n-\r\n-  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n-  if marginalize:\r\n-    #Summation term, need to branch over all possible values and continue calculation\r\n-    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n-\r\n-    # YOUR CODE HERE\r\n-    #\r\n-    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n-    # calculation\r\n-    #\r\n-    # You will need to recurse for each element of the summation (i.e. each branch)\r\n-    # Then properly combine the results together\r\n-    #\r\n-    # Slides 26-28 show examples of resolving summations.\r\n-    #\r\n-    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n-    #   BUT remember to change it back to the original values when you are done!\r\n-    #   (The original value for unknown variables is None.)\r\n-    #\r\n-    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n-    #   example of how to make the recursive call(s)\r\n-    #\r\n-    # (Reference solution is 7 lines of code.)\r\n-    variableValues_copy = variableValues.copy()  # Make a copy to handle both cases\r\n-    variableValues_copy[var] = True\r\n-    prQ_T_true, _ = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues_copy, remainingCalc)\r\n-\r\n-    variableValues_copy[var] = False\r\n-    _, prQ_F_false = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues_copy, remainingCalc)\r\n-\r\n-    # Combine the results for both cases\r\n-    prQ_T = prQ_T_true\r\n-    prQ_F = prQ_F_false\r\n-  else:\r\n-    #Probability term, calculate conditional probability for this variable and continue calculation\r\n-    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n-    if queryVar in model.varDist[var].parents:\r\n-      #Query variable is a condition for this term\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n-      #\r\n-      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n-      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n-      # consider both what happens when the query variable is True, and also when it is False.\r\n-      #\r\n-      # Copy from your code below and modify to deal with this additional element.\r\n-      #\r\n-      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n-      #\r\n-      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n-      #   BUT remember to change it back to the original values when you are done!\r\n-      #\r\n-      # (Reference solution is 11 lines of code.)\r\n-      variableValues_copy_true = variableValues.copy()  # Make a copy to handle both cases\r\n-      variableValues_copy_true[var] = True\r\n-      prQ_T_true, _ = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues_copy_true, remainingCalc)\r\n-\r\n-      variableValues_copy_false = variableValues.copy()  # Make a copy to handle both cases\r\n-      variableValues_copy_false[var] = False\r\n-      _, prQ_F_false = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues_copy_false, remainingCalc)\r\n-\r\n-        # Combine the results for both cases\r\n-      prQ_T *= prQ_T_true\r\n-      prQ_F *= prQ_F_false\r\n-    elif var==queryVar:\r\n-      #This term is probability _for_ the Query variable\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one second! (Atleast, I recommend this.)\r\n-      #\r\n-      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n-      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n-      # is False.\r\n-      #\r\n-      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n-      # \r\n-      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n-      #\r\n-      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n-      #   BUT remember to change it back to the original values when you are done!\r\n-      #\r\n-      # (Reference solution is 5 additional lines of code.)\r\n-      variableValues_copy = variableValues.copy()  # Make a copy to handle both cases\r\n-      variableValues_copy[var] = True\r\n-      prQ_T = model.varDist[var].P(**variableValues_copy)\r\n-\r\n-      variableValues_copy[var] = False\r\n-      prQ_F = model.varDist[var].P(**variableValues_copy)\r\n-    else:\r\n-      #Simple term, no need to worry about query variable\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one first! (It's the simplest of the three.)\r\n-      #\r\n-      # You need to get the conditional probability for this variable and correctly\r\n-      # combine it with the results of the recursive call above.\r\n-      #\r\n-      # Don't forget that this variable's value could be True or False!\r\n-      #\r\n-      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n-      #\r\n-      # (Reference solution is 5 lines of code.)\r\n-      pr_var_true = model.varDist[var].P(**variableValues, **{var: True})\r\n-      pr_var_false = model.varDist[var].P(**variableValues, **{var: False})\r\n-\r\n-      # Combine it with the results of the recursive call above\r\n-      prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n-\r\n-      # Update prQ_T, prQ_F with the results from the recursive call\r\n-      prQ_T = pr_var_true * prR_T\r\n-      prQ_F = pr_var_false * prR_F\r\n-\r\n-    if len(remainingCalc)>1:\r\n-      #If there are still terms left, then recurse\r\n-      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n-      \r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Update prQ_T, prQ_F with the results from the recursive call.\r\n-      #\r\n-      # How do you combine _factors_ together?\r\n-      #\r\n-      # (Reference solution is 2 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n-  \r\n-##############################################################################\r\n-## Support code\r\n-def read_cpt(model,varName,condVals):\r\n-  \"\"\"\r\n-  Read conditional probability for a specified variable with provided condition (parent) values\r\n-  Note, the value returned is conditional probability for variable being True\r\n-  \r\n-  Warning: If you get an index exception and referenced key has None in it, this means\r\n-    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n-  \r\n-  model: model object, see read_model_file() for specification\r\n-  varName: string, variable name to read probability for\r\n-  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n-              (Missing conditions will cause errors, extraneous values will be ignored)\r\n-  \"\"\"\r\n-  if varName not in model.varDist:\r\n-    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n-  varDist=model.varDist[varName]\r\n-  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n-  if key not in varDist.cpt:\r\n-    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n-  return varDist.cpt[key]\r\n-\r\n-def truefalse_combination_iterator(entries):\r\n-  \"\"\"\r\n-  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n-  \"\"\"\r\n-  entries=list(entries)\r\n-  entries.reverse()\r\n-  if len(entries)>30:\r\n-    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n-  for c in range(1<<len(entries)):\r\n-    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n-\r\n-def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n-  \"\"\"\r\n-  Create represention of terms in an inference calculation such as on slides 20-21\r\n-  \r\n-  Returns a list of (boolean,string) tuples where:\r\n-    (True,variable) represents a summation term where a variable needs to be marginalized\r\n-    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n-  \"\"\"\r\n-  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Naive solution\r\n-  #\r\n-  # model.varsDep already has variables in order of dependency...\r\n-  # So take that and insert summation terms any time we encounter a new hidden variable\r\n-  #\r\n-  # Downside is little optimization, likely to have many unnecessary terms\r\n-  if False:\r\n-    hiddenLeft=set(hiddenVars)\r\n-    seq=[]\r\n-    for v in model.varsDep:\r\n-      #Check if factor variable is a (unhandled) hidden variable\r\n-      if v in hiddenLeft:\r\n-        seq.append( (True,v) ) #If so, trigger a marginalization\r\n-        hiddenLeft.remove(v)   #And mark it as handled\r\n-      for p in model.varDist[v].parents:\r\n-        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n-        if p in hiddenLeft:\r\n-          seq.append( (True,p) )\r\n-          hiddenLeft.remove(p)\r\n-      seq.append( (False,v) ) #Then process the factor itself\r\n-    assert(len(hiddenLeft)==0)\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Arbitrary ordering\r\n-  #\r\n-  # What if we wanted to handle hidden variables in an arbitrary order?\r\n-  #\r\n-  # Possible, but we'll have to be careful where we put factors, after\r\n-  # all their dependencies are satisfied.\r\n-  def seq_from_hid_order(hOrd):\r\n-    #The trick to make this work is to first assign every\r\n-    #hidden variable a priority based on the order\r\n-    prio={h:i for i,h in enumerate(hOrd)}\r\n-    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n-    #Then rate each factor on the highest priority amongst its dependencies\r\n-    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n-    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n-    vOrd.sort()\r\n-    #All that's left is to turn it into the expected sequence format\r\n-    return list( (not nm,v) for _,nm,v in vOrd )\r\n-  \r\n-  #--------------------------------------------------------\r\n-  # Brute force best\r\n-  #\r\n-  # Now, where to get an ordering to use the above?\r\n-  #\r\n-  # We could brute force try every possible ordering...\r\n-  if True:\r\n-    bestSeq=None\r\n-    bestSeqCost=sys.maxsize\r\n-    for hOrd in permutations(hiddenVars):\r\n-      tSeq=seq_from_hid_order(hOrd)\r\n-      #Note, really should do below norm optimization here too\r\n-      \r\n-      #Now the tricky bit is to rate each ordering\r\n-      #We'll do it by doubling the cost of each factor every time\r\n-      #We cross a summation\r\n-      tot=0\r\n-      ct=1\r\n-      for m,v in tSeq:\r\n-        if m:\r\n-          ct*=2\r\n-        else:\r\n-          tot+=ct\r\n-      \r\n-      if tot<bestSeqCost:\r\n-        bestSeq=tSeq\r\n-        bestSeqCost=tot\r\n-    seq=bestSeq\r\n-  # But this will be very expensive for large models\r\n-  #--------------------------------------------------------\r\n-  # Greedy\r\n-  #\r\n-  # Alternately, we could apply a greedy approach.\r\n-  #\r\n-  # Some how rate each hidden variable on how expensive we think\r\n-  # it is, then put the most expensive ones earliest\r\n-  # ***TODO***\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Simple normalization optimization\r\n-  #\r\n-  # One thing we learned is that for a multiplicative term,\r\n-  # if it doesn't mention the query variable, then it's a\r\n-  # constant and can be handled via normalization (folded into alpha)\r\n-  #\r\n-  # This is non-trivial to detect for summation terms, but we\r\n-  # can easily do it for factors outside of any summation...\r\n-  if True:\r\n-    i=0\r\n-    while i<len(seq):\r\n-      m,v=seq[i]\r\n-      if m:\r\n-        break #Found first summation, quit\r\n-      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n-        #No mention of query variable, remove\r\n-        del seq[i]\r\n-      else:\r\n-        i+=1\r\n-  \r\n-  return seq\r\n-\r\n-def calc_query_approx(model,queryVar,queryVal,evidence):\r\n-  raise NotImplementedError()\r\n-\r\n-def generate_joint_prob_table(model):\r\n-  \"\"\"\r\n-  Output a joint probability table for the provided model\r\n-  \"\"\"\r\n-  from tabulate import tabulate\r\n-  table=[]\r\n-  row=list(model.vars)\r\n-  row.append('Joint Pr')\r\n-  table.append(row)\r\n-  for varVals in truefalse_combination_iterator(model.vars):\r\n-    pr=calc_global_joint_prob(model,varVals)\r\n-    row=[varVals[x] for x in model.vars]\r\n-    row.append(pr)\r\n-    table.append(row)\r\n-  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n-  return\r\n-\r\n-def read_model_file(filename):\r\n-  \"\"\"\r\n-  Returns model object with the following elements:\r\n-    vars : list of strings\r\n-      The list of variables the model describes\r\n-      In alphabetical order\r\n-    varsDep : list of strings\r\n-      Same contents as 'vars' but in dependency order (parents come before children)\r\n-    varDist : dict of objects\r\n-      Distribution information for each variable\r\n-      Dictionary key is variable name\r\n-      Object has the following elements:\r\n-        parents : set of strings\r\n-        children : set of strings\r\n-        cpt : dict of numbers\r\n-          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n-          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n-            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n-  Model file format is as follows:\r\n-    Basic file format is Comma-Separated Value (.csv)\r\n-    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n-    Tables are separated by atleast one empty line\r\n-    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n-    Each table:\r\n-      Starts with a header row containing variable names\r\n-        The last name is the variable whose cond probability is being described\r\n-        Any preceding names are considered to be parent variables\r\n-      Following rows contain True/False values for each parent and probability for main variable being true\r\n-      Any missing parent value combinations will be assumed to be probability 0.5\r\n-    Only Bernoulli/Boolean variables can be represented in this file format\r\n-  \"\"\"\r\n-  class ModelObj:\r\n-    def __init__(self):\r\n-      self.vars=[]\r\n-      self.varsDep=None\r\n-      self.varDist={}\r\n-\r\n-  class VarObj:\r\n-    def __init__(self, parents, children, cpt):\r\n-      self.parents = parents\r\n-      self.children = children\r\n-      self.cpt = cpt\r\n-\r\n-  model=ModelObj()\r\n-  #--------------------------------------------------------\r\n-  #Read data from file\r\n-  with open(filename, newline='') as csvfile:\r\n-    csvreader = csv.reader(csvfile)\r\n-    \r\n-    rowNum=0\r\n-    var=None\r\n-    varIdx=None\r\n-    parents=None\r\n-    cpt=None\r\n-    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n-      rowNum+=1\r\n-      srow=''.join(row).strip()\r\n-      if srow.startswith('#'):\r\n-        continue #Comment line, skip\r\n-      if len(srow)==0:\r\n-        #Empty line\r\n-        if var is not None:\r\n-          #End current table\r\n-          model.vars.append(var)\r\n-          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n-          #Wait for new table\r\n-          var=None\r\n-          varIdx=None\r\n-          parents=None\r\n-          cpt=None\r\n-      elif var is None:\r\n-        #Start new table\r\n-        if len(row)>1:\r\n-          parents=row[0:-1]\r\n-        else:\r\n-          parents=[]\r\n-        varIdx=len(row)-1\r\n-        var=row[varIdx]\r\n-        cpt={}\r\n-      else:\r\n-        #Add new entry to table\r\n-        if len(row)<varIdx+1:\r\n-          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n-        if len(parents)>0:\r\n-          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n-        else:\r\n-          key=frozenset()\r\n-        cpt[key]=float(row[-1])\r\n-  model.vars.sort()\r\n-  #--------------------------------------------------------\r\n-  # Check distributions for missing entries\r\n-  vCheck=frozenset(model.vars)\r\n-  for var in model.vars: #Make sure every mentioned variable has an entry\r\n-    for p in model.varDist[var].parents:\r\n-      if p not in vCheck:\r\n-        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n-  for var in model.vars: #Check every cpt for missing rows\r\n-    varDist=model.varDist[var]\r\n-    missingCnt=0\r\n-    for varVals in truefalse_combination_iterator(varDist.parents):\r\n-      key=frozenset(((x,v) for x,v in varVals.items()))\r\n-      if key not in varDist.cpt:\r\n-        missingCnt+=1\r\n-        varDist.cpt[key]=0.5\r\n-    if missingCnt>0:\r\n-      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n-  #--------------------------------------------------------\r\n-  # Create children entries\r\n-  for var in model.vars:\r\n-    model.varDist[var].children=set()\r\n-  for var in model.vars:\r\n-    for p in model.varDist[var].parents:\r\n-      model.varDist[p].children.add(var)\r\n-  for var in model.vars:\r\n-    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n-  #--------------------------------------------------------\r\n-  # Create dependency ordering\r\n-  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n-  idx=0\r\n-  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n-  while idx<len(varsDep):\r\n-    var=varsDep[idx]\r\n-    for c in model.varDist[var].children:\r\n-      parentsLeft[c]-=1\r\n-      if parentsLeft[c]==0:\r\n-        #All parents have been visited, so dependencies of this child are met\r\n-        varsDep.append(c)\r\n-      elif parentsLeft[c]<0:\r\n-        #Repeat visit to a parent can only happen if a cycle exists\r\n-        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n-    idx+=1\r\n-  model.varsDep=varsDep\r\n-  #--------------------------------------------------------\r\n-  return model\r\n-\r\n-def print_model(model):\r\n-  \"\"\"\r\n-  Print a model object back out in pretty form\r\n-  \"\"\"\r\n-  from tabulate import tabulate\r\n-  for v in model.vars:\r\n-    varDist=model.varDist[v]\r\n-    print('--------------------------------------------------')\r\n-    print('Variable:',v)\r\n-    print('--------------------------------------------------')\r\n-    print('Children:',', '.join(varDist.children))\r\n-    \r\n-    table=[]\r\n-    row=list(varDist.parents)\r\n-    row.append('P({0}=T|...)'.format(v))\r\n-    table.append(row)\r\n-    for varVals in truefalse_combination_iterator(varDist.parents):\r\n-      pr=read_cpt(model,v,varVals)\r\n-      row=[varVals[x] for x in varDist.parents]\r\n-      row.append(pr)\r\n-      table.append(row)\r\n-    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n-    print(\"\")\r\n-    \r\n-##############################################################################\r\n-## Main functions\r\n-def main(args):\r\n-  global DEBUG_OUTPUT\r\n-  if args.debug:\r\n-    DEBUG_OUTPUT=1\r\n-  #Argument checking plus additional parsing\r\n-  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n-    error('Arguments --query and --evidence not allowed in table mode')\r\n-  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n-    error('Arguments --query and --evidence not allowed in print mode')\r\n-  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n-    error('Argument --query required in inference modes')\r\n-  elif args.query is not None:\r\n-    if '=' not in args.query:\r\n-      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n-    s=args.query.split('=')\r\n-    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n-  if args.evidence is None:\r\n-    args.evidence=[]\r\n-  else:\r\n-    ev=[]\r\n-    for e in args.evidence:\r\n-      if '=' not in e:\r\n-        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n-      s=e.split('=')\r\n-      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n-    args.evidence={ var:val for var,val in ev }\r\n-\r\n-  print('Reading model from',args.model)\r\n-  model=read_model_file(args.model)\r\n-\r\n-  if args.mode=='table':\r\n-    generate_joint_prob_table(model)\r\n-  elif args.mode=='print':\r\n-    print_model(model)\r\n-  else:\r\n-    #One of the inference modes\r\n-    #Check inputs against model\r\n-    if args.query[0] not in model.vars:\r\n-      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n-    for var,val in args.evidence.items():\r\n-      if var not in model.vars:\r\n-        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n-    #Output problem setup\r\n-    print(\"Inference mode:\",args.mode)\r\n-    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n-    if len(args.evidence)==0:\r\n-      print(\"No evidence\")\r\n-    else:\r\n-      print(\"Evidence:\")\r\n-      for var,val in args.evidence.items():\r\n-        print(\"  '{0}' is {1}\".format(var,val))\r\n-\r\n-    #Run inference\r\n-    pr=None\r\n-    if args.mode=='brute':\r\n-      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n-    elif args.mode=='tree':\r\n-      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n-    else: #args.mode=='approx'\r\n-      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n-    print('Probability is',pr)\r\n-\r\n-  return\r\n-\r\n-def error(msg):\r\n-  print(msg)\r\n-  sys.exit(1)\r\n-  return\r\n-\r\n-if __name__ == '__main__':\r\n-  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n-  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n-  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n-  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n-  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n-  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n-  args = parser.parse_args()\r\n-  error=lambda msg : parser.error(msg)\r\n   main(args)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1699510114049,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -160,15 +160,10 @@\n   #\r\n   # Refer to the example on slide 30.\r\n   #\r\n   # (Reference solution is 3 lines of code.)\r\n-  prQ_total = prQ_T + prQ_F\r\n-  prQ_T /= prQ_total\r\n-  prQ_F /= prQ_total\r\n+  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n \r\n-  # Return the probability that answers the query (i.e., queryVal could be True or False)\r\n-  return prQ_T if queryVal else prQ_F\r\n-\r\n def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n   \"\"\"\r\n   Recursiving process the summation tree \r\n   \r\n@@ -207,26 +202,9 @@\n     # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n     #   example of how to make the recursive call(s)\r\n     #\r\n     # (Reference solution is 7 lines of code.)\r\n-    for value in [True, False]:\r\n-      # Update the variable value for the current branch\r\n-      variableValues[var] = value\r\n-\r\n-      # Recursively calculate the next term\r\n-      prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n-\r\n-      # Combine the results for both True and False cases\r\n-      prQ_T += prR_T\r\n-      prQ_F += prR_F\r\n-\r\n-      # Reset the variable value to None for the next iteration\r\n-      variableValues[var] = None\r\n-\r\n-    # Normalize the results after processing all branches\r\n-    prQ_total = prQ_T + prQ_F\r\n-    prQ_T /= prQ_total\r\n-    prQ_F /= prQ_total\r\n+    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n   else:\r\n     #Probability term, calculate conditional probability for this variable and continue calculation\r\n     prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n     if queryVar in model.varDist[var].parents:\r\n@@ -248,30 +226,9 @@\n       # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n       #   BUT remember to change it back to the original values when you are done!\r\n       #\r\n       # (Reference solution is 11 lines of code.)\r\n-      variableValues[var] = True\r\n-\r\n-      # Recursively calculate the next term\r\n-      prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n-\r\n-      # Combine the results for the True case\r\n-      prQ_T *= prR_T\r\n-\r\n-      # Reset the variable value to None for the next iteration\r\n-      variableValues[var] = None\r\n-\r\n-      # Update the variable value for the False case\r\n-      variableValues[var] = False\r\n-\r\n-      # Recursively calculate the next term\r\n-      prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n-\r\n-      # Combine the results for the False case\r\n-      prQ_F *= prR_F\r\n-\r\n-      # Reset the variable value to None for the next iteration\r\n-      variableValues[var] = None\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n     elif var==queryVar:\r\n       #This term is probability _for_ the Query variable\r\n       if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n \r\n@@ -290,30 +247,9 @@\n       # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n       #   BUT remember to change it back to the original values when you are done!\r\n       #\r\n       # (Reference solution is 5 additional lines of code.)\r\n-      variableValues[var] = True\r\n-\r\n-      # Recursively calculate the next term\r\n-      prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n-\r\n-      # Combine the results for the True case\r\n-      prQ_T *= prR_T\r\n-\r\n-      # Reset the variable value to None for the next iteration\r\n-      variableValues[var] = None\r\n-\r\n-      # Update the variable value for the False case\r\n-      variableValues[var] = False\r\n-\r\n-      # Recursively calculate the next term\r\n-      prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n-\r\n-      # Combine the results for the False case\r\n-      prQ_F *= prR_F\r\n-\r\n-      # Reset the variable value to None for the next iteration\r\n-      variableValues[var] = None\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n     else:\r\n       #Simple term, no need to worry about query variable\r\n       if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n \r\n@@ -328,25 +264,10 @@\n       #\r\n       # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n       #\r\n       # (Reference solution is 5 lines of code.)\r\n-      variableValues[var] = True\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n \r\n-      # Get the conditional probability for the True case\r\n-      prQ_T *= model.varDist[var].table[tuple(variableValues[parent] for parent in model.varDist[var].parents)]\r\n-\r\n-      # Reset the variable value to None for the next iteration\r\n-      variableValues[var] = None\r\n-\r\n-      # Update the variable value for the False case\r\n-      variableValues[var] = False\r\n-\r\n-      # Get the conditional probability for the False case\r\n-      prQ_F *= model.varDist[var].table[tuple(variableValues[parent] for parent in model.varDist[var].parents)]\r\n-\r\n-      # Reset the variable value to None for the next iteration\r\n-      variableValues[var] = None\r\n-\r\n     if len(remainingCalc)>1:\r\n       #If there are still terms left, then recurse\r\n       prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n       \r\n"
                },
                {
                    "date": 1699824012564,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -35,10 +35,8 @@\n   # (Reference solution is 7 lines of code.)\r\n   joint_prob = 1.0\r\n \r\n   for var in model.vars:\r\n-      parents = model.varDist[var].parents\r\n-      cond_vals = {parent: variableValues[parent] for parent in parents}\r\n       cpt_entry = read_cpt(model, var, cond_vals)\r\n \r\n       if variableValues[var]:\r\n           joint_prob *= cpt_entry\r\n"
                },
                {
                    "date": 1699824066215,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -35,8 +35,10 @@\n   # (Reference solution is 7 lines of code.)\r\n   joint_prob = 1.0\r\n \r\n   for var in model.vars:\r\n+      parents = model.varDist[var].parents\r\n+      cond_vals = {parent: variableValues[parent] for parent in parents}\r\n       cpt_entry = read_cpt(model, var, cond_vals)\r\n \r\n       if variableValues[var]:\r\n           joint_prob *= cpt_entry\r\n"
                },
                {
                    "date": 1699824078759,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -35,10 +35,8 @@\n   # (Reference solution is 7 lines of code.)\r\n   joint_prob = 1.0\r\n \r\n   for var in model.vars:\r\n-      parents = model.varDist[var].parents\r\n-      cond_vals = {parent: variableValues[parent] for parent in parents}\r\n       cpt_entry = read_cpt(model, var, cond_vals)\r\n \r\n       if variableValues[var]:\r\n           joint_prob *= cpt_entry\r\n"
                },
                {
                    "date": 1699824327464,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -33,17 +33,14 @@\n   # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n   #\r\n   # (Reference solution is 7 lines of code.)\r\n   joint_prob = 1.0\r\n-\r\n   for var in model.vars:\r\n-      cpt_entry = read_cpt(model, var, cond_vals)\r\n-\r\n+      cpt_entry = read_cpt(model, var, variableValues)\r\n       if variableValues[var]:\r\n           joint_prob *= cpt_entry\r\n       else:\r\n           joint_prob *= 1 - cpt_entry\r\n-\r\n   return joint_prob\r\n \r\n def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n   \"\"\"\r\n@@ -95,18 +92,12 @@\n     # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n     #\r\n     # (Reference solution is 4 lines of code.)\r\n     if dict_issubset(jptEntry, evidence):\r\n-            # Increment the joint probability with both query variable and evidence\r\n-            pr_QE += pr_entry\r\n-\r\n-            # Check if the entry satisfies only the evidence (for denominator)\r\n             if jptEntry[queryVar] == queryVal:\r\n                 pr_E += pr_entry\r\n+return pr_QE/pr_E\r\n \r\n-\r\n-  return pr_QE/pr_E\r\n-\r\n def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n   \"\"\"\r\n   Calculate posterior probability for a given variable\r\n \r\n"
                },
                {
                    "date": 1699824333555,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -94,9 +94,9 @@\n     # (Reference solution is 4 lines of code.)\r\n     if dict_issubset(jptEntry, evidence):\r\n             if jptEntry[queryVar] == queryVal:\r\n                 pr_E += pr_entry\r\n-return pr_QE/pr_E\r\n+  return pr_QE/pr_E\r\n \r\n def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n   \"\"\"\r\n   Calculate posterior probability for a given variable\r\n"
                },
                {
                    "date": 1699824356729,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -92,8 +92,9 @@\n     # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n     #\r\n     # (Reference solution is 4 lines of code.)\r\n     if dict_issubset(jptEntry, evidence):\r\n+            pr_QE += pr_entry\r\n             if jptEntry[queryVar] == queryVal:\r\n                 pr_E += pr_entry\r\n   return pr_QE/pr_E\r\n \r\n"
                },
                {
                    "date": 1699824584545,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -92,11 +92,11 @@\n     # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n     #\r\n     # (Reference solution is 4 lines of code.)\r\n     if dict_issubset(jptEntry, evidence):\r\n-            pr_QE += pr_entry\r\n+            pr_QE *= pr_entry\r\n             if jptEntry[queryVar] == queryVal:\r\n-                pr_E += pr_entry\r\n+                pr_E *= pr_entry\r\n   return pr_QE/pr_E\r\n \r\n def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n   \"\"\"\r\n"
                },
                {
                    "date": 1699824872654,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -92,11 +92,11 @@\n     # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n     #\r\n     # (Reference solution is 4 lines of code.)\r\n     if dict_issubset(jptEntry, evidence):\r\n-            pr_QE *= pr_entry\r\n-            if jptEntry[queryVar] == queryVal:\r\n-                pr_E *= pr_entry\r\n+            pr_QE += pr_entry\r\n+            if jptEntry[queryVar]:\r\n+                pr_E += pr_entry\r\n   return pr_QE/pr_E\r\n \r\n def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n   \"\"\"\r\n"
                },
                {
                    "date": 1699824877967,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,681 @@\n+import argparse\r\n+import csv\r\n+from itertools import chain, permutations\r\n+import math\r\n+#import matplotlib.pyplot as plt\r\n+#import numpy as np\r\n+from random import random\r\n+import sys\r\n+\r\n+DEBUG_OUTPUT=0\r\n+\r\n+##############################################################################\r\n+## Student code\r\n+def calc_global_joint_prob(model, variableValues):\r\n+  \"\"\"\r\n+  Calculate the global joint probability of a model for a specific set of values\r\n+  model: model object, see read_model_file() for specification\r\n+  variableValues: dictionary of boolean values, keys are variable names\r\n+  \"\"\"\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # You may assume variableValues is complete, i.e containes all variables in the model\r\n+  #   Thus, no marginalization is necessary\r\n+  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n+  #\r\n+  # You can find a complete descrition of the model object in the documentation of\r\n+  #   the read_model_file() function, BUT\r\n+  # All you will need is the list of variables: model.vars\r\n+  #\r\n+  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n+  #\r\n+  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n+  #\r\n+  # (Reference solution is 7 lines of code.)\r\n+  joint_prob = 1.0\r\n+  for var in model.vars:\r\n+      cpt_entry = read_cpt(model, var, variableValues)\r\n+      if variableValues[var]:\r\n+          joint_prob *= cpt_entry\r\n+      else:\r\n+          joint_prob *= 1 - cpt_entry\r\n+  return joint_prob\r\n+\r\n+def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+\r\n+  # This first attempt at probabilistic inference will use the brute-force (table)\r\n+  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n+  #\r\n+  # This requires the calculation of two joint probabilities based on the definition\r\n+  # of conditional probability:\r\n+  #                          Pr( Query & Evidence )\r\n+  #   Pr(Query | Evidence) = ----------------------\r\n+  #                              Pr( Evidence )\r\n+  #\r\n+  # Both of these joint probabilities can be calculated by going over every entry in\r\n+  # the global joint probability table and summing up the probabilities of those\r\n+  # entries that match what we're looking for\r\n+  \r\n+  def dict_issubset(d,sub):\r\n+    \"\"\"\r\n+    Returns True if every key,value pair in sub has a matching key and value in d\r\n+    Note: sub should not contain any entries with value None\r\n+    \"\"\"\r\n+    return all(d.get(key,None)==val for key,val in sub.items())\r\n+     \r\n+  pr_QE=0\r\n+  pr_E=0\r\n+  for jptEntry in truefalse_combination_iterator(model.vars):\r\n+    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # jptEntry will be a dictionary with a key for every variable in the model,\r\n+    #   and the loop will go over every possible combination of True/False for each variable\r\n+    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n+    #\r\n+    # Your task is to collect all the probabilities that match the evidence, and query\r\n+    #\r\n+    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n+    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n+    #\r\n+    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n+    #\r\n+    # (Reference solution is 4 lines of code.)\r\n+    if dict_issubset(jptEntry, evidence):\r\n+            pr_QE += pr_entry\r\n+            if jptEntry[queryVar] == queryVal:\r\n+                pr_E += pr_entry\r\n+  return pr_QE/pr_E\r\n+\r\n+def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+  \r\n+  # First step, we need to figure out what order we will calculate terms in and where\r\n+  # marginalization needs to happen.\r\n+  #\r\n+  # That said, though this is a part of the inference process that you need to know, it's a\r\n+  # bit tricky to get working in general, especially the optimization bits.\r\n+  #\r\n+  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n+  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n+  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n+  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n+  # For example, the formula on slide 20 would be represented as:\r\n+  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n+  # The formula on slide 21 would be:\r\n+  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n+  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n+  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n+  \r\n+  # Debug: Output a nicer version of the calculation order (inference formula)\r\n+  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n+  \r\n+  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n+  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n+  \r\n+  # Next step, implement the calculation\r\n+  #\r\n+  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n+  # and move on to implement the recurse_calc_query_exact_tree() function\r\n+  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n+  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n+  # and associated function and add your own calculation code here\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n+  #\r\n+  # Normalize this result to get true probability.\r\n+  #\r\n+  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n+  #\r\n+  # Refer to the example on slide 30.\r\n+  #\r\n+  # (Reference solution is 3 lines of code.)\r\n+  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n+  \"\"\"\r\n+  Recursiving process the summation tree \r\n+  \r\n+  model,queryVar,evidence: See calc_query_exact_tree()\r\n+  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n+    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n+  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n+  \"\"\"\r\n+  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n+\r\n+  # Your overall task in the function is to assign values to:\r\n+  #   prQ_T\r\n+  #   prQ_F\r\n+  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n+  # covering both cases where query=True and query=False.\r\n+\r\n+  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n+  if marginalize:\r\n+    #Summation term, need to branch over all possible values and continue calculation\r\n+    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n+    # calculation\r\n+    #\r\n+    # You will need to recurse for each element of the summation (i.e. each branch)\r\n+    # Then properly combine the results together\r\n+    #\r\n+    # Slides 26-28 show examples of resolving summations.\r\n+    #\r\n+    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n+    #   BUT remember to change it back to the original values when you are done!\r\n+    #   (The original value for unknown variables is None.)\r\n+    #\r\n+    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n+    #   example of how to make the recursive call(s)\r\n+    #\r\n+    # (Reference solution is 7 lines of code.)\r\n+    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+  else:\r\n+    #Probability term, calculate conditional probability for this variable and continue calculation\r\n+    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n+    if queryVar in model.varDist[var].parents:\r\n+      #Query variable is a condition for this term\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n+      #\r\n+      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n+      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n+      # consider both what happens when the query variable is True, and also when it is False.\r\n+      #\r\n+      # Copy from your code below and modify to deal with this additional element.\r\n+      #\r\n+      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 11 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+    elif var==queryVar:\r\n+      #This term is probability _for_ the Query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one second! (Atleast, I recommend this.)\r\n+      #\r\n+      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n+      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n+      # is False.\r\n+      #\r\n+      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n+      # \r\n+      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 5 additional lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+    else:\r\n+      #Simple term, no need to worry about query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one first! (It's the simplest of the three.)\r\n+      #\r\n+      # You need to get the conditional probability for this variable and correctly\r\n+      # combine it with the results of the recursive call above.\r\n+      #\r\n+      # Don't forget that this variable's value could be True or False!\r\n+      #\r\n+      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n+      #\r\n+      # (Reference solution is 5 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+    if len(remainingCalc)>1:\r\n+      #If there are still terms left, then recurse\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n+      \r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Update prQ_T, prQ_F with the results from the recursive call.\r\n+      #\r\n+      # How do you combine _factors_ together?\r\n+      #\r\n+      # (Reference solution is 2 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n+  \r\n+##############################################################################\r\n+## Support code\r\n+def read_cpt(model,varName,condVals):\r\n+  \"\"\"\r\n+  Read conditional probability for a specified variable with provided condition (parent) values\r\n+  Note, the value returned is conditional probability for variable being True\r\n+  \r\n+  Warning: If you get an index exception and referenced key has None in it, this means\r\n+    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n+  \r\n+  model: model object, see read_model_file() for specification\r\n+  varName: string, variable name to read probability for\r\n+  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n+              (Missing conditions will cause errors, extraneous values will be ignored)\r\n+  \"\"\"\r\n+  if varName not in model.varDist:\r\n+    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n+  varDist=model.varDist[varName]\r\n+  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n+  if key not in varDist.cpt:\r\n+    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n+  return varDist.cpt[key]\r\n+\r\n+def truefalse_combination_iterator(entries):\r\n+  \"\"\"\r\n+  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n+  \"\"\"\r\n+  entries=list(entries)\r\n+  entries.reverse()\r\n+  if len(entries)>30:\r\n+    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n+  for c in range(1<<len(entries)):\r\n+    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n+\r\n+def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n+  \"\"\"\r\n+  Create represention of terms in an inference calculation such as on slides 20-21\r\n+  \r\n+  Returns a list of (boolean,string) tuples where:\r\n+    (True,variable) represents a summation term where a variable needs to be marginalized\r\n+    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n+  \"\"\"\r\n+  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Naive solution\r\n+  #\r\n+  # model.varsDep already has variables in order of dependency...\r\n+  # So take that and insert summation terms any time we encounter a new hidden variable\r\n+  #\r\n+  # Downside is little optimization, likely to have many unnecessary terms\r\n+  if False:\r\n+    hiddenLeft=set(hiddenVars)\r\n+    seq=[]\r\n+    for v in model.varsDep:\r\n+      #Check if factor variable is a (unhandled) hidden variable\r\n+      if v in hiddenLeft:\r\n+        seq.append( (True,v) ) #If so, trigger a marginalization\r\n+        hiddenLeft.remove(v)   #And mark it as handled\r\n+      for p in model.varDist[v].parents:\r\n+        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n+        if p in hiddenLeft:\r\n+          seq.append( (True,p) )\r\n+          hiddenLeft.remove(p)\r\n+      seq.append( (False,v) ) #Then process the factor itself\r\n+    assert(len(hiddenLeft)==0)\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Arbitrary ordering\r\n+  #\r\n+  # What if we wanted to handle hidden variables in an arbitrary order?\r\n+  #\r\n+  # Possible, but we'll have to be careful where we put factors, after\r\n+  # all their dependencies are satisfied.\r\n+  def seq_from_hid_order(hOrd):\r\n+    #The trick to make this work is to first assign every\r\n+    #hidden variable a priority based on the order\r\n+    prio={h:i for i,h in enumerate(hOrd)}\r\n+    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n+    #Then rate each factor on the highest priority amongst its dependencies\r\n+    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n+    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n+    vOrd.sort()\r\n+    #All that's left is to turn it into the expected sequence format\r\n+    return list( (not nm,v) for _,nm,v in vOrd )\r\n+  \r\n+  #--------------------------------------------------------\r\n+  # Brute force best\r\n+  #\r\n+  # Now, where to get an ordering to use the above?\r\n+  #\r\n+  # We could brute force try every possible ordering...\r\n+  if True:\r\n+    bestSeq=None\r\n+    bestSeqCost=sys.maxsize\r\n+    for hOrd in permutations(hiddenVars):\r\n+      tSeq=seq_from_hid_order(hOrd)\r\n+      #Note, really should do below norm optimization here too\r\n+      \r\n+      #Now the tricky bit is to rate each ordering\r\n+      #We'll do it by doubling the cost of each factor every time\r\n+      #We cross a summation\r\n+      tot=0\r\n+      ct=1\r\n+      for m,v in tSeq:\r\n+        if m:\r\n+          ct*=2\r\n+        else:\r\n+          tot+=ct\r\n+      \r\n+      if tot<bestSeqCost:\r\n+        bestSeq=tSeq\r\n+        bestSeqCost=tot\r\n+    seq=bestSeq\r\n+  # But this will be very expensive for large models\r\n+  #--------------------------------------------------------\r\n+  # Greedy\r\n+  #\r\n+  # Alternately, we could apply a greedy approach.\r\n+  #\r\n+  # Some how rate each hidden variable on how expensive we think\r\n+  # it is, then put the most expensive ones earliest\r\n+  # ***TODO***\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Simple normalization optimization\r\n+  #\r\n+  # One thing we learned is that for a multiplicative term,\r\n+  # if it doesn't mention the query variable, then it's a\r\n+  # constant and can be handled via normalization (folded into alpha)\r\n+  #\r\n+  # This is non-trivial to detect for summation terms, but we\r\n+  # can easily do it for factors outside of any summation...\r\n+  if True:\r\n+    i=0\r\n+    while i<len(seq):\r\n+      m,v=seq[i]\r\n+      if m:\r\n+        break #Found first summation, quit\r\n+      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n+        #No mention of query variable, remove\r\n+        del seq[i]\r\n+      else:\r\n+        i+=1\r\n+  \r\n+  return seq\r\n+\r\n+def calc_query_approx(model,queryVar,queryVal,evidence):\r\n+  raise NotImplementedError()\r\n+\r\n+def generate_joint_prob_table(model):\r\n+  \"\"\"\r\n+  Output a joint probability table for the provided model\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  table=[]\r\n+  row=list(model.vars)\r\n+  row.append('Joint Pr')\r\n+  table.append(row)\r\n+  for varVals in truefalse_combination_iterator(model.vars):\r\n+    pr=calc_global_joint_prob(model,varVals)\r\n+    row=[varVals[x] for x in model.vars]\r\n+    row.append(pr)\r\n+    table.append(row)\r\n+  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+  return\r\n+\r\n+def read_model_file(filename):\r\n+  \"\"\"\r\n+  Returns model object with the following elements:\r\n+    vars : list of strings\r\n+      The list of variables the model describes\r\n+      In alphabetical order\r\n+    varsDep : list of strings\r\n+      Same contents as 'vars' but in dependency order (parents come before children)\r\n+    varDist : dict of objects\r\n+      Distribution information for each variable\r\n+      Dictionary key is variable name\r\n+      Object has the following elements:\r\n+        parents : set of strings\r\n+        children : set of strings\r\n+        cpt : dict of numbers\r\n+          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n+          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n+            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n+  Model file format is as follows:\r\n+    Basic file format is Comma-Separated Value (.csv)\r\n+    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n+    Tables are separated by atleast one empty line\r\n+    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n+    Each table:\r\n+      Starts with a header row containing variable names\r\n+        The last name is the variable whose cond probability is being described\r\n+        Any preceding names are considered to be parent variables\r\n+      Following rows contain True/False values for each parent and probability for main variable being true\r\n+      Any missing parent value combinations will be assumed to be probability 0.5\r\n+    Only Bernoulli/Boolean variables can be represented in this file format\r\n+  \"\"\"\r\n+  class ModelObj:\r\n+    def __init__(self):\r\n+      self.vars=[]\r\n+      self.varsDep=None\r\n+      self.varDist={}\r\n+\r\n+  class VarObj:\r\n+    def __init__(self, parents, children, cpt):\r\n+      self.parents = parents\r\n+      self.children = children\r\n+      self.cpt = cpt\r\n+\r\n+  model=ModelObj()\r\n+  #--------------------------------------------------------\r\n+  #Read data from file\r\n+  with open(filename, newline='') as csvfile:\r\n+    csvreader = csv.reader(csvfile)\r\n+    \r\n+    rowNum=0\r\n+    var=None\r\n+    varIdx=None\r\n+    parents=None\r\n+    cpt=None\r\n+    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n+      rowNum+=1\r\n+      srow=''.join(row).strip()\r\n+      if srow.startswith('#'):\r\n+        continue #Comment line, skip\r\n+      if len(srow)==0:\r\n+        #Empty line\r\n+        if var is not None:\r\n+          #End current table\r\n+          model.vars.append(var)\r\n+          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n+          #Wait for new table\r\n+          var=None\r\n+          varIdx=None\r\n+          parents=None\r\n+          cpt=None\r\n+      elif var is None:\r\n+        #Start new table\r\n+        if len(row)>1:\r\n+          parents=row[0:-1]\r\n+        else:\r\n+          parents=[]\r\n+        varIdx=len(row)-1\r\n+        var=row[varIdx]\r\n+        cpt={}\r\n+      else:\r\n+        #Add new entry to table\r\n+        if len(row)<varIdx+1:\r\n+          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n+        if len(parents)>0:\r\n+          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n+        else:\r\n+          key=frozenset()\r\n+        cpt[key]=float(row[-1])\r\n+  model.vars.sort()\r\n+  #--------------------------------------------------------\r\n+  # Check distributions for missing entries\r\n+  vCheck=frozenset(model.vars)\r\n+  for var in model.vars: #Make sure every mentioned variable has an entry\r\n+    for p in model.varDist[var].parents:\r\n+      if p not in vCheck:\r\n+        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n+  for var in model.vars: #Check every cpt for missing rows\r\n+    varDist=model.varDist[var]\r\n+    missingCnt=0\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      key=frozenset(((x,v) for x,v in varVals.items()))\r\n+      if key not in varDist.cpt:\r\n+        missingCnt+=1\r\n+        varDist.cpt[key]=0.5\r\n+    if missingCnt>0:\r\n+      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n+  #--------------------------------------------------------\r\n+  # Create children entries\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=set()\r\n+  for var in model.vars:\r\n+    for p in model.varDist[var].parents:\r\n+      model.varDist[p].children.add(var)\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n+  #--------------------------------------------------------\r\n+  # Create dependency ordering\r\n+  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n+  idx=0\r\n+  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n+  while idx<len(varsDep):\r\n+    var=varsDep[idx]\r\n+    for c in model.varDist[var].children:\r\n+      parentsLeft[c]-=1\r\n+      if parentsLeft[c]==0:\r\n+        #All parents have been visited, so dependencies of this child are met\r\n+        varsDep.append(c)\r\n+      elif parentsLeft[c]<0:\r\n+        #Repeat visit to a parent can only happen if a cycle exists\r\n+        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n+    idx+=1\r\n+  model.varsDep=varsDep\r\n+  #--------------------------------------------------------\r\n+  return model\r\n+\r\n+def print_model(model):\r\n+  \"\"\"\r\n+  Print a model object back out in pretty form\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  for v in model.vars:\r\n+    varDist=model.varDist[v]\r\n+    print('--------------------------------------------------')\r\n+    print('Variable:',v)\r\n+    print('--------------------------------------------------')\r\n+    print('Children:',', '.join(varDist.children))\r\n+    \r\n+    table=[]\r\n+    row=list(varDist.parents)\r\n+    row.append('P({0}=T|...)'.format(v))\r\n+    table.append(row)\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      pr=read_cpt(model,v,varVals)\r\n+      row=[varVals[x] for x in varDist.parents]\r\n+      row.append(pr)\r\n+      table.append(row)\r\n+    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+    print(\"\")\r\n+    \r\n+##############################################################################\r\n+## Main functions\r\n+def main(args):\r\n+  global DEBUG_OUTPUT\r\n+  if args.debug:\r\n+    DEBUG_OUTPUT=1\r\n+  #Argument checking plus additional parsing\r\n+  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in table mode')\r\n+  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in print mode')\r\n+  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n+    error('Argument --query required in inference modes')\r\n+  elif args.query is not None:\r\n+    if '=' not in args.query:\r\n+      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n+    s=args.query.split('=')\r\n+    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n+  if args.evidence is None:\r\n+    args.evidence=[]\r\n+  else:\r\n+    ev=[]\r\n+    for e in args.evidence:\r\n+      if '=' not in e:\r\n+        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n+      s=e.split('=')\r\n+      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n+    args.evidence={ var:val for var,val in ev }\r\n+\r\n+  print('Reading model from',args.model)\r\n+  model=read_model_file(args.model)\r\n+\r\n+  if args.mode=='table':\r\n+    generate_joint_prob_table(model)\r\n+  elif args.mode=='print':\r\n+    print_model(model)\r\n+  else:\r\n+    #One of the inference modes\r\n+    #Check inputs against model\r\n+    if args.query[0] not in model.vars:\r\n+      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n+    for var,val in args.evidence.items():\r\n+      if var not in model.vars:\r\n+        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n+    #Output problem setup\r\n+    print(\"Inference mode:\",args.mode)\r\n+    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n+    if len(args.evidence)==0:\r\n+      print(\"No evidence\")\r\n+    else:\r\n+      print(\"Evidence:\")\r\n+      for var,val in args.evidence.items():\r\n+        print(\"  '{0}' is {1}\".format(var,val))\r\n+\r\n+    #Run inference\r\n+    pr=None\r\n+    if args.mode=='brute':\r\n+      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n+    elif args.mode=='tree':\r\n+      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n+    else: #args.mode=='approx'\r\n+      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n+    print('Probability is',pr)\r\n+\r\n+  return\r\n+\r\n+def error(msg):\r\n+  print(msg)\r\n+  sys.exit(1)\r\n+  return\r\n+\r\n+if __name__ == '__main__':\r\n+  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n+  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n+  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n+  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n+  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n+  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n+  args = parser.parse_args()\r\n+  error=lambda msg : parser.error(msg)\r\n+  main(args)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1699824974347,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,681 @@\n+import argparse\r\n+import csv\r\n+from itertools import chain, permutations\r\n+import math\r\n+#import matplotlib.pyplot as plt\r\n+#import numpy as np\r\n+from random import random\r\n+import sys\r\n+\r\n+DEBUG_OUTPUT=0\r\n+\r\n+##############################################################################\r\n+## Student code\r\n+def calc_global_joint_prob(model, variableValues):\r\n+  \"\"\"\r\n+  Calculate the global joint probability of a model for a specific set of values\r\n+  model: model object, see read_model_file() for specification\r\n+  variableValues: dictionary of boolean values, keys are variable names\r\n+  \"\"\"\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # You may assume variableValues is complete, i.e containes all variables in the model\r\n+  #   Thus, no marginalization is necessary\r\n+  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n+  #\r\n+  # You can find a complete descrition of the model object in the documentation of\r\n+  #   the read_model_file() function, BUT\r\n+  # All you will need is the list of variables: model.vars\r\n+  #\r\n+  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n+  #\r\n+  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n+  #\r\n+  # (Reference solution is 7 lines of code.)\r\n+  joint_prob = 1.0\r\n+  for var in model.vars:\r\n+      cpt_entry = read_cpt(model, var, variableValues)\r\n+      if variableValues[var]:\r\n+          joint_prob *= cpt_entry\r\n+      else:\r\n+          joint_prob *= 1 - cpt_entry\r\n+  return joint_prob\r\n+\r\n+def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+\r\n+  # This first attempt at probabilistic inference will use the brute-force (table)\r\n+  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n+  #\r\n+  # This requires the calculation of two joint probabilities based on the definition\r\n+  # of conditional probability:\r\n+  #                          Pr( Query & Evidence )\r\n+  #   Pr(Query | Evidence) = ----------------------\r\n+  #                              Pr( Evidence )\r\n+  #\r\n+  # Both of these joint probabilities can be calculated by going over every entry in\r\n+  # the global joint probability table and summing up the probabilities of those\r\n+  # entries that match what we're looking for\r\n+  \r\n+  def dict_issubset(d,sub):\r\n+    \"\"\"\r\n+    Returns True if every key,value pair in sub has a matching key and value in d\r\n+    Note: sub should not contain any entries with value None\r\n+    \"\"\"\r\n+    return all(d.get(key,None)==val for key,val in sub.items())\r\n+     \r\n+  pr_QE=0\r\n+  pr_E=0\r\n+  for jptEntry in truefalse_combination_iterator(model.vars):\r\n+    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # jptEntry will be a dictionary with a key for every variable in the model,\r\n+    #   and the loop will go over every possible combination of True/False for each variable\r\n+    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n+    #\r\n+    # Your task is to collect all the probabilities that match the evidence, and query\r\n+    #\r\n+    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n+    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n+    #\r\n+    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n+    #\r\n+    # (Reference solution is 4 lines of code.)\r\n+    if dict_issubset(jptEntry, evidence):\r\n+            pr_QE /= pr_entry\r\n+            if jptEntry[queryVar] == queryVal:\r\n+                pr_E /= pr_entry\r\n+  return pr_QE/pr_E\r\n+\r\n+def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+  \r\n+  # First step, we need to figure out what order we will calculate terms in and where\r\n+  # marginalization needs to happen.\r\n+  #\r\n+  # That said, though this is a part of the inference process that you need to know, it's a\r\n+  # bit tricky to get working in general, especially the optimization bits.\r\n+  #\r\n+  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n+  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n+  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n+  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n+  # For example, the formula on slide 20 would be represented as:\r\n+  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n+  # The formula on slide 21 would be:\r\n+  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n+  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n+  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n+  \r\n+  # Debug: Output a nicer version of the calculation order (inference formula)\r\n+  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n+  \r\n+  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n+  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n+  \r\n+  # Next step, implement the calculation\r\n+  #\r\n+  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n+  # and move on to implement the recurse_calc_query_exact_tree() function\r\n+  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n+  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n+  # and associated function and add your own calculation code here\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n+  #\r\n+  # Normalize this result to get true probability.\r\n+  #\r\n+  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n+  #\r\n+  # Refer to the example on slide 30.\r\n+  #\r\n+  # (Reference solution is 3 lines of code.)\r\n+  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n+  \"\"\"\r\n+  Recursiving process the summation tree \r\n+  \r\n+  model,queryVar,evidence: See calc_query_exact_tree()\r\n+  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n+    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n+  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n+  \"\"\"\r\n+  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n+\r\n+  # Your overall task in the function is to assign values to:\r\n+  #   prQ_T\r\n+  #   prQ_F\r\n+  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n+  # covering both cases where query=True and query=False.\r\n+\r\n+  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n+  if marginalize:\r\n+    #Summation term, need to branch over all possible values and continue calculation\r\n+    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n+    # calculation\r\n+    #\r\n+    # You will need to recurse for each element of the summation (i.e. each branch)\r\n+    # Then properly combine the results together\r\n+    #\r\n+    # Slides 26-28 show examples of resolving summations.\r\n+    #\r\n+    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n+    #   BUT remember to change it back to the original values when you are done!\r\n+    #   (The original value for unknown variables is None.)\r\n+    #\r\n+    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n+    #   example of how to make the recursive call(s)\r\n+    #\r\n+    # (Reference solution is 7 lines of code.)\r\n+    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+  else:\r\n+    #Probability term, calculate conditional probability for this variable and continue calculation\r\n+    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n+    if queryVar in model.varDist[var].parents:\r\n+      #Query variable is a condition for this term\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n+      #\r\n+      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n+      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n+      # consider both what happens when the query variable is True, and also when it is False.\r\n+      #\r\n+      # Copy from your code below and modify to deal with this additional element.\r\n+      #\r\n+      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 11 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+    elif var==queryVar:\r\n+      #This term is probability _for_ the Query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one second! (Atleast, I recommend this.)\r\n+      #\r\n+      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n+      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n+      # is False.\r\n+      #\r\n+      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n+      # \r\n+      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 5 additional lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+    else:\r\n+      #Simple term, no need to worry about query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one first! (It's the simplest of the three.)\r\n+      #\r\n+      # You need to get the conditional probability for this variable and correctly\r\n+      # combine it with the results of the recursive call above.\r\n+      #\r\n+      # Don't forget that this variable's value could be True or False!\r\n+      #\r\n+      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n+      #\r\n+      # (Reference solution is 5 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+    if len(remainingCalc)>1:\r\n+      #If there are still terms left, then recurse\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n+      \r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Update prQ_T, prQ_F with the results from the recursive call.\r\n+      #\r\n+      # How do you combine _factors_ together?\r\n+      #\r\n+      # (Reference solution is 2 lines of code.)\r\n+      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+\r\n+  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n+  \r\n+##############################################################################\r\n+## Support code\r\n+def read_cpt(model,varName,condVals):\r\n+  \"\"\"\r\n+  Read conditional probability for a specified variable with provided condition (parent) values\r\n+  Note, the value returned is conditional probability for variable being True\r\n+  \r\n+  Warning: If you get an index exception and referenced key has None in it, this means\r\n+    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n+  \r\n+  model: model object, see read_model_file() for specification\r\n+  varName: string, variable name to read probability for\r\n+  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n+              (Missing conditions will cause errors, extraneous values will be ignored)\r\n+  \"\"\"\r\n+  if varName not in model.varDist:\r\n+    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n+  varDist=model.varDist[varName]\r\n+  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n+  if key not in varDist.cpt:\r\n+    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n+  return varDist.cpt[key]\r\n+\r\n+def truefalse_combination_iterator(entries):\r\n+  \"\"\"\r\n+  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n+  \"\"\"\r\n+  entries=list(entries)\r\n+  entries.reverse()\r\n+  if len(entries)>30:\r\n+    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n+  for c in range(1<<len(entries)):\r\n+    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n+\r\n+def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n+  \"\"\"\r\n+  Create represention of terms in an inference calculation such as on slides 20-21\r\n+  \r\n+  Returns a list of (boolean,string) tuples where:\r\n+    (True,variable) represents a summation term where a variable needs to be marginalized\r\n+    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n+  \"\"\"\r\n+  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Naive solution\r\n+  #\r\n+  # model.varsDep already has variables in order of dependency...\r\n+  # So take that and insert summation terms any time we encounter a new hidden variable\r\n+  #\r\n+  # Downside is little optimization, likely to have many unnecessary terms\r\n+  if False:\r\n+    hiddenLeft=set(hiddenVars)\r\n+    seq=[]\r\n+    for v in model.varsDep:\r\n+      #Check if factor variable is a (unhandled) hidden variable\r\n+      if v in hiddenLeft:\r\n+        seq.append( (True,v) ) #If so, trigger a marginalization\r\n+        hiddenLeft.remove(v)   #And mark it as handled\r\n+      for p in model.varDist[v].parents:\r\n+        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n+        if p in hiddenLeft:\r\n+          seq.append( (True,p) )\r\n+          hiddenLeft.remove(p)\r\n+      seq.append( (False,v) ) #Then process the factor itself\r\n+    assert(len(hiddenLeft)==0)\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Arbitrary ordering\r\n+  #\r\n+  # What if we wanted to handle hidden variables in an arbitrary order?\r\n+  #\r\n+  # Possible, but we'll have to be careful where we put factors, after\r\n+  # all their dependencies are satisfied.\r\n+  def seq_from_hid_order(hOrd):\r\n+    #The trick to make this work is to first assign every\r\n+    #hidden variable a priority based on the order\r\n+    prio={h:i for i,h in enumerate(hOrd)}\r\n+    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n+    #Then rate each factor on the highest priority amongst its dependencies\r\n+    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n+    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n+    vOrd.sort()\r\n+    #All that's left is to turn it into the expected sequence format\r\n+    return list( (not nm,v) for _,nm,v in vOrd )\r\n+  \r\n+  #--------------------------------------------------------\r\n+  # Brute force best\r\n+  #\r\n+  # Now, where to get an ordering to use the above?\r\n+  #\r\n+  # We could brute force try every possible ordering...\r\n+  if True:\r\n+    bestSeq=None\r\n+    bestSeqCost=sys.maxsize\r\n+    for hOrd in permutations(hiddenVars):\r\n+      tSeq=seq_from_hid_order(hOrd)\r\n+      #Note, really should do below norm optimization here too\r\n+      \r\n+      #Now the tricky bit is to rate each ordering\r\n+      #We'll do it by doubling the cost of each factor every time\r\n+      #We cross a summation\r\n+      tot=0\r\n+      ct=1\r\n+      for m,v in tSeq:\r\n+        if m:\r\n+          ct*=2\r\n+        else:\r\n+          tot+=ct\r\n+      \r\n+      if tot<bestSeqCost:\r\n+        bestSeq=tSeq\r\n+        bestSeqCost=tot\r\n+    seq=bestSeq\r\n+  # But this will be very expensive for large models\r\n+  #--------------------------------------------------------\r\n+  # Greedy\r\n+  #\r\n+  # Alternately, we could apply a greedy approach.\r\n+  #\r\n+  # Some how rate each hidden variable on how expensive we think\r\n+  # it is, then put the most expensive ones earliest\r\n+  # ***TODO***\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Simple normalization optimization\r\n+  #\r\n+  # One thing we learned is that for a multiplicative term,\r\n+  # if it doesn't mention the query variable, then it's a\r\n+  # constant and can be handled via normalization (folded into alpha)\r\n+  #\r\n+  # This is non-trivial to detect for summation terms, but we\r\n+  # can easily do it for factors outside of any summation...\r\n+  if True:\r\n+    i=0\r\n+    while i<len(seq):\r\n+      m,v=seq[i]\r\n+      if m:\r\n+        break #Found first summation, quit\r\n+      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n+        #No mention of query variable, remove\r\n+        del seq[i]\r\n+      else:\r\n+        i+=1\r\n+  \r\n+  return seq\r\n+\r\n+def calc_query_approx(model,queryVar,queryVal,evidence):\r\n+  raise NotImplementedError()\r\n+\r\n+def generate_joint_prob_table(model):\r\n+  \"\"\"\r\n+  Output a joint probability table for the provided model\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  table=[]\r\n+  row=list(model.vars)\r\n+  row.append('Joint Pr')\r\n+  table.append(row)\r\n+  for varVals in truefalse_combination_iterator(model.vars):\r\n+    pr=calc_global_joint_prob(model,varVals)\r\n+    row=[varVals[x] for x in model.vars]\r\n+    row.append(pr)\r\n+    table.append(row)\r\n+  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+  return\r\n+\r\n+def read_model_file(filename):\r\n+  \"\"\"\r\n+  Returns model object with the following elements:\r\n+    vars : list of strings\r\n+      The list of variables the model describes\r\n+      In alphabetical order\r\n+    varsDep : list of strings\r\n+      Same contents as 'vars' but in dependency order (parents come before children)\r\n+    varDist : dict of objects\r\n+      Distribution information for each variable\r\n+      Dictionary key is variable name\r\n+      Object has the following elements:\r\n+        parents : set of strings\r\n+        children : set of strings\r\n+        cpt : dict of numbers\r\n+          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n+          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n+            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n+  Model file format is as follows:\r\n+    Basic file format is Comma-Separated Value (.csv)\r\n+    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n+    Tables are separated by atleast one empty line\r\n+    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n+    Each table:\r\n+      Starts with a header row containing variable names\r\n+        The last name is the variable whose cond probability is being described\r\n+        Any preceding names are considered to be parent variables\r\n+      Following rows contain True/False values for each parent and probability for main variable being true\r\n+      Any missing parent value combinations will be assumed to be probability 0.5\r\n+    Only Bernoulli/Boolean variables can be represented in this file format\r\n+  \"\"\"\r\n+  class ModelObj:\r\n+    def __init__(self):\r\n+      self.vars=[]\r\n+      self.varsDep=None\r\n+      self.varDist={}\r\n+\r\n+  class VarObj:\r\n+    def __init__(self, parents, children, cpt):\r\n+      self.parents = parents\r\n+      self.children = children\r\n+      self.cpt = cpt\r\n+\r\n+  model=ModelObj()\r\n+  #--------------------------------------------------------\r\n+  #Read data from file\r\n+  with open(filename, newline='') as csvfile:\r\n+    csvreader = csv.reader(csvfile)\r\n+    \r\n+    rowNum=0\r\n+    var=None\r\n+    varIdx=None\r\n+    parents=None\r\n+    cpt=None\r\n+    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n+      rowNum+=1\r\n+      srow=''.join(row).strip()\r\n+      if srow.startswith('#'):\r\n+        continue #Comment line, skip\r\n+      if len(srow)==0:\r\n+        #Empty line\r\n+        if var is not None:\r\n+          #End current table\r\n+          model.vars.append(var)\r\n+          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n+          #Wait for new table\r\n+          var=None\r\n+          varIdx=None\r\n+          parents=None\r\n+          cpt=None\r\n+      elif var is None:\r\n+        #Start new table\r\n+        if len(row)>1:\r\n+          parents=row[0:-1]\r\n+        else:\r\n+          parents=[]\r\n+        varIdx=len(row)-1\r\n+        var=row[varIdx]\r\n+        cpt={}\r\n+      else:\r\n+        #Add new entry to table\r\n+        if len(row)<varIdx+1:\r\n+          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n+        if len(parents)>0:\r\n+          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n+        else:\r\n+          key=frozenset()\r\n+        cpt[key]=float(row[-1])\r\n+  model.vars.sort()\r\n+  #--------------------------------------------------------\r\n+  # Check distributions for missing entries\r\n+  vCheck=frozenset(model.vars)\r\n+  for var in model.vars: #Make sure every mentioned variable has an entry\r\n+    for p in model.varDist[var].parents:\r\n+      if p not in vCheck:\r\n+        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n+  for var in model.vars: #Check every cpt for missing rows\r\n+    varDist=model.varDist[var]\r\n+    missingCnt=0\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      key=frozenset(((x,v) for x,v in varVals.items()))\r\n+      if key not in varDist.cpt:\r\n+        missingCnt+=1\r\n+        varDist.cpt[key]=0.5\r\n+    if missingCnt>0:\r\n+      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n+  #--------------------------------------------------------\r\n+  # Create children entries\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=set()\r\n+  for var in model.vars:\r\n+    for p in model.varDist[var].parents:\r\n+      model.varDist[p].children.add(var)\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n+  #--------------------------------------------------------\r\n+  # Create dependency ordering\r\n+  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n+  idx=0\r\n+  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n+  while idx<len(varsDep):\r\n+    var=varsDep[idx]\r\n+    for c in model.varDist[var].children:\r\n+      parentsLeft[c]-=1\r\n+      if parentsLeft[c]==0:\r\n+        #All parents have been visited, so dependencies of this child are met\r\n+        varsDep.append(c)\r\n+      elif parentsLeft[c]<0:\r\n+        #Repeat visit to a parent can only happen if a cycle exists\r\n+        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n+    idx+=1\r\n+  model.varsDep=varsDep\r\n+  #--------------------------------------------------------\r\n+  return model\r\n+\r\n+def print_model(model):\r\n+  \"\"\"\r\n+  Print a model object back out in pretty form\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  for v in model.vars:\r\n+    varDist=model.varDist[v]\r\n+    print('--------------------------------------------------')\r\n+    print('Variable:',v)\r\n+    print('--------------------------------------------------')\r\n+    print('Children:',', '.join(varDist.children))\r\n+    \r\n+    table=[]\r\n+    row=list(varDist.parents)\r\n+    row.append('P({0}=T|...)'.format(v))\r\n+    table.append(row)\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      pr=read_cpt(model,v,varVals)\r\n+      row=[varVals[x] for x in varDist.parents]\r\n+      row.append(pr)\r\n+      table.append(row)\r\n+    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+    print(\"\")\r\n+    \r\n+##############################################################################\r\n+## Main functions\r\n+def main(args):\r\n+  global DEBUG_OUTPUT\r\n+  if args.debug:\r\n+    DEBUG_OUTPUT=1\r\n+  #Argument checking plus additional parsing\r\n+  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in table mode')\r\n+  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in print mode')\r\n+  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n+    error('Argument --query required in inference modes')\r\n+  elif args.query is not None:\r\n+    if '=' not in args.query:\r\n+      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n+    s=args.query.split('=')\r\n+    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n+  if args.evidence is None:\r\n+    args.evidence=[]\r\n+  else:\r\n+    ev=[]\r\n+    for e in args.evidence:\r\n+      if '=' not in e:\r\n+        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n+      s=e.split('=')\r\n+      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n+    args.evidence={ var:val for var,val in ev }\r\n+\r\n+  print('Reading model from',args.model)\r\n+  model=read_model_file(args.model)\r\n+\r\n+  if args.mode=='table':\r\n+    generate_joint_prob_table(model)\r\n+  elif args.mode=='print':\r\n+    print_model(model)\r\n+  else:\r\n+    #One of the inference modes\r\n+    #Check inputs against model\r\n+    if args.query[0] not in model.vars:\r\n+      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n+    for var,val in args.evidence.items():\r\n+      if var not in model.vars:\r\n+        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n+    #Output problem setup\r\n+    print(\"Inference mode:\",args.mode)\r\n+    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n+    if len(args.evidence)==0:\r\n+      print(\"No evidence\")\r\n+    else:\r\n+      print(\"Evidence:\")\r\n+      for var,val in args.evidence.items():\r\n+        print(\"  '{0}' is {1}\".format(var,val))\r\n+\r\n+    #Run inference\r\n+    pr=None\r\n+    if args.mode=='brute':\r\n+      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n+    elif args.mode=='tree':\r\n+      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n+    else: #args.mode=='approx'\r\n+      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n+    print('Probability is',pr)\r\n+\r\n+  return\r\n+\r\n+def error(msg):\r\n+  print(msg)\r\n+  sys.exit(1)\r\n+  return\r\n+\r\n+if __name__ == '__main__':\r\n+  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n+  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n+  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n+  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n+  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n+  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n+  args = parser.parse_args()\r\n+  error=lambda msg : parser.error(msg)\r\n+  main(args)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1699824983002,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -92,11 +92,11 @@\n     # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n     #\r\n     # (Reference solution is 4 lines of code.)\r\n     if dict_issubset(jptEntry, evidence):\r\n-            pr_QE /= pr_entry\r\n+            pr_QE -= pr_entry\r\n             if jptEntry[queryVar] == queryVal:\r\n-                pr_E /= pr_entry\r\n+                pr_E -= pr_entry\r\n   return pr_QE/pr_E\r\n \r\n def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n   \"\"\"\r\n@@ -677,1367 +677,5 @@\n   parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n   parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n   args = parser.parse_args()\r\n   error=lambda msg : parser.error(msg)\r\n-  main(args)\n-import argparse\r\n-import csv\r\n-from itertools import chain, permutations\r\n-import math\r\n-#import matplotlib.pyplot as plt\r\n-#import numpy as np\r\n-from random import random\r\n-import sys\r\n-\r\n-DEBUG_OUTPUT=0\r\n-\r\n-##############################################################################\r\n-## Student code\r\n-def calc_global_joint_prob(model, variableValues):\r\n-  \"\"\"\r\n-  Calculate the global joint probability of a model for a specific set of values\r\n-  model: model object, see read_model_file() for specification\r\n-  variableValues: dictionary of boolean values, keys are variable names\r\n-  \"\"\"\r\n-  \r\n-  # YOUR CODE HERE\r\n-  #\r\n-  # You may assume variableValues is complete, i.e containes all variables in the model\r\n-  #   Thus, no marginalization is necessary\r\n-  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n-  #\r\n-  # You can find a complete descrition of the model object in the documentation of\r\n-  #   the read_model_file() function, BUT\r\n-  # All you will need is the list of variables: model.vars\r\n-  #\r\n-  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n-  #\r\n-  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n-  #\r\n-  # (Reference solution is 7 lines of code.)\r\n-  joint_prob = 1.0\r\n-  for var in model.vars:\r\n-      cpt_entry = read_cpt(model, var, variableValues)\r\n-      if variableValues[var]:\r\n-          joint_prob *= cpt_entry\r\n-      else:\r\n-          joint_prob *= 1 - cpt_entry\r\n-  return joint_prob\r\n-\r\n-def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n-  \"\"\"\r\n-  Calculate posterior probability for a given variable\r\n-\r\n-  model: model object, see read_model_file() for specification\r\n-  queryVar: string, query variable name\r\n-  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n-  evidence: dictionary of boolean values, where keys are evidence variable names\r\n-            (Any variable not listed as query or evidence is assumed to be hidden)\r\n-  \"\"\"\r\n-\r\n-  # This first attempt at probabilistic inference will use the brute-force (table)\r\n-  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n-  #\r\n-  # This requires the calculation of two joint probabilities based on the definition\r\n-  # of conditional probability:\r\n-  #                          Pr( Query & Evidence )\r\n-  #   Pr(Query | Evidence) = ----------------------\r\n-  #                              Pr( Evidence )\r\n-  #\r\n-  # Both of these joint probabilities can be calculated by going over every entry in\r\n-  # the global joint probability table and summing up the probabilities of those\r\n-  # entries that match what we're looking for\r\n-  \r\n-  def dict_issubset(d,sub):\r\n-    \"\"\"\r\n-    Returns True if every key,value pair in sub has a matching key and value in d\r\n-    Note: sub should not contain any entries with value None\r\n-    \"\"\"\r\n-    return all(d.get(key,None)==val for key,val in sub.items())\r\n-     \r\n-  pr_QE=0\r\n-  pr_E=0\r\n-  for jptEntry in truefalse_combination_iterator(model.vars):\r\n-    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n-\r\n-    # YOUR CODE HERE\r\n-    #\r\n-    # jptEntry will be a dictionary with a key for every variable in the model,\r\n-    #   and the loop will go over every possible combination of True/False for each variable\r\n-    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n-    #\r\n-    # Your task is to collect all the probabilities that match the evidence, and query\r\n-    #\r\n-    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n-    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n-    #\r\n-    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n-    #\r\n-    # (Reference solution is 4 lines of code.)\r\n-    if dict_issubset(jptEntry, evidence):\r\n-            pr_QE += pr_entry\r\n-            if jptEntry[queryVar] == queryVal:\r\n-                pr_E += pr_entry\r\n-  return pr_QE/pr_E\r\n-\r\n-def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n-  \"\"\"\r\n-  Calculate posterior probability for a given variable\r\n-\r\n-  model: model object, see read_model_file() for specification\r\n-  queryVar: string, query variable name\r\n-  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n-  evidence: dictionary of boolean values, where keys are evidence variable names\r\n-            (Any variable not listed as query or evidence is assumed to be hidden)\r\n-  \"\"\"\r\n-  \r\n-  # First step, we need to figure out what order we will calculate terms in and where\r\n-  # marginalization needs to happen.\r\n-  #\r\n-  # That said, though this is a part of the inference process that you need to know, it's a\r\n-  # bit tricky to get working in general, especially the optimization bits.\r\n-  #\r\n-  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n-  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n-  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n-  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n-  # For example, the formula on slide 20 would be represented as:\r\n-  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n-  # The formula on slide 21 would be:\r\n-  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n-  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n-  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n-  \r\n-  # Debug: Output a nicer version of the calculation order (inference formula)\r\n-  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n-  \r\n-  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n-  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n-  \r\n-  # Next step, implement the calculation\r\n-  #\r\n-  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n-  # and move on to implement the recurse_calc_query_exact_tree() function\r\n-  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n-  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n-  # and associated function and add your own calculation code here\r\n-  \r\n-  # YOUR CODE HERE\r\n-  #\r\n-  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n-  #\r\n-  # Normalize this result to get true probability.\r\n-  #\r\n-  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n-  #\r\n-  # Refer to the example on slide 30.\r\n-  #\r\n-  # (Reference solution is 3 lines of code.)\r\n-  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n-  \"\"\"\r\n-  Recursiving process the summation tree \r\n-  \r\n-  model,queryVar,evidence: See calc_query_exact_tree()\r\n-  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n-    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n-  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n-  \"\"\"\r\n-  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n-\r\n-  # Your overall task in the function is to assign values to:\r\n-  #   prQ_T\r\n-  #   prQ_F\r\n-  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n-  # covering both cases where query=True and query=False.\r\n-\r\n-  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n-  if marginalize:\r\n-    #Summation term, need to branch over all possible values and continue calculation\r\n-    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n-\r\n-    # YOUR CODE HERE\r\n-    #\r\n-    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n-    # calculation\r\n-    #\r\n-    # You will need to recurse for each element of the summation (i.e. each branch)\r\n-    # Then properly combine the results together\r\n-    #\r\n-    # Slides 26-28 show examples of resolving summations.\r\n-    #\r\n-    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n-    #   BUT remember to change it back to the original values when you are done!\r\n-    #   (The original value for unknown variables is None.)\r\n-    #\r\n-    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n-    #   example of how to make the recursive call(s)\r\n-    #\r\n-    # (Reference solution is 7 lines of code.)\r\n-    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-  else:\r\n-    #Probability term, calculate conditional probability for this variable and continue calculation\r\n-    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n-    if queryVar in model.varDist[var].parents:\r\n-      #Query variable is a condition for this term\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n-      #\r\n-      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n-      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n-      # consider both what happens when the query variable is True, and also when it is False.\r\n-      #\r\n-      # Copy from your code below and modify to deal with this additional element.\r\n-      #\r\n-      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n-      #\r\n-      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n-      #   BUT remember to change it back to the original values when you are done!\r\n-      #\r\n-      # (Reference solution is 11 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-    elif var==queryVar:\r\n-      #This term is probability _for_ the Query variable\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one second! (Atleast, I recommend this.)\r\n-      #\r\n-      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n-      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n-      # is False.\r\n-      #\r\n-      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n-      # \r\n-      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n-      #\r\n-      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n-      #   BUT remember to change it back to the original values when you are done!\r\n-      #\r\n-      # (Reference solution is 5 additional lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-    else:\r\n-      #Simple term, no need to worry about query variable\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one first! (It's the simplest of the three.)\r\n-      #\r\n-      # You need to get the conditional probability for this variable and correctly\r\n-      # combine it with the results of the recursive call above.\r\n-      #\r\n-      # Don't forget that this variable's value could be True or False!\r\n-      #\r\n-      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n-      #\r\n-      # (Reference solution is 5 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-    if len(remainingCalc)>1:\r\n-      #If there are still terms left, then recurse\r\n-      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n-      \r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Update prQ_T, prQ_F with the results from the recursive call.\r\n-      #\r\n-      # How do you combine _factors_ together?\r\n-      #\r\n-      # (Reference solution is 2 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n-  \r\n-##############################################################################\r\n-## Support code\r\n-def read_cpt(model,varName,condVals):\r\n-  \"\"\"\r\n-  Read conditional probability for a specified variable with provided condition (parent) values\r\n-  Note, the value returned is conditional probability for variable being True\r\n-  \r\n-  Warning: If you get an index exception and referenced key has None in it, this means\r\n-    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n-  \r\n-  model: model object, see read_model_file() for specification\r\n-  varName: string, variable name to read probability for\r\n-  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n-              (Missing conditions will cause errors, extraneous values will be ignored)\r\n-  \"\"\"\r\n-  if varName not in model.varDist:\r\n-    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n-  varDist=model.varDist[varName]\r\n-  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n-  if key not in varDist.cpt:\r\n-    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n-  return varDist.cpt[key]\r\n-\r\n-def truefalse_combination_iterator(entries):\r\n-  \"\"\"\r\n-  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n-  \"\"\"\r\n-  entries=list(entries)\r\n-  entries.reverse()\r\n-  if len(entries)>30:\r\n-    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n-  for c in range(1<<len(entries)):\r\n-    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n-\r\n-def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n-  \"\"\"\r\n-  Create represention of terms in an inference calculation such as on slides 20-21\r\n-  \r\n-  Returns a list of (boolean,string) tuples where:\r\n-    (True,variable) represents a summation term where a variable needs to be marginalized\r\n-    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n-  \"\"\"\r\n-  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Naive solution\r\n-  #\r\n-  # model.varsDep already has variables in order of dependency...\r\n-  # So take that and insert summation terms any time we encounter a new hidden variable\r\n-  #\r\n-  # Downside is little optimization, likely to have many unnecessary terms\r\n-  if False:\r\n-    hiddenLeft=set(hiddenVars)\r\n-    seq=[]\r\n-    for v in model.varsDep:\r\n-      #Check if factor variable is a (unhandled) hidden variable\r\n-      if v in hiddenLeft:\r\n-        seq.append( (True,v) ) #If so, trigger a marginalization\r\n-        hiddenLeft.remove(v)   #And mark it as handled\r\n-      for p in model.varDist[v].parents:\r\n-        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n-        if p in hiddenLeft:\r\n-          seq.append( (True,p) )\r\n-          hiddenLeft.remove(p)\r\n-      seq.append( (False,v) ) #Then process the factor itself\r\n-    assert(len(hiddenLeft)==0)\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Arbitrary ordering\r\n-  #\r\n-  # What if we wanted to handle hidden variables in an arbitrary order?\r\n-  #\r\n-  # Possible, but we'll have to be careful where we put factors, after\r\n-  # all their dependencies are satisfied.\r\n-  def seq_from_hid_order(hOrd):\r\n-    #The trick to make this work is to first assign every\r\n-    #hidden variable a priority based on the order\r\n-    prio={h:i for i,h in enumerate(hOrd)}\r\n-    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n-    #Then rate each factor on the highest priority amongst its dependencies\r\n-    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n-    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n-    vOrd.sort()\r\n-    #All that's left is to turn it into the expected sequence format\r\n-    return list( (not nm,v) for _,nm,v in vOrd )\r\n-  \r\n-  #--------------------------------------------------------\r\n-  # Brute force best\r\n-  #\r\n-  # Now, where to get an ordering to use the above?\r\n-  #\r\n-  # We could brute force try every possible ordering...\r\n-  if True:\r\n-    bestSeq=None\r\n-    bestSeqCost=sys.maxsize\r\n-    for hOrd in permutations(hiddenVars):\r\n-      tSeq=seq_from_hid_order(hOrd)\r\n-      #Note, really should do below norm optimization here too\r\n-      \r\n-      #Now the tricky bit is to rate each ordering\r\n-      #We'll do it by doubling the cost of each factor every time\r\n-      #We cross a summation\r\n-      tot=0\r\n-      ct=1\r\n-      for m,v in tSeq:\r\n-        if m:\r\n-          ct*=2\r\n-        else:\r\n-          tot+=ct\r\n-      \r\n-      if tot<bestSeqCost:\r\n-        bestSeq=tSeq\r\n-        bestSeqCost=tot\r\n-    seq=bestSeq\r\n-  # But this will be very expensive for large models\r\n-  #--------------------------------------------------------\r\n-  # Greedy\r\n-  #\r\n-  # Alternately, we could apply a greedy approach.\r\n-  #\r\n-  # Some how rate each hidden variable on how expensive we think\r\n-  # it is, then put the most expensive ones earliest\r\n-  # ***TODO***\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Simple normalization optimization\r\n-  #\r\n-  # One thing we learned is that for a multiplicative term,\r\n-  # if it doesn't mention the query variable, then it's a\r\n-  # constant and can be handled via normalization (folded into alpha)\r\n-  #\r\n-  # This is non-trivial to detect for summation terms, but we\r\n-  # can easily do it for factors outside of any summation...\r\n-  if True:\r\n-    i=0\r\n-    while i<len(seq):\r\n-      m,v=seq[i]\r\n-      if m:\r\n-        break #Found first summation, quit\r\n-      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n-        #No mention of query variable, remove\r\n-        del seq[i]\r\n-      else:\r\n-        i+=1\r\n-  \r\n-  return seq\r\n-\r\n-def calc_query_approx(model,queryVar,queryVal,evidence):\r\n-  raise NotImplementedError()\r\n-\r\n-def generate_joint_prob_table(model):\r\n-  \"\"\"\r\n-  Output a joint probability table for the provided model\r\n-  \"\"\"\r\n-  from tabulate import tabulate\r\n-  table=[]\r\n-  row=list(model.vars)\r\n-  row.append('Joint Pr')\r\n-  table.append(row)\r\n-  for varVals in truefalse_combination_iterator(model.vars):\r\n-    pr=calc_global_joint_prob(model,varVals)\r\n-    row=[varVals[x] for x in model.vars]\r\n-    row.append(pr)\r\n-    table.append(row)\r\n-  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n-  return\r\n-\r\n-def read_model_file(filename):\r\n-  \"\"\"\r\n-  Returns model object with the following elements:\r\n-    vars : list of strings\r\n-      The list of variables the model describes\r\n-      In alphabetical order\r\n-    varsDep : list of strings\r\n-      Same contents as 'vars' but in dependency order (parents come before children)\r\n-    varDist : dict of objects\r\n-      Distribution information for each variable\r\n-      Dictionary key is variable name\r\n-      Object has the following elements:\r\n-        parents : set of strings\r\n-        children : set of strings\r\n-        cpt : dict of numbers\r\n-          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n-          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n-            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n-  Model file format is as follows:\r\n-    Basic file format is Comma-Separated Value (.csv)\r\n-    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n-    Tables are separated by atleast one empty line\r\n-    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n-    Each table:\r\n-      Starts with a header row containing variable names\r\n-        The last name is the variable whose cond probability is being described\r\n-        Any preceding names are considered to be parent variables\r\n-      Following rows contain True/False values for each parent and probability for main variable being true\r\n-      Any missing parent value combinations will be assumed to be probability 0.5\r\n-    Only Bernoulli/Boolean variables can be represented in this file format\r\n-  \"\"\"\r\n-  class ModelObj:\r\n-    def __init__(self):\r\n-      self.vars=[]\r\n-      self.varsDep=None\r\n-      self.varDist={}\r\n-\r\n-  class VarObj:\r\n-    def __init__(self, parents, children, cpt):\r\n-      self.parents = parents\r\n-      self.children = children\r\n-      self.cpt = cpt\r\n-\r\n-  model=ModelObj()\r\n-  #--------------------------------------------------------\r\n-  #Read data from file\r\n-  with open(filename, newline='') as csvfile:\r\n-    csvreader = csv.reader(csvfile)\r\n-    \r\n-    rowNum=0\r\n-    var=None\r\n-    varIdx=None\r\n-    parents=None\r\n-    cpt=None\r\n-    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n-      rowNum+=1\r\n-      srow=''.join(row).strip()\r\n-      if srow.startswith('#'):\r\n-        continue #Comment line, skip\r\n-      if len(srow)==0:\r\n-        #Empty line\r\n-        if var is not None:\r\n-          #End current table\r\n-          model.vars.append(var)\r\n-          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n-          #Wait for new table\r\n-          var=None\r\n-          varIdx=None\r\n-          parents=None\r\n-          cpt=None\r\n-      elif var is None:\r\n-        #Start new table\r\n-        if len(row)>1:\r\n-          parents=row[0:-1]\r\n-        else:\r\n-          parents=[]\r\n-        varIdx=len(row)-1\r\n-        var=row[varIdx]\r\n-        cpt={}\r\n-      else:\r\n-        #Add new entry to table\r\n-        if len(row)<varIdx+1:\r\n-          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n-        if len(parents)>0:\r\n-          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n-        else:\r\n-          key=frozenset()\r\n-        cpt[key]=float(row[-1])\r\n-  model.vars.sort()\r\n-  #--------------------------------------------------------\r\n-  # Check distributions for missing entries\r\n-  vCheck=frozenset(model.vars)\r\n-  for var in model.vars: #Make sure every mentioned variable has an entry\r\n-    for p in model.varDist[var].parents:\r\n-      if p not in vCheck:\r\n-        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n-  for var in model.vars: #Check every cpt for missing rows\r\n-    varDist=model.varDist[var]\r\n-    missingCnt=0\r\n-    for varVals in truefalse_combination_iterator(varDist.parents):\r\n-      key=frozenset(((x,v) for x,v in varVals.items()))\r\n-      if key not in varDist.cpt:\r\n-        missingCnt+=1\r\n-        varDist.cpt[key]=0.5\r\n-    if missingCnt>0:\r\n-      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n-  #--------------------------------------------------------\r\n-  # Create children entries\r\n-  for var in model.vars:\r\n-    model.varDist[var].children=set()\r\n-  for var in model.vars:\r\n-    for p in model.varDist[var].parents:\r\n-      model.varDist[p].children.add(var)\r\n-  for var in model.vars:\r\n-    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n-  #--------------------------------------------------------\r\n-  # Create dependency ordering\r\n-  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n-  idx=0\r\n-  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n-  while idx<len(varsDep):\r\n-    var=varsDep[idx]\r\n-    for c in model.varDist[var].children:\r\n-      parentsLeft[c]-=1\r\n-      if parentsLeft[c]==0:\r\n-        #All parents have been visited, so dependencies of this child are met\r\n-        varsDep.append(c)\r\n-      elif parentsLeft[c]<0:\r\n-        #Repeat visit to a parent can only happen if a cycle exists\r\n-        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n-    idx+=1\r\n-  model.varsDep=varsDep\r\n-  #--------------------------------------------------------\r\n-  return model\r\n-\r\n-def print_model(model):\r\n-  \"\"\"\r\n-  Print a model object back out in pretty form\r\n-  \"\"\"\r\n-  from tabulate import tabulate\r\n-  for v in model.vars:\r\n-    varDist=model.varDist[v]\r\n-    print('--------------------------------------------------')\r\n-    print('Variable:',v)\r\n-    print('--------------------------------------------------')\r\n-    print('Children:',', '.join(varDist.children))\r\n-    \r\n-    table=[]\r\n-    row=list(varDist.parents)\r\n-    row.append('P({0}=T|...)'.format(v))\r\n-    table.append(row)\r\n-    for varVals in truefalse_combination_iterator(varDist.parents):\r\n-      pr=read_cpt(model,v,varVals)\r\n-      row=[varVals[x] for x in varDist.parents]\r\n-      row.append(pr)\r\n-      table.append(row)\r\n-    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n-    print(\"\")\r\n-    \r\n-##############################################################################\r\n-## Main functions\r\n-def main(args):\r\n-  global DEBUG_OUTPUT\r\n-  if args.debug:\r\n-    DEBUG_OUTPUT=1\r\n-  #Argument checking plus additional parsing\r\n-  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n-    error('Arguments --query and --evidence not allowed in table mode')\r\n-  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n-    error('Arguments --query and --evidence not allowed in print mode')\r\n-  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n-    error('Argument --query required in inference modes')\r\n-  elif args.query is not None:\r\n-    if '=' not in args.query:\r\n-      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n-    s=args.query.split('=')\r\n-    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n-  if args.evidence is None:\r\n-    args.evidence=[]\r\n-  else:\r\n-    ev=[]\r\n-    for e in args.evidence:\r\n-      if '=' not in e:\r\n-        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n-      s=e.split('=')\r\n-      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n-    args.evidence={ var:val for var,val in ev }\r\n-\r\n-  print('Reading model from',args.model)\r\n-  model=read_model_file(args.model)\r\n-\r\n-  if args.mode=='table':\r\n-    generate_joint_prob_table(model)\r\n-  elif args.mode=='print':\r\n-    print_model(model)\r\n-  else:\r\n-    #One of the inference modes\r\n-    #Check inputs against model\r\n-    if args.query[0] not in model.vars:\r\n-      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n-    for var,val in args.evidence.items():\r\n-      if var not in model.vars:\r\n-        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n-    #Output problem setup\r\n-    print(\"Inference mode:\",args.mode)\r\n-    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n-    if len(args.evidence)==0:\r\n-      print(\"No evidence\")\r\n-    else:\r\n-      print(\"Evidence:\")\r\n-      for var,val in args.evidence.items():\r\n-        print(\"  '{0}' is {1}\".format(var,val))\r\n-\r\n-    #Run inference\r\n-    pr=None\r\n-    if args.mode=='brute':\r\n-      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n-    elif args.mode=='tree':\r\n-      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n-    else: #args.mode=='approx'\r\n-      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n-    print('Probability is',pr)\r\n-\r\n-  return\r\n-\r\n-def error(msg):\r\n-  print(msg)\r\n-  sys.exit(1)\r\n-  return\r\n-\r\n-if __name__ == '__main__':\r\n-  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n-  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n-  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n-  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n-  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n-  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n-  args = parser.parse_args()\r\n-  error=lambda msg : parser.error(msg)\r\n-  main(args)\n-import argparse\r\n-import csv\r\n-from itertools import chain, permutations\r\n-import math\r\n-#import matplotlib.pyplot as plt\r\n-#import numpy as np\r\n-from random import random\r\n-import sys\r\n-\r\n-DEBUG_OUTPUT=0\r\n-\r\n-##############################################################################\r\n-## Student code\r\n-def calc_global_joint_prob(model, variableValues):\r\n-  \"\"\"\r\n-  Calculate the global joint probability of a model for a specific set of values\r\n-  model: model object, see read_model_file() for specification\r\n-  variableValues: dictionary of boolean values, keys are variable names\r\n-  \"\"\"\r\n-  \r\n-  # YOUR CODE HERE\r\n-  #\r\n-  # You may assume variableValues is complete, i.e containes all variables in the model\r\n-  #   Thus, no marginalization is necessary\r\n-  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n-  #\r\n-  # You can find a complete descrition of the model object in the documentation of\r\n-  #   the read_model_file() function, BUT\r\n-  # All you will need is the list of variables: model.vars\r\n-  #\r\n-  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n-  #\r\n-  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n-  #\r\n-  # (Reference solution is 7 lines of code.)\r\n-  joint_prob = 1.0\r\n-  for var in model.vars:\r\n-      cpt_entry = read_cpt(model, var, variableValues)\r\n-      if variableValues[var]:\r\n-          joint_prob *= cpt_entry\r\n-      else:\r\n-          joint_prob *= 1 - cpt_entry\r\n-  return joint_prob\r\n-\r\n-def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n-  \"\"\"\r\n-  Calculate posterior probability for a given variable\r\n-\r\n-  model: model object, see read_model_file() for specification\r\n-  queryVar: string, query variable name\r\n-  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n-  evidence: dictionary of boolean values, where keys are evidence variable names\r\n-            (Any variable not listed as query or evidence is assumed to be hidden)\r\n-  \"\"\"\r\n-\r\n-  # This first attempt at probabilistic inference will use the brute-force (table)\r\n-  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n-  #\r\n-  # This requires the calculation of two joint probabilities based on the definition\r\n-  # of conditional probability:\r\n-  #                          Pr( Query & Evidence )\r\n-  #   Pr(Query | Evidence) = ----------------------\r\n-  #                              Pr( Evidence )\r\n-  #\r\n-  # Both of these joint probabilities can be calculated by going over every entry in\r\n-  # the global joint probability table and summing up the probabilities of those\r\n-  # entries that match what we're looking for\r\n-  \r\n-  def dict_issubset(d,sub):\r\n-    \"\"\"\r\n-    Returns True if every key,value pair in sub has a matching key and value in d\r\n-    Note: sub should not contain any entries with value None\r\n-    \"\"\"\r\n-    return all(d.get(key,None)==val for key,val in sub.items())\r\n-     \r\n-  pr_QE=0\r\n-  pr_E=0\r\n-  for jptEntry in truefalse_combination_iterator(model.vars):\r\n-    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n-\r\n-    # YOUR CODE HERE\r\n-    #\r\n-    # jptEntry will be a dictionary with a key for every variable in the model,\r\n-    #   and the loop will go over every possible combination of True/False for each variable\r\n-    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n-    #\r\n-    # Your task is to collect all the probabilities that match the evidence, and query\r\n-    #\r\n-    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n-    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n-    #\r\n-    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n-    #\r\n-    # (Reference solution is 4 lines of code.)\r\n-    if dict_issubset(jptEntry, evidence):\r\n-            pr_QE += pr_entry\r\n-            if jptEntry[queryVar]:\r\n-                pr_E += pr_entry\r\n-  return pr_QE/pr_E\r\n-\r\n-def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n-  \"\"\"\r\n-  Calculate posterior probability for a given variable\r\n-\r\n-  model: model object, see read_model_file() for specification\r\n-  queryVar: string, query variable name\r\n-  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n-  evidence: dictionary of boolean values, where keys are evidence variable names\r\n-            (Any variable not listed as query or evidence is assumed to be hidden)\r\n-  \"\"\"\r\n-  \r\n-  # First step, we need to figure out what order we will calculate terms in and where\r\n-  # marginalization needs to happen.\r\n-  #\r\n-  # That said, though this is a part of the inference process that you need to know, it's a\r\n-  # bit tricky to get working in general, especially the optimization bits.\r\n-  #\r\n-  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n-  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n-  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n-  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n-  # For example, the formula on slide 20 would be represented as:\r\n-  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n-  # The formula on slide 21 would be:\r\n-  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n-  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n-  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n-  \r\n-  # Debug: Output a nicer version of the calculation order (inference formula)\r\n-  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n-  \r\n-  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n-  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n-  \r\n-  # Next step, implement the calculation\r\n-  #\r\n-  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n-  # and move on to implement the recurse_calc_query_exact_tree() function\r\n-  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n-  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n-  # and associated function and add your own calculation code here\r\n-  \r\n-  # YOUR CODE HERE\r\n-  #\r\n-  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n-  #\r\n-  # Normalize this result to get true probability.\r\n-  #\r\n-  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n-  #\r\n-  # Refer to the example on slide 30.\r\n-  #\r\n-  # (Reference solution is 3 lines of code.)\r\n-  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n-  \"\"\"\r\n-  Recursiving process the summation tree \r\n-  \r\n-  model,queryVar,evidence: See calc_query_exact_tree()\r\n-  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n-    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n-  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n-  \"\"\"\r\n-  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n-\r\n-  # Your overall task in the function is to assign values to:\r\n-  #   prQ_T\r\n-  #   prQ_F\r\n-  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n-  # covering both cases where query=True and query=False.\r\n-\r\n-  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n-  if marginalize:\r\n-    #Summation term, need to branch over all possible values and continue calculation\r\n-    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n-\r\n-    # YOUR CODE HERE\r\n-    #\r\n-    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n-    # calculation\r\n-    #\r\n-    # You will need to recurse for each element of the summation (i.e. each branch)\r\n-    # Then properly combine the results together\r\n-    #\r\n-    # Slides 26-28 show examples of resolving summations.\r\n-    #\r\n-    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n-    #   BUT remember to change it back to the original values when you are done!\r\n-    #   (The original value for unknown variables is None.)\r\n-    #\r\n-    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n-    #   example of how to make the recursive call(s)\r\n-    #\r\n-    # (Reference solution is 7 lines of code.)\r\n-    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-  else:\r\n-    #Probability term, calculate conditional probability for this variable and continue calculation\r\n-    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n-    if queryVar in model.varDist[var].parents:\r\n-      #Query variable is a condition for this term\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n-      #\r\n-      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n-      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n-      # consider both what happens when the query variable is True, and also when it is False.\r\n-      #\r\n-      # Copy from your code below and modify to deal with this additional element.\r\n-      #\r\n-      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n-      #\r\n-      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n-      #   BUT remember to change it back to the original values when you are done!\r\n-      #\r\n-      # (Reference solution is 11 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-    elif var==queryVar:\r\n-      #This term is probability _for_ the Query variable\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one second! (Atleast, I recommend this.)\r\n-      #\r\n-      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n-      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n-      # is False.\r\n-      #\r\n-      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n-      # \r\n-      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n-      #\r\n-      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n-      #   BUT remember to change it back to the original values when you are done!\r\n-      #\r\n-      # (Reference solution is 5 additional lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-    else:\r\n-      #Simple term, no need to worry about query variable\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one first! (It's the simplest of the three.)\r\n-      #\r\n-      # You need to get the conditional probability for this variable and correctly\r\n-      # combine it with the results of the recursive call above.\r\n-      #\r\n-      # Don't forget that this variable's value could be True or False!\r\n-      #\r\n-      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n-      #\r\n-      # (Reference solution is 5 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-    if len(remainingCalc)>1:\r\n-      #If there are still terms left, then recurse\r\n-      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n-      \r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Update prQ_T, prQ_F with the results from the recursive call.\r\n-      #\r\n-      # How do you combine _factors_ together?\r\n-      #\r\n-      # (Reference solution is 2 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n-\r\n-  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n-  \r\n-##############################################################################\r\n-## Support code\r\n-def read_cpt(model,varName,condVals):\r\n-  \"\"\"\r\n-  Read conditional probability for a specified variable with provided condition (parent) values\r\n-  Note, the value returned is conditional probability for variable being True\r\n-  \r\n-  Warning: If you get an index exception and referenced key has None in it, this means\r\n-    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n-  \r\n-  model: model object, see read_model_file() for specification\r\n-  varName: string, variable name to read probability for\r\n-  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n-              (Missing conditions will cause errors, extraneous values will be ignored)\r\n-  \"\"\"\r\n-  if varName not in model.varDist:\r\n-    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n-  varDist=model.varDist[varName]\r\n-  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n-  if key not in varDist.cpt:\r\n-    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n-  return varDist.cpt[key]\r\n-\r\n-def truefalse_combination_iterator(entries):\r\n-  \"\"\"\r\n-  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n-  \"\"\"\r\n-  entries=list(entries)\r\n-  entries.reverse()\r\n-  if len(entries)>30:\r\n-    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n-  for c in range(1<<len(entries)):\r\n-    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n-\r\n-def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n-  \"\"\"\r\n-  Create represention of terms in an inference calculation such as on slides 20-21\r\n-  \r\n-  Returns a list of (boolean,string) tuples where:\r\n-    (True,variable) represents a summation term where a variable needs to be marginalized\r\n-    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n-  \"\"\"\r\n-  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Naive solution\r\n-  #\r\n-  # model.varsDep already has variables in order of dependency...\r\n-  # So take that and insert summation terms any time we encounter a new hidden variable\r\n-  #\r\n-  # Downside is little optimization, likely to have many unnecessary terms\r\n-  if False:\r\n-    hiddenLeft=set(hiddenVars)\r\n-    seq=[]\r\n-    for v in model.varsDep:\r\n-      #Check if factor variable is a (unhandled) hidden variable\r\n-      if v in hiddenLeft:\r\n-        seq.append( (True,v) ) #If so, trigger a marginalization\r\n-        hiddenLeft.remove(v)   #And mark it as handled\r\n-      for p in model.varDist[v].parents:\r\n-        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n-        if p in hiddenLeft:\r\n-          seq.append( (True,p) )\r\n-          hiddenLeft.remove(p)\r\n-      seq.append( (False,v) ) #Then process the factor itself\r\n-    assert(len(hiddenLeft)==0)\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Arbitrary ordering\r\n-  #\r\n-  # What if we wanted to handle hidden variables in an arbitrary order?\r\n-  #\r\n-  # Possible, but we'll have to be careful where we put factors, after\r\n-  # all their dependencies are satisfied.\r\n-  def seq_from_hid_order(hOrd):\r\n-    #The trick to make this work is to first assign every\r\n-    #hidden variable a priority based on the order\r\n-    prio={h:i for i,h in enumerate(hOrd)}\r\n-    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n-    #Then rate each factor on the highest priority amongst its dependencies\r\n-    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n-    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n-    vOrd.sort()\r\n-    #All that's left is to turn it into the expected sequence format\r\n-    return list( (not nm,v) for _,nm,v in vOrd )\r\n-  \r\n-  #--------------------------------------------------------\r\n-  # Brute force best\r\n-  #\r\n-  # Now, where to get an ordering to use the above?\r\n-  #\r\n-  # We could brute force try every possible ordering...\r\n-  if True:\r\n-    bestSeq=None\r\n-    bestSeqCost=sys.maxsize\r\n-    for hOrd in permutations(hiddenVars):\r\n-      tSeq=seq_from_hid_order(hOrd)\r\n-      #Note, really should do below norm optimization here too\r\n-      \r\n-      #Now the tricky bit is to rate each ordering\r\n-      #We'll do it by doubling the cost of each factor every time\r\n-      #We cross a summation\r\n-      tot=0\r\n-      ct=1\r\n-      for m,v in tSeq:\r\n-        if m:\r\n-          ct*=2\r\n-        else:\r\n-          tot+=ct\r\n-      \r\n-      if tot<bestSeqCost:\r\n-        bestSeq=tSeq\r\n-        bestSeqCost=tot\r\n-    seq=bestSeq\r\n-  # But this will be very expensive for large models\r\n-  #--------------------------------------------------------\r\n-  # Greedy\r\n-  #\r\n-  # Alternately, we could apply a greedy approach.\r\n-  #\r\n-  # Some how rate each hidden variable on how expensive we think\r\n-  # it is, then put the most expensive ones earliest\r\n-  # ***TODO***\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Simple normalization optimization\r\n-  #\r\n-  # One thing we learned is that for a multiplicative term,\r\n-  # if it doesn't mention the query variable, then it's a\r\n-  # constant and can be handled via normalization (folded into alpha)\r\n-  #\r\n-  # This is non-trivial to detect for summation terms, but we\r\n-  # can easily do it for factors outside of any summation...\r\n-  if True:\r\n-    i=0\r\n-    while i<len(seq):\r\n-      m,v=seq[i]\r\n-      if m:\r\n-        break #Found first summation, quit\r\n-      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n-        #No mention of query variable, remove\r\n-        del seq[i]\r\n-      else:\r\n-        i+=1\r\n-  \r\n-  return seq\r\n-\r\n-def calc_query_approx(model,queryVar,queryVal,evidence):\r\n-  raise NotImplementedError()\r\n-\r\n-def generate_joint_prob_table(model):\r\n-  \"\"\"\r\n-  Output a joint probability table for the provided model\r\n-  \"\"\"\r\n-  from tabulate import tabulate\r\n-  table=[]\r\n-  row=list(model.vars)\r\n-  row.append('Joint Pr')\r\n-  table.append(row)\r\n-  for varVals in truefalse_combination_iterator(model.vars):\r\n-    pr=calc_global_joint_prob(model,varVals)\r\n-    row=[varVals[x] for x in model.vars]\r\n-    row.append(pr)\r\n-    table.append(row)\r\n-  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n-  return\r\n-\r\n-def read_model_file(filename):\r\n-  \"\"\"\r\n-  Returns model object with the following elements:\r\n-    vars : list of strings\r\n-      The list of variables the model describes\r\n-      In alphabetical order\r\n-    varsDep : list of strings\r\n-      Same contents as 'vars' but in dependency order (parents come before children)\r\n-    varDist : dict of objects\r\n-      Distribution information for each variable\r\n-      Dictionary key is variable name\r\n-      Object has the following elements:\r\n-        parents : set of strings\r\n-        children : set of strings\r\n-        cpt : dict of numbers\r\n-          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n-          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n-            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n-  Model file format is as follows:\r\n-    Basic file format is Comma-Separated Value (.csv)\r\n-    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n-    Tables are separated by atleast one empty line\r\n-    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n-    Each table:\r\n-      Starts with a header row containing variable names\r\n-        The last name is the variable whose cond probability is being described\r\n-        Any preceding names are considered to be parent variables\r\n-      Following rows contain True/False values for each parent and probability for main variable being true\r\n-      Any missing parent value combinations will be assumed to be probability 0.5\r\n-    Only Bernoulli/Boolean variables can be represented in this file format\r\n-  \"\"\"\r\n-  class ModelObj:\r\n-    def __init__(self):\r\n-      self.vars=[]\r\n-      self.varsDep=None\r\n-      self.varDist={}\r\n-\r\n-  class VarObj:\r\n-    def __init__(self, parents, children, cpt):\r\n-      self.parents = parents\r\n-      self.children = children\r\n-      self.cpt = cpt\r\n-\r\n-  model=ModelObj()\r\n-  #--------------------------------------------------------\r\n-  #Read data from file\r\n-  with open(filename, newline='') as csvfile:\r\n-    csvreader = csv.reader(csvfile)\r\n-    \r\n-    rowNum=0\r\n-    var=None\r\n-    varIdx=None\r\n-    parents=None\r\n-    cpt=None\r\n-    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n-      rowNum+=1\r\n-      srow=''.join(row).strip()\r\n-      if srow.startswith('#'):\r\n-        continue #Comment line, skip\r\n-      if len(srow)==0:\r\n-        #Empty line\r\n-        if var is not None:\r\n-          #End current table\r\n-          model.vars.append(var)\r\n-          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n-          #Wait for new table\r\n-          var=None\r\n-          varIdx=None\r\n-          parents=None\r\n-          cpt=None\r\n-      elif var is None:\r\n-        #Start new table\r\n-        if len(row)>1:\r\n-          parents=row[0:-1]\r\n-        else:\r\n-          parents=[]\r\n-        varIdx=len(row)-1\r\n-        var=row[varIdx]\r\n-        cpt={}\r\n-      else:\r\n-        #Add new entry to table\r\n-        if len(row)<varIdx+1:\r\n-          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n-        if len(parents)>0:\r\n-          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n-        else:\r\n-          key=frozenset()\r\n-        cpt[key]=float(row[-1])\r\n-  model.vars.sort()\r\n-  #--------------------------------------------------------\r\n-  # Check distributions for missing entries\r\n-  vCheck=frozenset(model.vars)\r\n-  for var in model.vars: #Make sure every mentioned variable has an entry\r\n-    for p in model.varDist[var].parents:\r\n-      if p not in vCheck:\r\n-        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n-  for var in model.vars: #Check every cpt for missing rows\r\n-    varDist=model.varDist[var]\r\n-    missingCnt=0\r\n-    for varVals in truefalse_combination_iterator(varDist.parents):\r\n-      key=frozenset(((x,v) for x,v in varVals.items()))\r\n-      if key not in varDist.cpt:\r\n-        missingCnt+=1\r\n-        varDist.cpt[key]=0.5\r\n-    if missingCnt>0:\r\n-      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n-  #--------------------------------------------------------\r\n-  # Create children entries\r\n-  for var in model.vars:\r\n-    model.varDist[var].children=set()\r\n-  for var in model.vars:\r\n-    for p in model.varDist[var].parents:\r\n-      model.varDist[p].children.add(var)\r\n-  for var in model.vars:\r\n-    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n-  #--------------------------------------------------------\r\n-  # Create dependency ordering\r\n-  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n-  idx=0\r\n-  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n-  while idx<len(varsDep):\r\n-    var=varsDep[idx]\r\n-    for c in model.varDist[var].children:\r\n-      parentsLeft[c]-=1\r\n-      if parentsLeft[c]==0:\r\n-        #All parents have been visited, so dependencies of this child are met\r\n-        varsDep.append(c)\r\n-      elif parentsLeft[c]<0:\r\n-        #Repeat visit to a parent can only happen if a cycle exists\r\n-        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n-    idx+=1\r\n-  model.varsDep=varsDep\r\n-  #--------------------------------------------------------\r\n-  return model\r\n-\r\n-def print_model(model):\r\n-  \"\"\"\r\n-  Print a model object back out in pretty form\r\n-  \"\"\"\r\n-  from tabulate import tabulate\r\n-  for v in model.vars:\r\n-    varDist=model.varDist[v]\r\n-    print('--------------------------------------------------')\r\n-    print('Variable:',v)\r\n-    print('--------------------------------------------------')\r\n-    print('Children:',', '.join(varDist.children))\r\n-    \r\n-    table=[]\r\n-    row=list(varDist.parents)\r\n-    row.append('P({0}=T|...)'.format(v))\r\n-    table.append(row)\r\n-    for varVals in truefalse_combination_iterator(varDist.parents):\r\n-      pr=read_cpt(model,v,varVals)\r\n-      row=[varVals[x] for x in varDist.parents]\r\n-      row.append(pr)\r\n-      table.append(row)\r\n-    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n-    print(\"\")\r\n-    \r\n-##############################################################################\r\n-## Main functions\r\n-def main(args):\r\n-  global DEBUG_OUTPUT\r\n-  if args.debug:\r\n-    DEBUG_OUTPUT=1\r\n-  #Argument checking plus additional parsing\r\n-  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n-    error('Arguments --query and --evidence not allowed in table mode')\r\n-  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n-    error('Arguments --query and --evidence not allowed in print mode')\r\n-  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n-    error('Argument --query required in inference modes')\r\n-  elif args.query is not None:\r\n-    if '=' not in args.query:\r\n-      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n-    s=args.query.split('=')\r\n-    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n-  if args.evidence is None:\r\n-    args.evidence=[]\r\n-  else:\r\n-    ev=[]\r\n-    for e in args.evidence:\r\n-      if '=' not in e:\r\n-        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n-      s=e.split('=')\r\n-      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n-    args.evidence={ var:val for var,val in ev }\r\n-\r\n-  print('Reading model from',args.model)\r\n-  model=read_model_file(args.model)\r\n-\r\n-  if args.mode=='table':\r\n-    generate_joint_prob_table(model)\r\n-  elif args.mode=='print':\r\n-    print_model(model)\r\n-  else:\r\n-    #One of the inference modes\r\n-    #Check inputs against model\r\n-    if args.query[0] not in model.vars:\r\n-      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n-    for var,val in args.evidence.items():\r\n-      if var not in model.vars:\r\n-        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n-    #Output problem setup\r\n-    print(\"Inference mode:\",args.mode)\r\n-    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n-    if len(args.evidence)==0:\r\n-      print(\"No evidence\")\r\n-    else:\r\n-      print(\"Evidence:\")\r\n-      for var,val in args.evidence.items():\r\n-        print(\"  '{0}' is {1}\".format(var,val))\r\n-\r\n-    #Run inference\r\n-    pr=None\r\n-    if args.mode=='brute':\r\n-      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n-    elif args.mode=='tree':\r\n-      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n-    else: #args.mode=='approx'\r\n-      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n-    print('Probability is',pr)\r\n-\r\n-  return\r\n-\r\n-def error(msg):\r\n-  print(msg)\r\n-  sys.exit(1)\r\n-  return\r\n-\r\n-if __name__ == '__main__':\r\n-  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n-  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n-  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n-  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n-  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n-  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n-  args = parser.parse_args()\r\n-  error=lambda msg : parser.error(msg)\r\n   main(args)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1699825008670,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -92,11 +92,11 @@\n     # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n     #\r\n     # (Reference solution is 4 lines of code.)\r\n     if dict_issubset(jptEntry, evidence):\r\n-            pr_QE -= pr_entry\r\n-            if jptEntry[queryVar] == queryVal:\r\n-                pr_E -= pr_entry\r\n+            pr_QE += pr_entry\r\n+    if jptEntry[queryVar] == queryVal:\r\n+            pr_E += pr_entry\r\n   return pr_QE/pr_E\r\n \r\n def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n   \"\"\"\r\n"
                },
                {
                    "date": 1699825042568,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -93,9 +93,8 @@\n     #\r\n     # (Reference solution is 4 lines of code.)\r\n     if dict_issubset(jptEntry, evidence):\r\n             pr_QE += pr_entry\r\n-    if jptEntry[queryVar] == queryVal:\r\n             pr_E += pr_entry\r\n   return pr_QE/pr_E\r\n \r\n def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n"
                },
                {
                    "date": 1699825084309,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -92,10 +92,11 @@\n     # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n     #\r\n     # (Reference solution is 4 lines of code.)\r\n     if dict_issubset(jptEntry, evidence):\r\n-            pr_QE += pr_entry\r\n             pr_E += pr_entry\r\n+            if jptEntry[queryVar] == queryVal:\r\n+              pr_QE += pr_entry\r\n   return pr_QE/pr_E\r\n \r\n def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n   \"\"\"\r\n"
                },
                {
                    "date": 1699826371624,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -138,9 +138,8 @@\n   # and move on to implement the recurse_calc_query_exact_tree() function\r\n   prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n   # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n   # and associated function and add your own calculation code here\r\n-  \r\n   # YOUR CODE HERE\r\n   #\r\n   # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n   #\r\n@@ -150,9 +149,15 @@\n   #\r\n   # Refer to the example on slide 30.\r\n   #\r\n   # (Reference solution is 3 lines of code.)\r\n-  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+  total_probability = prQ_T + prQ_F\r\n+  prQ_T /= total_probability\r\n+  prQ_F /= total_probability\r\n+  \r\n+  # Return the probability which answers the query\r\n+  return prQ_T if queryVal else prQ_F\r\n+  \r\n \r\n def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n   \"\"\"\r\n   Recursiving process the summation tree \r\n@@ -173,9 +178,8 @@\n   marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n   if marginalize:\r\n     #Summation term, need to branch over all possible values and continue calculation\r\n     if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n-\r\n     # YOUR CODE HERE\r\n     #\r\n     # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n     # calculation\r\n@@ -192,16 +196,27 @@\n     # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n     #   example of how to make the recursive call(s)\r\n     #\r\n     # (Reference solution is 7 lines of code.)\r\n-    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+    for value in [True, False]:\r\n+        # Update the variable value in the dictionary\r\n+        variableValues[var] = value\r\n+\r\n+        # Recurse for each element of the summation (each branch)\r\n+        prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+        # Combine the results together\r\n+        prQ_T += prR_T\r\n+        prQ_F += prR_F\r\n+\r\n+    # Restore the original value for the variable\r\n+    variableValues[var] = original_value\r\n   else:\r\n     #Probability term, calculate conditional probability for this variable and continue calculation\r\n     prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n     if queryVar in model.varDist[var].parents:\r\n       #Query variable is a condition for this term\r\n       if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n       # YOUR CODE HERE\r\n       #\r\n       # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n       #\r\n@@ -216,9 +231,26 @@\n       # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n       #   BUT remember to change it back to the original values when you are done!\r\n       #\r\n       # (Reference solution is 11 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+      original_value = variableValues[var]\r\n+\r\n+        # Iterate over both cases when the query variable is True and False\r\n+      for query_value in [True, False]:\r\n+            # Update the variable value in the dictionary\r\n+            variableValues[var] = query_value\r\n+\r\n+            # Recurse for each case\r\n+            prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+            # Combine the results together\r\n+            if query_value:\r\n+                prQ_T *= prR_T\r\n+            else:\r\n+                prQ_F *= prR_F\r\n+\r\n+        # Restore the original value for the variable\r\n+      variableValues[var] = original_value\r\n     elif var==queryVar:\r\n       #This term is probability _for_ the Query variable\r\n       if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n \r\n@@ -237,9 +269,26 @@\n       # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n       #   BUT remember to change it back to the original values when you are done!\r\n       #\r\n       # (Reference solution is 5 additional lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+      original_value = variableValues[var]\r\n+\r\n+        # Iterate over both cases when the query variable is True and False\r\n+      for query_value in [True, False]:\r\n+            # Update the variable value in the dictionary\r\n+            variableValues[var] = query_value\r\n+\r\n+            # Recurse for each case\r\n+            prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+            # Combine the results together\r\n+            if query_value:\r\n+                prQ_T *= prR_T\r\n+            else:\r\n+                prQ_F *= prR_F\r\n+\r\n+        # Restore the original value for the variable\r\n+      variableValues[var] = original_value\r\n     else:\r\n       #Simple term, no need to worry about query variable\r\n       if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n \r\n@@ -254,10 +303,14 @@\n       #\r\n       # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n       #\r\n       # (Reference solution is 5 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+      pr_var_T = model.get_prob(var, variableValues)\r\n \r\n+        # Update prQ_T, prQ_F with the conditional probability\r\n+      prQ_T *= pr_var_T\r\n+      prQ_F *= (1 - pr_var_T)\r\n+\r\n     if len(remainingCalc)>1:\r\n       #If there are still terms left, then recurse\r\n       prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n       \r\n@@ -267,9 +320,10 @@\n       #\r\n       # How do you combine _factors_ together?\r\n       #\r\n       # (Reference solution is 2 lines of code.)\r\n-      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n+      prQ_T *= prR_T\r\n+      prQ_F *= prR_F\r\n \r\n   return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n   \r\n ##############################################################################\r\n"
                },
                {
                    "date": 1699826509333,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,735 @@\n+import argparse\r\n+import csv\r\n+from itertools import chain, permutations\r\n+import math\r\n+#import matplotlib.pyplot as plt\r\n+#import numpy as np\r\n+from random import random\r\n+import sys\r\n+\r\n+DEBUG_OUTPUT=0\r\n+\r\n+##############################################################################\r\n+## Student code\r\n+def calc_global_joint_prob(model, variableValues):\r\n+  \"\"\"\r\n+  Calculate the global joint probability of a model for a specific set of values\r\n+  model: model object, see read_model_file() for specification\r\n+  variableValues: dictionary of boolean values, keys are variable names\r\n+  \"\"\"\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # You may assume variableValues is complete, i.e containes all variables in the model\r\n+  #   Thus, no marginalization is necessary\r\n+  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n+  #\r\n+  # You can find a complete descrition of the model object in the documentation of\r\n+  #   the read_model_file() function, BUT\r\n+  # All you will need is the list of variables: model.vars\r\n+  #\r\n+  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n+  #\r\n+  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n+  #\r\n+  # (Reference solution is 7 lines of code.)\r\n+  joint_prob = 1.0\r\n+  for var in model.vars:\r\n+      cpt_entry = read_cpt(model, var, variableValues)\r\n+      if variableValues[var]:\r\n+          joint_prob *= cpt_entry\r\n+      else:\r\n+          joint_prob *= 1 - cpt_entry\r\n+  return joint_prob\r\n+\r\n+def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+\r\n+  # This first attempt at probabilistic inference will use the brute-force (table)\r\n+  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n+  #\r\n+  # This requires the calculation of two joint probabilities based on the definition\r\n+  # of conditional probability:\r\n+  #                          Pr( Query & Evidence )\r\n+  #   Pr(Query | Evidence) = ----------------------\r\n+  #                              Pr( Evidence )\r\n+  #\r\n+  # Both of these joint probabilities can be calculated by going over every entry in\r\n+  # the global joint probability table and summing up the probabilities of those\r\n+  # entries that match what we're looking for\r\n+  \r\n+  def dict_issubset(d,sub):\r\n+    \"\"\"\r\n+    Returns True if every key,value pair in sub has a matching key and value in d\r\n+    Note: sub should not contain any entries with value None\r\n+    \"\"\"\r\n+    return all(d.get(key,None)==val for key,val in sub.items())\r\n+     \r\n+  pr_QE=0\r\n+  pr_E=0\r\n+  for jptEntry in truefalse_combination_iterator(model.vars):\r\n+    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # jptEntry will be a dictionary with a key for every variable in the model,\r\n+    #   and the loop will go over every possible combination of True/False for each variable\r\n+    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n+    #\r\n+    # Your task is to collect all the probabilities that match the evidence, and query\r\n+    #\r\n+    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n+    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n+    #\r\n+    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n+    #\r\n+    # (Reference solution is 4 lines of code.)\r\n+    if dict_issubset(jptEntry, evidence):\r\n+            pr_E += pr_entry\r\n+            if jptEntry[queryVar] == queryVal:\r\n+              pr_QE += pr_entry\r\n+  return pr_QE/pr_E\r\n+\r\n+def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+  \r\n+  # First step, we need to figure out what order we will calculate terms in and where\r\n+  # marginalization needs to happen.\r\n+  #\r\n+  # That said, though this is a part of the inference process that you need to know, it's a\r\n+  # bit tricky to get working in general, especially the optimization bits.\r\n+  #\r\n+  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n+  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n+  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n+  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n+  # For example, the formula on slide 20 would be represented as:\r\n+  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n+  # The formula on slide 21 would be:\r\n+  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n+  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n+  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n+  \r\n+  # Debug: Output a nicer version of the calculation order (inference formula)\r\n+  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n+  \r\n+  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n+  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n+  \r\n+  # Next step, implement the calculation\r\n+  #\r\n+  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n+  # and move on to implement the recurse_calc_query_exact_tree() function\r\n+  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n+  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n+  # and associated function and add your own calculation code here\r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n+  #\r\n+  # Normalize this result to get true probability.\r\n+  #\r\n+  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n+  #\r\n+  # Refer to the example on slide 30.\r\n+  #\r\n+  # (Reference solution is 3 lines of code.)\r\n+  total_probability = prQ_T + prQ_F\r\n+  prQ_T /= total_probability\r\n+  prQ_F /= total_probability\r\n+  \r\n+  # Return the probability which answers the query\r\n+  return prQ_T if queryVal else prQ_F\r\n+  \r\n+\r\n+def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n+  \"\"\"\r\n+  Recursiving process the summation tree \r\n+  \r\n+  model,queryVar,evidence: See calc_query_exact_tree()\r\n+  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n+    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n+  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n+  \"\"\"\r\n+  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n+\r\n+  # Your overall task in the function is to assign values to:\r\n+  #   prQ_T\r\n+  #   prQ_F\r\n+  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n+  # covering both cases where query=True and query=False.\r\n+\r\n+  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n+  if marginalize:\r\n+    #Summation term, need to branch over all possible values and continue calculation\r\n+    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n+    # calculation\r\n+    #\r\n+    # You will need to recurse for each element of the summation (i.e. each branch)\r\n+    # Then properly combine the results together\r\n+    #\r\n+    # Slides 26-28 show examples of resolving summations.\r\n+    #\r\n+    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n+    #   BUT remember to change it back to the original values when you are done!\r\n+    #   (The original value for unknown variables is None.)\r\n+    #\r\n+    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n+    #   example of how to make the recursive call(s)\r\n+    #\r\n+    # (Reference solution is 7 lines of code.)\r\n+    for value in [True, False]:\r\n+        # Update the variable value in the dictionary\r\n+        variableValues[var] = value\r\n+\r\n+        # Recurse for each element of the summation (each branch)\r\n+        \r\n+        # Combine the results together\r\n+        prQ_T += prR_T\r\n+        prQ_F += prR_F\r\n+        prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+    # Restore the original value for the variable\r\n+    variableValues[var] = original_value\r\n+  else:\r\n+    #Probability term, calculate conditional probability for this variable and continue calculation\r\n+    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n+    if queryVar in model.varDist[var].parents:\r\n+      #Query variable is a condition for this term\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n+      #\r\n+      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n+      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n+      # consider both what happens when the query variable is True, and also when it is False.\r\n+      #\r\n+      # Copy from your code below and modify to deal with this additional element.\r\n+      #\r\n+      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 11 lines of code.)\r\n+      original_value = variableValues[var]\r\n+\r\n+        # Iterate over both cases when the query variable is True and False\r\n+      for query_value in [True, False]:\r\n+            # Update the variable value in the dictionary\r\n+            variableValues[var] = query_value\r\n+\r\n+            # Recurse for each case\r\n+            prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+            # Combine the results together\r\n+            if query_value:\r\n+                prQ_T *= prR_T\r\n+            else:\r\n+                prQ_F *= prR_F\r\n+\r\n+        # Restore the original value for the variable\r\n+      variableValues[var] = original_value\r\n+    elif var==queryVar:\r\n+      #This term is probability _for_ the Query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one second! (Atleast, I recommend this.)\r\n+      #\r\n+      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n+      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n+      # is False.\r\n+      #\r\n+      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n+      # \r\n+      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 5 additional lines of code.)\r\n+      original_value = variableValues[var]\r\n+\r\n+        # Iterate over both cases when the query variable is True and False\r\n+      for query_value in [True, False]:\r\n+            # Update the variable value in the dictionary\r\n+            variableValues[var] = query_value\r\n+\r\n+            # Recurse for each case\r\n+            prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+            # Combine the results together\r\n+            if query_value:\r\n+                prQ_T *= prR_T\r\n+            else:\r\n+                prQ_F *= prR_F\r\n+\r\n+        # Restore the original value for the variable\r\n+      variableValues[var] = original_value\r\n+    else:\r\n+      #Simple term, no need to worry about query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one first! (It's the simplest of the three.)\r\n+      #\r\n+      # You need to get the conditional probability for this variable and correctly\r\n+      # combine it with the results of the recursive call above.\r\n+      #\r\n+      # Don't forget that this variable's value could be True or False!\r\n+      #\r\n+      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n+      #\r\n+      # (Reference solution is 5 lines of code.)\r\n+      pr_var_T = model.get_prob(var, variableValues)\r\n+\r\n+        # Update prQ_T, prQ_F with the conditional probability\r\n+      prQ_T *= pr_var_T\r\n+      prQ_F *= (1 - pr_var_T)\r\n+\r\n+    if len(remainingCalc)>1:\r\n+      #If there are still terms left, then recurse\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n+      \r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Update prQ_T, prQ_F with the results from the recursive call.\r\n+      #\r\n+      # How do you combine _factors_ together?\r\n+      #\r\n+      # (Reference solution is 2 lines of code.)\r\n+      prQ_T *= prR_T\r\n+      prQ_F *= prR_F\r\n+\r\n+  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n+  \r\n+##############################################################################\r\n+## Support code\r\n+def read_cpt(model,varName,condVals):\r\n+  \"\"\"\r\n+  Read conditional probability for a specified variable with provided condition (parent) values\r\n+  Note, the value returned is conditional probability for variable being True\r\n+  \r\n+  Warning: If you get an index exception and referenced key has None in it, this means\r\n+    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n+  \r\n+  model: model object, see read_model_file() for specification\r\n+  varName: string, variable name to read probability for\r\n+  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n+              (Missing conditions will cause errors, extraneous values will be ignored)\r\n+  \"\"\"\r\n+  if varName not in model.varDist:\r\n+    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n+  varDist=model.varDist[varName]\r\n+  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n+  if key not in varDist.cpt:\r\n+    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n+  return varDist.cpt[key]\r\n+\r\n+def truefalse_combination_iterator(entries):\r\n+  \"\"\"\r\n+  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n+  \"\"\"\r\n+  entries=list(entries)\r\n+  entries.reverse()\r\n+  if len(entries)>30:\r\n+    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n+  for c in range(1<<len(entries)):\r\n+    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n+\r\n+def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n+  \"\"\"\r\n+  Create represention of terms in an inference calculation such as on slides 20-21\r\n+  \r\n+  Returns a list of (boolean,string) tuples where:\r\n+    (True,variable) represents a summation term where a variable needs to be marginalized\r\n+    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n+  \"\"\"\r\n+  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Naive solution\r\n+  #\r\n+  # model.varsDep already has variables in order of dependency...\r\n+  # So take that and insert summation terms any time we encounter a new hidden variable\r\n+  #\r\n+  # Downside is little optimization, likely to have many unnecessary terms\r\n+  if False:\r\n+    hiddenLeft=set(hiddenVars)\r\n+    seq=[]\r\n+    for v in model.varsDep:\r\n+      #Check if factor variable is a (unhandled) hidden variable\r\n+      if v in hiddenLeft:\r\n+        seq.append( (True,v) ) #If so, trigger a marginalization\r\n+        hiddenLeft.remove(v)   #And mark it as handled\r\n+      for p in model.varDist[v].parents:\r\n+        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n+        if p in hiddenLeft:\r\n+          seq.append( (True,p) )\r\n+          hiddenLeft.remove(p)\r\n+      seq.append( (False,v) ) #Then process the factor itself\r\n+    assert(len(hiddenLeft)==0)\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Arbitrary ordering\r\n+  #\r\n+  # What if we wanted to handle hidden variables in an arbitrary order?\r\n+  #\r\n+  # Possible, but we'll have to be careful where we put factors, after\r\n+  # all their dependencies are satisfied.\r\n+  def seq_from_hid_order(hOrd):\r\n+    #The trick to make this work is to first assign every\r\n+    #hidden variable a priority based on the order\r\n+    prio={h:i for i,h in enumerate(hOrd)}\r\n+    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n+    #Then rate each factor on the highest priority amongst its dependencies\r\n+    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n+    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n+    vOrd.sort()\r\n+    #All that's left is to turn it into the expected sequence format\r\n+    return list( (not nm,v) for _,nm,v in vOrd )\r\n+  \r\n+  #--------------------------------------------------------\r\n+  # Brute force best\r\n+  #\r\n+  # Now, where to get an ordering to use the above?\r\n+  #\r\n+  # We could brute force try every possible ordering...\r\n+  if True:\r\n+    bestSeq=None\r\n+    bestSeqCost=sys.maxsize\r\n+    for hOrd in permutations(hiddenVars):\r\n+      tSeq=seq_from_hid_order(hOrd)\r\n+      #Note, really should do below norm optimization here too\r\n+      \r\n+      #Now the tricky bit is to rate each ordering\r\n+      #We'll do it by doubling the cost of each factor every time\r\n+      #We cross a summation\r\n+      tot=0\r\n+      ct=1\r\n+      for m,v in tSeq:\r\n+        if m:\r\n+          ct*=2\r\n+        else:\r\n+          tot+=ct\r\n+      \r\n+      if tot<bestSeqCost:\r\n+        bestSeq=tSeq\r\n+        bestSeqCost=tot\r\n+    seq=bestSeq\r\n+  # But this will be very expensive for large models\r\n+  #--------------------------------------------------------\r\n+  # Greedy\r\n+  #\r\n+  # Alternately, we could apply a greedy approach.\r\n+  #\r\n+  # Some how rate each hidden variable on how expensive we think\r\n+  # it is, then put the most expensive ones earliest\r\n+  # ***TODO***\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Simple normalization optimization\r\n+  #\r\n+  # One thing we learned is that for a multiplicative term,\r\n+  # if it doesn't mention the query variable, then it's a\r\n+  # constant and can be handled via normalization (folded into alpha)\r\n+  #\r\n+  # This is non-trivial to detect for summation terms, but we\r\n+  # can easily do it for factors outside of any summation...\r\n+  if True:\r\n+    i=0\r\n+    while i<len(seq):\r\n+      m,v=seq[i]\r\n+      if m:\r\n+        break #Found first summation, quit\r\n+      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n+        #No mention of query variable, remove\r\n+        del seq[i]\r\n+      else:\r\n+        i+=1\r\n+  \r\n+  return seq\r\n+\r\n+def calc_query_approx(model,queryVar,queryVal,evidence):\r\n+  raise NotImplementedError()\r\n+\r\n+def generate_joint_prob_table(model):\r\n+  \"\"\"\r\n+  Output a joint probability table for the provided model\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  table=[]\r\n+  row=list(model.vars)\r\n+  row.append('Joint Pr')\r\n+  table.append(row)\r\n+  for varVals in truefalse_combination_iterator(model.vars):\r\n+    pr=calc_global_joint_prob(model,varVals)\r\n+    row=[varVals[x] for x in model.vars]\r\n+    row.append(pr)\r\n+    table.append(row)\r\n+  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+  return\r\n+\r\n+def read_model_file(filename):\r\n+  \"\"\"\r\n+  Returns model object with the following elements:\r\n+    vars : list of strings\r\n+      The list of variables the model describes\r\n+      In alphabetical order\r\n+    varsDep : list of strings\r\n+      Same contents as 'vars' but in dependency order (parents come before children)\r\n+    varDist : dict of objects\r\n+      Distribution information for each variable\r\n+      Dictionary key is variable name\r\n+      Object has the following elements:\r\n+        parents : set of strings\r\n+        children : set of strings\r\n+        cpt : dict of numbers\r\n+          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n+          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n+            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n+  Model file format is as follows:\r\n+    Basic file format is Comma-Separated Value (.csv)\r\n+    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n+    Tables are separated by atleast one empty line\r\n+    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n+    Each table:\r\n+      Starts with a header row containing variable names\r\n+        The last name is the variable whose cond probability is being described\r\n+        Any preceding names are considered to be parent variables\r\n+      Following rows contain True/False values for each parent and probability for main variable being true\r\n+      Any missing parent value combinations will be assumed to be probability 0.5\r\n+    Only Bernoulli/Boolean variables can be represented in this file format\r\n+  \"\"\"\r\n+  class ModelObj:\r\n+    def __init__(self):\r\n+      self.vars=[]\r\n+      self.varsDep=None\r\n+      self.varDist={}\r\n+\r\n+  class VarObj:\r\n+    def __init__(self, parents, children, cpt):\r\n+      self.parents = parents\r\n+      self.children = children\r\n+      self.cpt = cpt\r\n+\r\n+  model=ModelObj()\r\n+  #--------------------------------------------------------\r\n+  #Read data from file\r\n+  with open(filename, newline='') as csvfile:\r\n+    csvreader = csv.reader(csvfile)\r\n+    \r\n+    rowNum=0\r\n+    var=None\r\n+    varIdx=None\r\n+    parents=None\r\n+    cpt=None\r\n+    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n+      rowNum+=1\r\n+      srow=''.join(row).strip()\r\n+      if srow.startswith('#'):\r\n+        continue #Comment line, skip\r\n+      if len(srow)==0:\r\n+        #Empty line\r\n+        if var is not None:\r\n+          #End current table\r\n+          model.vars.append(var)\r\n+          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n+          #Wait for new table\r\n+          var=None\r\n+          varIdx=None\r\n+          parents=None\r\n+          cpt=None\r\n+      elif var is None:\r\n+        #Start new table\r\n+        if len(row)>1:\r\n+          parents=row[0:-1]\r\n+        else:\r\n+          parents=[]\r\n+        varIdx=len(row)-1\r\n+        var=row[varIdx]\r\n+        cpt={}\r\n+      else:\r\n+        #Add new entry to table\r\n+        if len(row)<varIdx+1:\r\n+          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n+        if len(parents)>0:\r\n+          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n+        else:\r\n+          key=frozenset()\r\n+        cpt[key]=float(row[-1])\r\n+  model.vars.sort()\r\n+  #--------------------------------------------------------\r\n+  # Check distributions for missing entries\r\n+  vCheck=frozenset(model.vars)\r\n+  for var in model.vars: #Make sure every mentioned variable has an entry\r\n+    for p in model.varDist[var].parents:\r\n+      if p not in vCheck:\r\n+        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n+  for var in model.vars: #Check every cpt for missing rows\r\n+    varDist=model.varDist[var]\r\n+    missingCnt=0\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      key=frozenset(((x,v) for x,v in varVals.items()))\r\n+      if key not in varDist.cpt:\r\n+        missingCnt+=1\r\n+        varDist.cpt[key]=0.5\r\n+    if missingCnt>0:\r\n+      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n+  #--------------------------------------------------------\r\n+  # Create children entries\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=set()\r\n+  for var in model.vars:\r\n+    for p in model.varDist[var].parents:\r\n+      model.varDist[p].children.add(var)\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n+  #--------------------------------------------------------\r\n+  # Create dependency ordering\r\n+  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n+  idx=0\r\n+  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n+  while idx<len(varsDep):\r\n+    var=varsDep[idx]\r\n+    for c in model.varDist[var].children:\r\n+      parentsLeft[c]-=1\r\n+      if parentsLeft[c]==0:\r\n+        #All parents have been visited, so dependencies of this child are met\r\n+        varsDep.append(c)\r\n+      elif parentsLeft[c]<0:\r\n+        #Repeat visit to a parent can only happen if a cycle exists\r\n+        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n+    idx+=1\r\n+  model.varsDep=varsDep\r\n+  #--------------------------------------------------------\r\n+  return model\r\n+\r\n+def print_model(model):\r\n+  \"\"\"\r\n+  Print a model object back out in pretty form\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  for v in model.vars:\r\n+    varDist=model.varDist[v]\r\n+    print('--------------------------------------------------')\r\n+    print('Variable:',v)\r\n+    print('--------------------------------------------------')\r\n+    print('Children:',', '.join(varDist.children))\r\n+    \r\n+    table=[]\r\n+    row=list(varDist.parents)\r\n+    row.append('P({0}=T|...)'.format(v))\r\n+    table.append(row)\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      pr=read_cpt(model,v,varVals)\r\n+      row=[varVals[x] for x in varDist.parents]\r\n+      row.append(pr)\r\n+      table.append(row)\r\n+    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+    print(\"\")\r\n+    \r\n+##############################################################################\r\n+## Main functions\r\n+def main(args):\r\n+  global DEBUG_OUTPUT\r\n+  if args.debug:\r\n+    DEBUG_OUTPUT=1\r\n+  #Argument checking plus additional parsing\r\n+  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in table mode')\r\n+  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in print mode')\r\n+  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n+    error('Argument --query required in inference modes')\r\n+  elif args.query is not None:\r\n+    if '=' not in args.query:\r\n+      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n+    s=args.query.split('=')\r\n+    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n+  if args.evidence is None:\r\n+    args.evidence=[]\r\n+  else:\r\n+    ev=[]\r\n+    for e in args.evidence:\r\n+      if '=' not in e:\r\n+        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n+      s=e.split('=')\r\n+      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n+    args.evidence={ var:val for var,val in ev }\r\n+\r\n+  print('Reading model from',args.model)\r\n+  model=read_model_file(args.model)\r\n+\r\n+  if args.mode=='table':\r\n+    generate_joint_prob_table(model)\r\n+  elif args.mode=='print':\r\n+    print_model(model)\r\n+  else:\r\n+    #One of the inference modes\r\n+    #Check inputs against model\r\n+    if args.query[0] not in model.vars:\r\n+      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n+    for var,val in args.evidence.items():\r\n+      if var not in model.vars:\r\n+        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n+    #Output problem setup\r\n+    print(\"Inference mode:\",args.mode)\r\n+    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n+    if len(args.evidence)==0:\r\n+      print(\"No evidence\")\r\n+    else:\r\n+      print(\"Evidence:\")\r\n+      for var,val in args.evidence.items():\r\n+        print(\"  '{0}' is {1}\".format(var,val))\r\n+\r\n+    #Run inference\r\n+    pr=None\r\n+    if args.mode=='brute':\r\n+      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n+    elif args.mode=='tree':\r\n+      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n+    else: #args.mode=='approx'\r\n+      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n+    print('Probability is',pr)\r\n+\r\n+  return\r\n+\r\n+def error(msg):\r\n+  print(msg)\r\n+  sys.exit(1)\r\n+  return\r\n+\r\n+if __name__ == '__main__':\r\n+  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n+  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n+  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n+  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n+  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n+  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n+  args = parser.parse_args()\r\n+  error=lambda msg : parser.error(msg)\r\n+  main(args)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1699826701813,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -201,13 +201,13 @@\n         # Update the variable value in the dictionary\r\n         variableValues[var] = value\r\n \r\n         # Recurse for each element of the summation (each branch)\r\n-        \r\n+        prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n         # Combine the results together\r\n         prQ_T += prR_T\r\n         prQ_F += prR_F\r\n-        prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n \r\n     # Restore the original value for the variable\r\n     variableValues[var] = original_value\r\n   else:\r\n@@ -304,748 +304,13 @@\n       # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n       #\r\n       # (Reference solution is 5 lines of code.)\r\n       pr_var_T = model.get_prob(var, variableValues)\r\n-\r\n-        # Update prQ_T, prQ_F with the conditional probability\r\n-      prQ_T *= pr_var_T\r\n-      prQ_F *= (1 - pr_var_T)\r\n-\r\n-    if len(remainingCalc)>1:\r\n-      #If there are still terms left, then recurse\r\n-      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n-      \r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Update prQ_T, prQ_F with the results from the recursive call.\r\n-      #\r\n-      # How do you combine _factors_ together?\r\n-      #\r\n-      # (Reference solution is 2 lines of code.)\r\n-      prQ_T *= prR_T\r\n-      prQ_F *= prR_F\r\n-\r\n-  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n-  \r\n-##############################################################################\r\n-## Support code\r\n-def read_cpt(model,varName,condVals):\r\n-  \"\"\"\r\n-  Read conditional probability for a specified variable with provided condition (parent) values\r\n-  Note, the value returned is conditional probability for variable being True\r\n-  \r\n-  Warning: If you get an index exception and referenced key has None in it, this means\r\n-    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n-  \r\n-  model: model object, see read_model_file() for specification\r\n-  varName: string, variable name to read probability for\r\n-  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n-              (Missing conditions will cause errors, extraneous values will be ignored)\r\n-  \"\"\"\r\n-  if varName not in model.varDist:\r\n-    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n-  varDist=model.varDist[varName]\r\n-  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n-  if key not in varDist.cpt:\r\n-    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n-  return varDist.cpt[key]\r\n-\r\n-def truefalse_combination_iterator(entries):\r\n-  \"\"\"\r\n-  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n-  \"\"\"\r\n-  entries=list(entries)\r\n-  entries.reverse()\r\n-  if len(entries)>30:\r\n-    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n-  for c in range(1<<len(entries)):\r\n-    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n-\r\n-def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n-  \"\"\"\r\n-  Create represention of terms in an inference calculation such as on slides 20-21\r\n-  \r\n-  Returns a list of (boolean,string) tuples where:\r\n-    (True,variable) represents a summation term where a variable needs to be marginalized\r\n-    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n-  \"\"\"\r\n-  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Naive solution\r\n-  #\r\n-  # model.varsDep already has variables in order of dependency...\r\n-  # So take that and insert summation terms any time we encounter a new hidden variable\r\n-  #\r\n-  # Downside is little optimization, likely to have many unnecessary terms\r\n-  if False:\r\n-    hiddenLeft=set(hiddenVars)\r\n-    seq=[]\r\n-    for v in model.varsDep:\r\n-      #Check if factor variable is a (unhandled) hidden variable\r\n-      if v in hiddenLeft:\r\n-        seq.append( (True,v) ) #If so, trigger a marginalization\r\n-        hiddenLeft.remove(v)   #And mark it as handled\r\n-      for p in model.varDist[v].parents:\r\n-        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n-        if p in hiddenLeft:\r\n-          seq.append( (True,p) )\r\n-          hiddenLeft.remove(p)\r\n-      seq.append( (False,v) ) #Then process the factor itself\r\n-    assert(len(hiddenLeft)==0)\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Arbitrary ordering\r\n-  #\r\n-  # What if we wanted to handle hidden variables in an arbitrary order?\r\n-  #\r\n-  # Possible, but we'll have to be careful where we put factors, after\r\n-  # all their dependencies are satisfied.\r\n-  def seq_from_hid_order(hOrd):\r\n-    #The trick to make this work is to first assign every\r\n-    #hidden variable a priority based on the order\r\n-    prio={h:i for i,h in enumerate(hOrd)}\r\n-    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n-    #Then rate each factor on the highest priority amongst its dependencies\r\n-    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n-    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n-    vOrd.sort()\r\n-    #All that's left is to turn it into the expected sequence format\r\n-    return list( (not nm,v) for _,nm,v in vOrd )\r\n-  \r\n-  #--------------------------------------------------------\r\n-  # Brute force best\r\n-  #\r\n-  # Now, where to get an ordering to use the above?\r\n-  #\r\n-  # We could brute force try every possible ordering...\r\n-  if True:\r\n-    bestSeq=None\r\n-    bestSeqCost=sys.maxsize\r\n-    for hOrd in permutations(hiddenVars):\r\n-      tSeq=seq_from_hid_order(hOrd)\r\n-      #Note, really should do below norm optimization here too\r\n-      \r\n-      #Now the tricky bit is to rate each ordering\r\n-      #We'll do it by doubling the cost of each factor every time\r\n-      #We cross a summation\r\n-      tot=0\r\n-      ct=1\r\n-      for m,v in tSeq:\r\n-        if m:\r\n-          ct*=2\r\n-        else:\r\n-          tot+=ct\r\n-      \r\n-      if tot<bestSeqCost:\r\n-        bestSeq=tSeq\r\n-        bestSeqCost=tot\r\n-    seq=bestSeq\r\n-  # But this will be very expensive for large models\r\n-  #--------------------------------------------------------\r\n-  # Greedy\r\n-  #\r\n-  # Alternately, we could apply a greedy approach.\r\n-  #\r\n-  # Some how rate each hidden variable on how expensive we think\r\n-  # it is, then put the most expensive ones earliest\r\n-  # ***TODO***\r\n-\r\n-  #--------------------------------------------------------\r\n-  # Simple normalization optimization\r\n-  #\r\n-  # One thing we learned is that for a multiplicative term,\r\n-  # if it doesn't mention the query variable, then it's a\r\n-  # constant and can be handled via normalization (folded into alpha)\r\n-  #\r\n-  # This is non-trivial to detect for summation terms, but we\r\n-  # can easily do it for factors outside of any summation...\r\n-  if True:\r\n-    i=0\r\n-    while i<len(seq):\r\n-      m,v=seq[i]\r\n-      if m:\r\n-        break #Found first summation, quit\r\n-      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n-        #No mention of query variable, remove\r\n-        del seq[i]\r\n-      else:\r\n-        i+=1\r\n-  \r\n-  return seq\r\n-\r\n-def calc_query_approx(model,queryVar,queryVal,evidence):\r\n-  raise NotImplementedError()\r\n-\r\n-def generate_joint_prob_table(model):\r\n-  \"\"\"\r\n-  Output a joint probability table for the provided model\r\n-  \"\"\"\r\n-  from tabulate import tabulate\r\n-  table=[]\r\n-  row=list(model.vars)\r\n-  row.append('Joint Pr')\r\n-  table.append(row)\r\n-  for varVals in truefalse_combination_iterator(model.vars):\r\n-    pr=calc_global_joint_prob(model,varVals)\r\n-    row=[varVals[x] for x in model.vars]\r\n-    row.append(pr)\r\n-    table.append(row)\r\n-  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n-  return\r\n-\r\n-def read_model_file(filename):\r\n-  \"\"\"\r\n-  Returns model object with the following elements:\r\n-    vars : list of strings\r\n-      The list of variables the model describes\r\n-      In alphabetical order\r\n-    varsDep : list of strings\r\n-      Same contents as 'vars' but in dependency order (parents come before children)\r\n-    varDist : dict of objects\r\n-      Distribution information for each variable\r\n-      Dictionary key is variable name\r\n-      Object has the following elements:\r\n-        parents : set of strings\r\n-        children : set of strings\r\n-        cpt : dict of numbers\r\n-          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n-          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n-            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n-  Model file format is as follows:\r\n-    Basic file format is Comma-Separated Value (.csv)\r\n-    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n-    Tables are separated by atleast one empty line\r\n-    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n-    Each table:\r\n-      Starts with a header row containing variable names\r\n-        The last name is the variable whose cond probability is being described\r\n-        Any preceding names are considered to be parent variables\r\n-      Following rows contain True/False values for each parent and probability for main variable being true\r\n-      Any missing parent value combinations will be assumed to be probability 0.5\r\n-    Only Bernoulli/Boolean variables can be represented in this file format\r\n-  \"\"\"\r\n-  class ModelObj:\r\n-    def __init__(self):\r\n-      self.vars=[]\r\n-      self.varsDep=None\r\n-      self.varDist={}\r\n-\r\n-  class VarObj:\r\n-    def __init__(self, parents, children, cpt):\r\n-      self.parents = parents\r\n-      self.children = children\r\n-      self.cpt = cpt\r\n-\r\n-  model=ModelObj()\r\n-  #--------------------------------------------------------\r\n-  #Read data from file\r\n-  with open(filename, newline='') as csvfile:\r\n-    csvreader = csv.reader(csvfile)\r\n-    \r\n-    rowNum=0\r\n-    var=None\r\n-    varIdx=None\r\n-    parents=None\r\n-    cpt=None\r\n-    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n-      rowNum+=1\r\n-      srow=''.join(row).strip()\r\n-      if srow.startswith('#'):\r\n-        continue #Comment line, skip\r\n-      if len(srow)==0:\r\n-        #Empty line\r\n-        if var is not None:\r\n-          #End current table\r\n-          model.vars.append(var)\r\n-          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n-          #Wait for new table\r\n-          var=None\r\n-          varIdx=None\r\n-          parents=None\r\n-          cpt=None\r\n-      elif var is None:\r\n-        #Start new table\r\n-        if len(row)>1:\r\n-          parents=row[0:-1]\r\n-        else:\r\n-          parents=[]\r\n-        varIdx=len(row)-1\r\n-        var=row[varIdx]\r\n-        cpt={}\r\n-      else:\r\n-        #Add new entry to table\r\n-        if len(row)<varIdx+1:\r\n-          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n-        if len(parents)>0:\r\n-          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n-        else:\r\n-          key=frozenset()\r\n-        cpt[key]=float(row[-1])\r\n-  model.vars.sort()\r\n-  #--------------------------------------------------------\r\n-  # Check distributions for missing entries\r\n-  vCheck=frozenset(model.vars)\r\n-  for var in model.vars: #Make sure every mentioned variable has an entry\r\n-    for p in model.varDist[var].parents:\r\n-      if p not in vCheck:\r\n-        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n-  for var in model.vars: #Check every cpt for missing rows\r\n-    varDist=model.varDist[var]\r\n-    missingCnt=0\r\n-    for varVals in truefalse_combination_iterator(varDist.parents):\r\n-      key=frozenset(((x,v) for x,v in varVals.items()))\r\n-      if key not in varDist.cpt:\r\n-        missingCnt+=1\r\n-        varDist.cpt[key]=0.5\r\n-    if missingCnt>0:\r\n-      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n-  #--------------------------------------------------------\r\n-  # Create children entries\r\n-  for var in model.vars:\r\n-    model.varDist[var].children=set()\r\n-  for var in model.vars:\r\n-    for p in model.varDist[var].parents:\r\n-      model.varDist[p].children.add(var)\r\n-  for var in model.vars:\r\n-    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n-  #--------------------------------------------------------\r\n-  # Create dependency ordering\r\n-  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n-  idx=0\r\n-  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n-  while idx<len(varsDep):\r\n-    var=varsDep[idx]\r\n-    for c in model.varDist[var].children:\r\n-      parentsLeft[c]-=1\r\n-      if parentsLeft[c]==0:\r\n-        #All parents have been visited, so dependencies of this child are met\r\n-        varsDep.append(c)\r\n-      elif parentsLeft[c]<0:\r\n-        #Repeat visit to a parent can only happen if a cycle exists\r\n-        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n-    idx+=1\r\n-  model.varsDep=varsDep\r\n-  #--------------------------------------------------------\r\n-  return model\r\n-\r\n-def print_model(model):\r\n-  \"\"\"\r\n-  Print a model object back out in pretty form\r\n-  \"\"\"\r\n-  from tabulate import tabulate\r\n-  for v in model.vars:\r\n-    varDist=model.varDist[v]\r\n-    print('--------------------------------------------------')\r\n-    print('Variable:',v)\r\n-    print('--------------------------------------------------')\r\n-    print('Children:',', '.join(varDist.children))\r\n-    \r\n-    table=[]\r\n-    row=list(varDist.parents)\r\n-    row.append('P({0}=T|...)'.format(v))\r\n-    table.append(row)\r\n-    for varVals in truefalse_combination_iterator(varDist.parents):\r\n-      pr=read_cpt(model,v,varVals)\r\n-      row=[varVals[x] for x in varDist.parents]\r\n-      row.append(pr)\r\n-      table.append(row)\r\n-    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n-    print(\"\")\r\n-    \r\n-##############################################################################\r\n-## Main functions\r\n-def main(args):\r\n-  global DEBUG_OUTPUT\r\n-  if args.debug:\r\n-    DEBUG_OUTPUT=1\r\n-  #Argument checking plus additional parsing\r\n-  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n-    error('Arguments --query and --evidence not allowed in table mode')\r\n-  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n-    error('Arguments --query and --evidence not allowed in print mode')\r\n-  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n-    error('Argument --query required in inference modes')\r\n-  elif args.query is not None:\r\n-    if '=' not in args.query:\r\n-      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n-    s=args.query.split('=')\r\n-    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n-  if args.evidence is None:\r\n-    args.evidence=[]\r\n-  else:\r\n-    ev=[]\r\n-    for e in args.evidence:\r\n-      if '=' not in e:\r\n-        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n-      s=e.split('=')\r\n-      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n-    args.evidence={ var:val for var,val in ev }\r\n-\r\n-  print('Reading model from',args.model)\r\n-  model=read_model_file(args.model)\r\n-\r\n-  if args.mode=='table':\r\n-    generate_joint_prob_table(model)\r\n-  elif args.mode=='print':\r\n-    print_model(model)\r\n-  else:\r\n-    #One of the inference modes\r\n-    #Check inputs against model\r\n-    if args.query[0] not in model.vars:\r\n-      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n-    for var,val in args.evidence.items():\r\n-      if var not in model.vars:\r\n-        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n-    #Output problem setup\r\n-    print(\"Inference mode:\",args.mode)\r\n-    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n-    if len(args.evidence)==0:\r\n-      print(\"No evidence\")\r\n-    else:\r\n-      print(\"Evidence:\")\r\n-      for var,val in args.evidence.items():\r\n-        print(\"  '{0}' is {1}\".format(var,val))\r\n-\r\n-    #Run inference\r\n-    pr=None\r\n-    if args.mode=='brute':\r\n-      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n-    elif args.mode=='tree':\r\n-      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n-    else: #args.mode=='approx'\r\n-      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n-    print('Probability is',pr)\r\n-\r\n-  return\r\n-\r\n-def error(msg):\r\n-  print(msg)\r\n-  sys.exit(1)\r\n-  return\r\n-\r\n-if __name__ == '__main__':\r\n-  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n-  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n-  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n-  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n-  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n-  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n-  args = parser.parse_args()\r\n-  error=lambda msg : parser.error(msg)\r\n-  main(args)\n-import argparse\r\n-import csv\r\n-from itertools import chain, permutations\r\n-import math\r\n-#import matplotlib.pyplot as plt\r\n-#import numpy as np\r\n-from random import random\r\n-import sys\r\n-\r\n-DEBUG_OUTPUT=0\r\n-\r\n-##############################################################################\r\n-## Student code\r\n-def calc_global_joint_prob(model, variableValues):\r\n-  \"\"\"\r\n-  Calculate the global joint probability of a model for a specific set of values\r\n-  model: model object, see read_model_file() for specification\r\n-  variableValues: dictionary of boolean values, keys are variable names\r\n-  \"\"\"\r\n-  \r\n-  # YOUR CODE HERE\r\n-  #\r\n-  # You may assume variableValues is complete, i.e containes all variables in the model\r\n-  #   Thus, no marginalization is necessary\r\n-  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n-  #\r\n-  # You can find a complete descrition of the model object in the documentation of\r\n-  #   the read_model_file() function, BUT\r\n-  # All you will need is the list of variables: model.vars\r\n-  #\r\n-  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n-  #\r\n-  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n-  #\r\n-  # (Reference solution is 7 lines of code.)\r\n-  joint_prob = 1.0\r\n-  for var in model.vars:\r\n-      cpt_entry = read_cpt(model, var, variableValues)\r\n       if variableValues[var]:\r\n-          joint_prob *= cpt_entry\r\n+          prQ_T *= pr_var_T\r\n       else:\r\n-          joint_prob *= 1 - cpt_entry\r\n-  return joint_prob\r\n+          prQ_F *= (1 - pr_var_T)\r\n \r\n-def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n-  \"\"\"\r\n-  Calculate posterior probability for a given variable\r\n-\r\n-  model: model object, see read_model_file() for specification\r\n-  queryVar: string, query variable name\r\n-  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n-  evidence: dictionary of boolean values, where keys are evidence variable names\r\n-            (Any variable not listed as query or evidence is assumed to be hidden)\r\n-  \"\"\"\r\n-\r\n-  # This first attempt at probabilistic inference will use the brute-force (table)\r\n-  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n-  #\r\n-  # This requires the calculation of two joint probabilities based on the definition\r\n-  # of conditional probability:\r\n-  #                          Pr( Query & Evidence )\r\n-  #   Pr(Query | Evidence) = ----------------------\r\n-  #                              Pr( Evidence )\r\n-  #\r\n-  # Both of these joint probabilities can be calculated by going over every entry in\r\n-  # the global joint probability table and summing up the probabilities of those\r\n-  # entries that match what we're looking for\r\n-  \r\n-  def dict_issubset(d,sub):\r\n-    \"\"\"\r\n-    Returns True if every key,value pair in sub has a matching key and value in d\r\n-    Note: sub should not contain any entries with value None\r\n-    \"\"\"\r\n-    return all(d.get(key,None)==val for key,val in sub.items())\r\n-     \r\n-  pr_QE=0\r\n-  pr_E=0\r\n-  for jptEntry in truefalse_combination_iterator(model.vars):\r\n-    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n-\r\n-    # YOUR CODE HERE\r\n-    #\r\n-    # jptEntry will be a dictionary with a key for every variable in the model,\r\n-    #   and the loop will go over every possible combination of True/False for each variable\r\n-    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n-    #\r\n-    # Your task is to collect all the probabilities that match the evidence, and query\r\n-    #\r\n-    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n-    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n-    #\r\n-    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n-    #\r\n-    # (Reference solution is 4 lines of code.)\r\n-    if dict_issubset(jptEntry, evidence):\r\n-            pr_E += pr_entry\r\n-            if jptEntry[queryVar] == queryVal:\r\n-              pr_QE += pr_entry\r\n-  return pr_QE/pr_E\r\n-\r\n-def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n-  \"\"\"\r\n-  Calculate posterior probability for a given variable\r\n-\r\n-  model: model object, see read_model_file() for specification\r\n-  queryVar: string, query variable name\r\n-  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n-  evidence: dictionary of boolean values, where keys are evidence variable names\r\n-            (Any variable not listed as query or evidence is assumed to be hidden)\r\n-  \"\"\"\r\n-  \r\n-  # First step, we need to figure out what order we will calculate terms in and where\r\n-  # marginalization needs to happen.\r\n-  #\r\n-  # That said, though this is a part of the inference process that you need to know, it's a\r\n-  # bit tricky to get working in general, especially the optimization bits.\r\n-  #\r\n-  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n-  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n-  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n-  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n-  # For example, the formula on slide 20 would be represented as:\r\n-  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n-  # The formula on slide 21 would be:\r\n-  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n-  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n-  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n-  \r\n-  # Debug: Output a nicer version of the calculation order (inference formula)\r\n-  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n-  \r\n-  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n-  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n-  \r\n-  # Next step, implement the calculation\r\n-  #\r\n-  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n-  # and move on to implement the recurse_calc_query_exact_tree() function\r\n-  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n-  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n-  # and associated function and add your own calculation code here\r\n-  # YOUR CODE HERE\r\n-  #\r\n-  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n-  #\r\n-  # Normalize this result to get true probability.\r\n-  #\r\n-  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n-  #\r\n-  # Refer to the example on slide 30.\r\n-  #\r\n-  # (Reference solution is 3 lines of code.)\r\n-  total_probability = prQ_T + prQ_F\r\n-  prQ_T /= total_probability\r\n-  prQ_F /= total_probability\r\n-  \r\n-  # Return the probability which answers the query\r\n-  return prQ_T if queryVal else prQ_F\r\n-  \r\n-\r\n-def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n-  \"\"\"\r\n-  Recursiving process the summation tree \r\n-  \r\n-  model,queryVar,evidence: See calc_query_exact_tree()\r\n-  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n-    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n-  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n-  \"\"\"\r\n-  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n-\r\n-  # Your overall task in the function is to assign values to:\r\n-  #   prQ_T\r\n-  #   prQ_F\r\n-  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n-  # covering both cases where query=True and query=False.\r\n-\r\n-  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n-  if marginalize:\r\n-    #Summation term, need to branch over all possible values and continue calculation\r\n-    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n-    # YOUR CODE HERE\r\n-    #\r\n-    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n-    # calculation\r\n-    #\r\n-    # You will need to recurse for each element of the summation (i.e. each branch)\r\n-    # Then properly combine the results together\r\n-    #\r\n-    # Slides 26-28 show examples of resolving summations.\r\n-    #\r\n-    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n-    #   BUT remember to change it back to the original values when you are done!\r\n-    #   (The original value for unknown variables is None.)\r\n-    #\r\n-    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n-    #   example of how to make the recursive call(s)\r\n-    #\r\n-    # (Reference solution is 7 lines of code.)\r\n-    for value in [True, False]:\r\n-        # Update the variable value in the dictionary\r\n-        variableValues[var] = value\r\n-\r\n-        # Recurse for each element of the summation (each branch)\r\n-        prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n-\r\n-        # Combine the results together\r\n-        prQ_T += prR_T\r\n-        prQ_F += prR_F\r\n-\r\n-    # Restore the original value for the variable\r\n-    variableValues[var] = original_value\r\n-  else:\r\n-    #Probability term, calculate conditional probability for this variable and continue calculation\r\n-    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n-    if queryVar in model.varDist[var].parents:\r\n-      #Query variable is a condition for this term\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n-      #\r\n-      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n-      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n-      # consider both what happens when the query variable is True, and also when it is False.\r\n-      #\r\n-      # Copy from your code below and modify to deal with this additional element.\r\n-      #\r\n-      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n-      #\r\n-      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n-      #   BUT remember to change it back to the original values when you are done!\r\n-      #\r\n-      # (Reference solution is 11 lines of code.)\r\n-      original_value = variableValues[var]\r\n-\r\n-        # Iterate over both cases when the query variable is True and False\r\n-      for query_value in [True, False]:\r\n-            # Update the variable value in the dictionary\r\n-            variableValues[var] = query_value\r\n-\r\n-            # Recurse for each case\r\n-            prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n-\r\n-            # Combine the results together\r\n-            if query_value:\r\n-                prQ_T *= prR_T\r\n-            else:\r\n-                prQ_F *= prR_F\r\n-\r\n-        # Restore the original value for the variable\r\n-      variableValues[var] = original_value\r\n-    elif var==queryVar:\r\n-      #This term is probability _for_ the Query variable\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one second! (Atleast, I recommend this.)\r\n-      #\r\n-      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n-      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n-      # is False.\r\n-      #\r\n-      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n-      # \r\n-      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n-      #\r\n-      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n-      #   BUT remember to change it back to the original values when you are done!\r\n-      #\r\n-      # (Reference solution is 5 additional lines of code.)\r\n-      original_value = variableValues[var]\r\n-\r\n-        # Iterate over both cases when the query variable is True and False\r\n-      for query_value in [True, False]:\r\n-            # Update the variable value in the dictionary\r\n-            variableValues[var] = query_value\r\n-\r\n-            # Recurse for each case\r\n-            prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n-\r\n-            # Combine the results together\r\n-            if query_value:\r\n-                prQ_T *= prR_T\r\n-            else:\r\n-                prQ_F *= prR_F\r\n-\r\n-        # Restore the original value for the variable\r\n-      variableValues[var] = original_value\r\n-    else:\r\n-      #Simple term, no need to worry about query variable\r\n-      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n-\r\n-      # YOUR CODE HERE\r\n-      #\r\n-      # Finish this one first! (It's the simplest of the three.)\r\n-      #\r\n-      # You need to get the conditional probability for this variable and correctly\r\n-      # combine it with the results of the recursive call above.\r\n-      #\r\n-      # Don't forget that this variable's value could be True or False!\r\n-      #\r\n-      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n-      #\r\n-      # (Reference solution is 5 lines of code.)\r\n-      pr_var_T = model.get_prob(var, variableValues)\r\n-\r\n-        # Update prQ_T, prQ_F with the conditional probability\r\n-      prQ_T *= pr_var_T\r\n-      prQ_F *= (1 - pr_var_T)\r\n-\r\n     if len(remainingCalc)>1:\r\n       #If there are still terms left, then recurse\r\n       prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n       \r\n"
                },
                {
                    "date": 1699826760434,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -303,13 +303,13 @@\n       #\r\n       # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n       #\r\n       # (Reference solution is 5 lines of code.)\r\n-      pr_var_T = model.get_prob(var, variableValues)\r\n+      cpt_entry =read_cpt(model, var, variableValues)\r\n       if variableValues[var]:\r\n-          prQ_T *= pr_var_T\r\n+          prQ_T *= cpt_entry\r\n       else:\r\n-          prQ_F *= (1 - pr_var_T)\r\n+          prQ_F *= (1 - cpt_entry)\r\n \r\n     if len(remainingCalc)>1:\r\n       #If there are still terms left, then recurse\r\n       prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n"
                },
                {
                    "date": 1699827092652,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,729 @@\n+import argparse\r\n+import csv\r\n+from itertools import chain, permutations\r\n+import math\r\n+#import matplotlib.pyplot as plt\r\n+#import numpy as np\r\n+from random import random\r\n+import sys\r\n+\r\n+DEBUG_OUTPUT=0\r\n+\r\n+##############################################################################\r\n+## Student code\r\n+def calc_global_joint_prob(model, variableValues):\r\n+  \"\"\"\r\n+  Calculate the global joint probability of a model for a specific set of values\r\n+  model: model object, see read_model_file() for specification\r\n+  variableValues: dictionary of boolean values, keys are variable names\r\n+  \"\"\"\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # You may assume variableValues is complete, i.e containes all variables in the model\r\n+  #   Thus, no marginalization is necessary\r\n+  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n+  #\r\n+  # You can find a complete descrition of the model object in the documentation of\r\n+  #   the read_model_file() function, BUT\r\n+  # All you will need is the list of variables: model.vars\r\n+  #\r\n+  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n+  #\r\n+  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n+  #\r\n+  # (Reference solution is 7 lines of code.)\r\n+  joint_prob = 1.0\r\n+  for var in model.vars:\r\n+      cpt_entry = read_cpt(model, var, variableValues)\r\n+      if variableValues[var]:\r\n+          joint_prob *= cpt_entry\r\n+      else:\r\n+          joint_prob *= 1 - cpt_entry\r\n+  return joint_prob\r\n+\r\n+def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+\r\n+  # This first attempt at probabilistic inference will use the brute-force (table)\r\n+  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n+  #\r\n+  # This requires the calculation of two joint probabilities based on the definition\r\n+  # of conditional probability:\r\n+  #                          Pr( Query & Evidence )\r\n+  #   Pr(Query | Evidence) = ----------------------\r\n+  #                              Pr( Evidence )\r\n+  #\r\n+  # Both of these joint probabilities can be calculated by going over every entry in\r\n+  # the global joint probability table and summing up the probabilities of those\r\n+  # entries that match what we're looking for\r\n+  \r\n+  def dict_issubset(d,sub):\r\n+    \"\"\"\r\n+    Returns True if every key,value pair in sub has a matching key and value in d\r\n+    Note: sub should not contain any entries with value None\r\n+    \"\"\"\r\n+    return all(d.get(key,None)==val for key,val in sub.items())\r\n+     \r\n+  pr_QE=0\r\n+  pr_E=0\r\n+  for jptEntry in truefalse_combination_iterator(model.vars):\r\n+    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # jptEntry will be a dictionary with a key for every variable in the model,\r\n+    #   and the loop will go over every possible combination of True/False for each variable\r\n+    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n+    #\r\n+    # Your task is to collect all the probabilities that match the evidence, and query\r\n+    #\r\n+    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n+    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n+    #\r\n+    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n+    #\r\n+    # (Reference solution is 4 lines of code.)\r\n+    if dict_issubset(jptEntry, evidence):\r\n+            pr_E += pr_entry\r\n+            if jptEntry[queryVar] == queryVal:\r\n+              pr_QE += pr_entry\r\n+  return pr_QE/pr_E\r\n+\r\n+def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+  \r\n+  # First step, we need to figure out what order we will calculate terms in and where\r\n+  # marginalization needs to happen.\r\n+  #\r\n+  # That said, though this is a part of the inference process that you need to know, it's a\r\n+  # bit tricky to get working in general, especially the optimization bits.\r\n+  #\r\n+  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n+  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n+  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n+  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n+  # For example, the formula on slide 20 would be represented as:\r\n+  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n+  # The formula on slide 21 would be:\r\n+  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n+  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n+  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n+  \r\n+  # Debug: Output a nicer version of the calculation order (inference formula)\r\n+  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n+  \r\n+  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n+  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n+  \r\n+  # Next step, implement the calculation\r\n+  #\r\n+  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n+  # and move on to implement the recurse_calc_query_exact_tree() function\r\n+  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n+  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n+  # and associated function and add your own calculation code here\r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n+  #\r\n+  # Normalize this result to get true probability.\r\n+  #\r\n+  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n+  #\r\n+  # Refer to the example on slide 30.\r\n+  #\r\n+  # (Reference solution is 3 lines of code.)\r\n+  total_probability = prQ_T + prQ_F\r\n+  prQ_T /= total_probability\r\n+  prQ_F /= total_probability\r\n+  \r\n+  # Return the probability which answers the query\r\n+  return prQ_T if queryVal else prQ_F\r\n+  \r\n+\r\n+def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n+  \"\"\"\r\n+  Recursiving process the summation tree \r\n+  \r\n+  model,queryVar,evidence: See calc_query_exact_tree()\r\n+  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n+    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n+  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n+  \"\"\"\r\n+  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n+\r\n+  # Your overall task in the function is to assign values to:\r\n+  #   prQ_T\r\n+  #   prQ_F\r\n+  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n+  # covering both cases where query=True and query=False.\r\n+\r\n+  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n+  if marginalize:\r\n+    #Summation term, need to branch over all possible values and continue calculation\r\n+    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n+    # calculation\r\n+    #\r\n+    # You will need to recurse for each element of the summation (i.e. each branch)\r\n+    # Then properly combine the results together\r\n+    #\r\n+    # Slides 26-28 show examples of resolving summations.\r\n+    #\r\n+    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n+    #   BUT remember to change it back to the original values when you are done!\r\n+    #   (The original value for unknown variables is None.)\r\n+    #\r\n+    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n+    #   example of how to make the recursive call(s)\r\n+    #\r\n+    # (Reference solution is 7 lines of code.)\r\n+    for value in [True, False]:\r\n+        # Update the variable value in the dictionary\r\n+        variableValues[var] = value\r\n+\r\n+        # Recurse for each element of the summation (each branch)\r\n+        prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+        # Combine the results together\r\n+        prQ_T += prR_T\r\n+        prQ_F += prR_F\r\n+\r\n+    # Restore the original value for the variable\r\n+    variableValues[var] = original_value\r\n+  else:\r\n+    #Probability term, calculate conditional probability for this variable and continue calculation\r\n+    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n+    if queryVar in model.varDist[var].parents:\r\n+      #Query variable is a condition for this term\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n+      #\r\n+      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n+      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n+      # consider both what happens when the query variable is True, and also when it is False.\r\n+      #\r\n+      # Copy from your code below and modify to deal with this additional element.\r\n+      #\r\n+      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 11 lines of code.)\r\n+      original_value = variableValues[var]\r\n+\r\n+        # Iterate over both cases when the query variable is True and False\r\n+      for query_value in [True, False]:\r\n+            # Update the variable value in the dictionary\r\n+            variableValues[var] = query_value\r\n+\r\n+            # Recurse for each case\r\n+            prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+            # Combine the results together\r\n+            if query_value:\r\n+                prQ_T *= prR_T\r\n+            else:\r\n+                prQ_F *= prR_F\r\n+\r\n+        # Restore the original value for the variable\r\n+      variableValues[var] = original_value\r\n+    elif var==queryVar:\r\n+      #This term is probability _for_ the Query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one second! (Atleast, I recommend this.)\r\n+      #\r\n+      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n+      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n+      # is False.\r\n+      #\r\n+      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n+      # \r\n+      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 5 additional lines of code.\r\n+      for query_value in [True, False]:\r\n+            variableValues[var] = query_value\r\n+            prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+            # Combine the results together\r\n+            if query_value:\r\n+                prQ_T *= prR_T\r\n+            else:\r\n+                prQ_F *= prR_F\r\n+\r\n+        # Restore the original value for the variable\r\n+      variableValues[var] = original_value\r\n+    else:\r\n+      #Simple term, no need to worry about query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one first! (It's the simplest of the three.)\r\n+      #\r\n+      # You need to get the conditional probability for this variable and correctly\r\n+      # combine it with the results of the recursive call above.\r\n+      #\r\n+      # Don't forget that this variable's value could be True or False!\r\n+      #\r\n+      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n+      #\r\n+      # (Reference solution is 5 lines of code.)\r\n+      cpt_entry =recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+      if variableValues[var]:\r\n+          prQ_T *= cpt_entry\r\n+      else:\r\n+          prQ_F *= (1 - cpt_entry)\r\n+\r\n+    if len(remainingCalc)>1:\r\n+      #If there are still terms left, then recurse\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n+      \r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Update prQ_T, prQ_F with the results from the recursive call.\r\n+      #\r\n+      # How do you combine _factors_ together?\r\n+      #\r\n+      # (Reference solution is 2 lines of code.)\r\n+      prQ_T *= prR_T\r\n+      prQ_F *= prR_F\r\n+\r\n+  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n+  \r\n+##############################################################################\r\n+## Support code\r\n+def read_cpt(model,varName,condVals):\r\n+  \"\"\"\r\n+  Read conditional probability for a specified variable with provided condition (parent) values\r\n+  Note, the value returned is conditional probability for variable being True\r\n+  \r\n+  Warning: If you get an index exception and referenced key has None in it, this means\r\n+    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n+  \r\n+  model: model object, see read_model_file() for specification\r\n+  varName: string, variable name to read probability for\r\n+  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n+              (Missing conditions will cause errors, extraneous values will be ignored)\r\n+  \"\"\"\r\n+  if varName not in model.varDist:\r\n+    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n+  varDist=model.varDist[varName]\r\n+  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n+  if key not in varDist.cpt:\r\n+    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n+  return varDist.cpt[key]\r\n+\r\n+def truefalse_combination_iterator(entries):\r\n+  \"\"\"\r\n+  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n+  \"\"\"\r\n+  entries=list(entries)\r\n+  entries.reverse()\r\n+  if len(entries)>30:\r\n+    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n+  for c in range(1<<len(entries)):\r\n+    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n+\r\n+def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n+  \"\"\"\r\n+  Create represention of terms in an inference calculation such as on slides 20-21\r\n+  \r\n+  Returns a list of (boolean,string) tuples where:\r\n+    (True,variable) represents a summation term where a variable needs to be marginalized\r\n+    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n+  \"\"\"\r\n+  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Naive solution\r\n+  #\r\n+  # model.varsDep already has variables in order of dependency...\r\n+  # So take that and insert summation terms any time we encounter a new hidden variable\r\n+  #\r\n+  # Downside is little optimization, likely to have many unnecessary terms\r\n+  if False:\r\n+    hiddenLeft=set(hiddenVars)\r\n+    seq=[]\r\n+    for v in model.varsDep:\r\n+      #Check if factor variable is a (unhandled) hidden variable\r\n+      if v in hiddenLeft:\r\n+        seq.append( (True,v) ) #If so, trigger a marginalization\r\n+        hiddenLeft.remove(v)   #And mark it as handled\r\n+      for p in model.varDist[v].parents:\r\n+        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n+        if p in hiddenLeft:\r\n+          seq.append( (True,p) )\r\n+          hiddenLeft.remove(p)\r\n+      seq.append( (False,v) ) #Then process the factor itself\r\n+    assert(len(hiddenLeft)==0)\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Arbitrary ordering\r\n+  #\r\n+  # What if we wanted to handle hidden variables in an arbitrary order?\r\n+  #\r\n+  # Possible, but we'll have to be careful where we put factors, after\r\n+  # all their dependencies are satisfied.\r\n+  def seq_from_hid_order(hOrd):\r\n+    #The trick to make this work is to first assign every\r\n+    #hidden variable a priority based on the order\r\n+    prio={h:i for i,h in enumerate(hOrd)}\r\n+    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n+    #Then rate each factor on the highest priority amongst its dependencies\r\n+    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n+    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n+    vOrd.sort()\r\n+    #All that's left is to turn it into the expected sequence format\r\n+    return list( (not nm,v) for _,nm,v in vOrd )\r\n+  \r\n+  #--------------------------------------------------------\r\n+  # Brute force best\r\n+  #\r\n+  # Now, where to get an ordering to use the above?\r\n+  #\r\n+  # We could brute force try every possible ordering...\r\n+  if True:\r\n+    bestSeq=None\r\n+    bestSeqCost=sys.maxsize\r\n+    for hOrd in permutations(hiddenVars):\r\n+      tSeq=seq_from_hid_order(hOrd)\r\n+      #Note, really should do below norm optimization here too\r\n+      \r\n+      #Now the tricky bit is to rate each ordering\r\n+      #We'll do it by doubling the cost of each factor every time\r\n+      #We cross a summation\r\n+      tot=0\r\n+      ct=1\r\n+      for m,v in tSeq:\r\n+        if m:\r\n+          ct*=2\r\n+        else:\r\n+          tot+=ct\r\n+      \r\n+      if tot<bestSeqCost:\r\n+        bestSeq=tSeq\r\n+        bestSeqCost=tot\r\n+    seq=bestSeq\r\n+  # But this will be very expensive for large models\r\n+  #--------------------------------------------------------\r\n+  # Greedy\r\n+  #\r\n+  # Alternately, we could apply a greedy approach.\r\n+  #\r\n+  # Some how rate each hidden variable on how expensive we think\r\n+  # it is, then put the most expensive ones earliest\r\n+  # ***TODO***\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Simple normalization optimization\r\n+  #\r\n+  # One thing we learned is that for a multiplicative term,\r\n+  # if it doesn't mention the query variable, then it's a\r\n+  # constant and can be handled via normalization (folded into alpha)\r\n+  #\r\n+  # This is non-trivial to detect for summation terms, but we\r\n+  # can easily do it for factors outside of any summation...\r\n+  if True:\r\n+    i=0\r\n+    while i<len(seq):\r\n+      m,v=seq[i]\r\n+      if m:\r\n+        break #Found first summation, quit\r\n+      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n+        #No mention of query variable, remove\r\n+        del seq[i]\r\n+      else:\r\n+        i+=1\r\n+  \r\n+  return seq\r\n+\r\n+def calc_query_approx(model,queryVar,queryVal,evidence):\r\n+  raise NotImplementedError()\r\n+\r\n+def generate_joint_prob_table(model):\r\n+  \"\"\"\r\n+  Output a joint probability table for the provided model\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  table=[]\r\n+  row=list(model.vars)\r\n+  row.append('Joint Pr')\r\n+  table.append(row)\r\n+  for varVals in truefalse_combination_iterator(model.vars):\r\n+    pr=calc_global_joint_prob(model,varVals)\r\n+    row=[varVals[x] for x in model.vars]\r\n+    row.append(pr)\r\n+    table.append(row)\r\n+  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+  return\r\n+\r\n+def read_model_file(filename):\r\n+  \"\"\"\r\n+  Returns model object with the following elements:\r\n+    vars : list of strings\r\n+      The list of variables the model describes\r\n+      In alphabetical order\r\n+    varsDep : list of strings\r\n+      Same contents as 'vars' but in dependency order (parents come before children)\r\n+    varDist : dict of objects\r\n+      Distribution information for each variable\r\n+      Dictionary key is variable name\r\n+      Object has the following elements:\r\n+        parents : set of strings\r\n+        children : set of strings\r\n+        cpt : dict of numbers\r\n+          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n+          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n+            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n+  Model file format is as follows:\r\n+    Basic file format is Comma-Separated Value (.csv)\r\n+    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n+    Tables are separated by atleast one empty line\r\n+    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n+    Each table:\r\n+      Starts with a header row containing variable names\r\n+        The last name is the variable whose cond probability is being described\r\n+        Any preceding names are considered to be parent variables\r\n+      Following rows contain True/False values for each parent and probability for main variable being true\r\n+      Any missing parent value combinations will be assumed to be probability 0.5\r\n+    Only Bernoulli/Boolean variables can be represented in this file format\r\n+  \"\"\"\r\n+  class ModelObj:\r\n+    def __init__(self):\r\n+      self.vars=[]\r\n+      self.varsDep=None\r\n+      self.varDist={}\r\n+\r\n+  class VarObj:\r\n+    def __init__(self, parents, children, cpt):\r\n+      self.parents = parents\r\n+      self.children = children\r\n+      self.cpt = cpt\r\n+\r\n+  model=ModelObj()\r\n+  #--------------------------------------------------------\r\n+  #Read data from file\r\n+  with open(filename, newline='') as csvfile:\r\n+    csvreader = csv.reader(csvfile)\r\n+    \r\n+    rowNum=0\r\n+    var=None\r\n+    varIdx=None\r\n+    parents=None\r\n+    cpt=None\r\n+    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n+      rowNum+=1\r\n+      srow=''.join(row).strip()\r\n+      if srow.startswith('#'):\r\n+        continue #Comment line, skip\r\n+      if len(srow)==0:\r\n+        #Empty line\r\n+        if var is not None:\r\n+          #End current table\r\n+          model.vars.append(var)\r\n+          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n+          #Wait for new table\r\n+          var=None\r\n+          varIdx=None\r\n+          parents=None\r\n+          cpt=None\r\n+      elif var is None:\r\n+        #Start new table\r\n+        if len(row)>1:\r\n+          parents=row[0:-1]\r\n+        else:\r\n+          parents=[]\r\n+        varIdx=len(row)-1\r\n+        var=row[varIdx]\r\n+        cpt={}\r\n+      else:\r\n+        #Add new entry to table\r\n+        if len(row)<varIdx+1:\r\n+          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n+        if len(parents)>0:\r\n+          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n+        else:\r\n+          key=frozenset()\r\n+        cpt[key]=float(row[-1])\r\n+  model.vars.sort()\r\n+  #--------------------------------------------------------\r\n+  # Check distributions for missing entries\r\n+  vCheck=frozenset(model.vars)\r\n+  for var in model.vars: #Make sure every mentioned variable has an entry\r\n+    for p in model.varDist[var].parents:\r\n+      if p not in vCheck:\r\n+        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n+  for var in model.vars: #Check every cpt for missing rows\r\n+    varDist=model.varDist[var]\r\n+    missingCnt=0\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      key=frozenset(((x,v) for x,v in varVals.items()))\r\n+      if key not in varDist.cpt:\r\n+        missingCnt+=1\r\n+        varDist.cpt[key]=0.5\r\n+    if missingCnt>0:\r\n+      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n+  #--------------------------------------------------------\r\n+  # Create children entries\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=set()\r\n+  for var in model.vars:\r\n+    for p in model.varDist[var].parents:\r\n+      model.varDist[p].children.add(var)\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n+  #--------------------------------------------------------\r\n+  # Create dependency ordering\r\n+  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n+  idx=0\r\n+  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n+  while idx<len(varsDep):\r\n+    var=varsDep[idx]\r\n+    for c in model.varDist[var].children:\r\n+      parentsLeft[c]-=1\r\n+      if parentsLeft[c]==0:\r\n+        #All parents have been visited, so dependencies of this child are met\r\n+        varsDep.append(c)\r\n+      elif parentsLeft[c]<0:\r\n+        #Repeat visit to a parent can only happen if a cycle exists\r\n+        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n+    idx+=1\r\n+  model.varsDep=varsDep\r\n+  #--------------------------------------------------------\r\n+  return model\r\n+\r\n+def print_model(model):\r\n+  \"\"\"\r\n+  Print a model object back out in pretty form\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  for v in model.vars:\r\n+    varDist=model.varDist[v]\r\n+    print('--------------------------------------------------')\r\n+    print('Variable:',v)\r\n+    print('--------------------------------------------------')\r\n+    print('Children:',', '.join(varDist.children))\r\n+    \r\n+    table=[]\r\n+    row=list(varDist.parents)\r\n+    row.append('P({0}=T|...)'.format(v))\r\n+    table.append(row)\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      pr=read_cpt(model,v,varVals)\r\n+      row=[varVals[x] for x in varDist.parents]\r\n+      row.append(pr)\r\n+      table.append(row)\r\n+    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+    print(\"\")\r\n+    \r\n+##############################################################################\r\n+## Main functions\r\n+def main(args):\r\n+  global DEBUG_OUTPUT\r\n+  if args.debug:\r\n+    DEBUG_OUTPUT=1\r\n+  #Argument checking plus additional parsing\r\n+  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in table mode')\r\n+  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in print mode')\r\n+  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n+    error('Argument --query required in inference modes')\r\n+  elif args.query is not None:\r\n+    if '=' not in args.query:\r\n+      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n+    s=args.query.split('=')\r\n+    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n+  if args.evidence is None:\r\n+    args.evidence=[]\r\n+  else:\r\n+    ev=[]\r\n+    for e in args.evidence:\r\n+      if '=' not in e:\r\n+        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n+      s=e.split('=')\r\n+      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n+    args.evidence={ var:val for var,val in ev }\r\n+\r\n+  print('Reading model from',args.model)\r\n+  model=read_model_file(args.model)\r\n+\r\n+  if args.mode=='table':\r\n+    generate_joint_prob_table(model)\r\n+  elif args.mode=='print':\r\n+    print_model(model)\r\n+  else:\r\n+    #One of the inference modes\r\n+    #Check inputs against model\r\n+    if args.query[0] not in model.vars:\r\n+      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n+    for var,val in args.evidence.items():\r\n+      if var not in model.vars:\r\n+        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n+    #Output problem setup\r\n+    print(\"Inference mode:\",args.mode)\r\n+    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n+    if len(args.evidence)==0:\r\n+      print(\"No evidence\")\r\n+    else:\r\n+      print(\"Evidence:\")\r\n+      for var,val in args.evidence.items():\r\n+        print(\"  '{0}' is {1}\".format(var,val))\r\n+\r\n+    #Run inference\r\n+    pr=None\r\n+    if args.mode=='brute':\r\n+      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n+    elif args.mode=='tree':\r\n+      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n+    else: #args.mode=='approx'\r\n+      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n+    print('Probability is',pr)\r\n+\r\n+  return\r\n+\r\n+def error(msg):\r\n+  print(msg)\r\n+  sys.exit(1)\r\n+  return\r\n+\r\n+if __name__ == '__main__':\r\n+  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n+  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n+  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n+  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n+  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n+  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n+  args = parser.parse_args()\r\n+  error=lambda msg : parser.error(msg)\r\n+  main(args)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1699835641307,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,732 @@\n+import argparse\r\n+import csv\r\n+from itertools import chain, permutations\r\n+import math\r\n+#import matplotlib.pyplot as plt\r\n+#import numpy as np\r\n+from random import random\r\n+import sys\r\n+\r\n+DEBUG_OUTPUT=0\r\n+\r\n+##############################################################################\r\n+## Student code\r\n+def calc_global_joint_prob(model, variableValues):\r\n+  \"\"\"\r\n+  Calculate the global joint probability of a model for a specific set of values\r\n+  model: model object, see read_model_file() for specification\r\n+  variableValues: dictionary of boolean values, keys are variable names\r\n+  \"\"\"\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # You may assume variableValues is complete, i.e containes all variables in the model\r\n+  #   Thus, no marginalization is necessary\r\n+  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n+  #\r\n+  # You can find a complete descrition of the model object in the documentation of\r\n+  #   the read_model_file() function, BUT\r\n+  # All you will need is the list of variables: model.vars\r\n+  #\r\n+  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n+  #\r\n+  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n+  #\r\n+  # (Reference solution is 7 lines of code.)\r\n+  joint_prob = 1.0\r\n+  for var in model.vars:\r\n+      cpt_entry = read_cpt(model, var, variableValues)\r\n+      if variableValues[var]:\r\n+          joint_prob *= cpt_entry\r\n+      else:\r\n+          joint_prob *= 1 - cpt_entry\r\n+  return joint_prob\r\n+\r\n+def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+\r\n+  # This first attempt at probabilistic inference will use the brute-force (table)\r\n+  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n+  #\r\n+  # This requires the calculation of two joint probabilities based on the definition\r\n+  # of conditional probability:\r\n+  #                          Pr( Query & Evidence )\r\n+  #   Pr(Query | Evidence) = ----------------------\r\n+  #                              Pr( Evidence )\r\n+  #\r\n+  # Both of these joint probabilities can be calculated by going over every entry in\r\n+  # the global joint probability table and summing up the probabilities of those\r\n+  # entries that match what we're looking for\r\n+  \r\n+  def dict_issubset(d,sub):\r\n+    \"\"\"\r\n+    Returns True if every key,value pair in sub has a matching key and value in d\r\n+    Note: sub should not contain any entries with value None\r\n+    \"\"\"\r\n+    return all(d.get(key,None)==val for key,val in sub.items())\r\n+     \r\n+  pr_QE=0\r\n+  pr_E=0\r\n+  for jptEntry in truefalse_combination_iterator(model.vars):\r\n+    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # jptEntry will be a dictionary with a key for every variable in the model,\r\n+    #   and the loop will go over every possible combination of True/False for each variable\r\n+    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n+    #\r\n+    # Your task is to collect all the probabilities that match the evidence, and query\r\n+    #\r\n+    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n+    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n+    #\r\n+    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n+    #\r\n+    # (Reference solution is 4 lines of code.)\r\n+    if dict_issubset(jptEntry, evidence):\r\n+            pr_E += pr_entry\r\n+            if jptEntry[queryVar] == queryVal:\r\n+              pr_QE += pr_entry\r\n+  return pr_QE/pr_E\r\n+\r\n+def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+  \r\n+  # First step, we need to figure out what order we will calculate terms in and where\r\n+  # marginalization needs to happen.\r\n+  #\r\n+  # That said, though this is a part of the inference process that you need to know, it's a\r\n+  # bit tricky to get working in general, especially the optimization bits.\r\n+  #\r\n+  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n+  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n+  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n+  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n+  # For example, the formula on slide 20 would be represented as:\r\n+  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n+  # The formula on slide 21 would be:\r\n+  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n+  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n+  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n+  \r\n+  # Debug: Output a nicer version of the calculation order (inference formula)\r\n+  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n+  \r\n+  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n+  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n+  \r\n+  # Next step, implement the calculation\r\n+  #\r\n+  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n+  # and move on to implement the recurse_calc_query_exact_tree() function\r\n+  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n+  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n+  # and associated function and add your own calculation code here\r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n+  #\r\n+  # Normalize this result to get true probability.\r\n+  #\r\n+  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n+  #\r\n+  # Refer to the example on slide 30.\r\n+  #\r\n+  # (Reference solution is 3 lines of code.)\r\n+  total_probability = prQ_T + prQ_F\r\n+  prQ_T /= total_probability\r\n+  prQ_F /= total_probability\r\n+  \r\n+  # Return the probability which answers the query\r\n+  return prQ_T if queryVal else prQ_F\r\n+  \r\n+\r\n+def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n+  \"\"\"\r\n+  Recursiving process the summation tree \r\n+  \r\n+  model,queryVar,evidence: See calc_query_exact_tree()\r\n+  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n+    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n+  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n+  \"\"\"\r\n+  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n+\r\n+  # Your overall task in the function is to assign values to:\r\n+  #   prQ_T\r\n+  #   prQ_F\r\n+  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n+  # covering both cases where query=True and query=False.\r\n+\r\n+  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n+  if marginalize:\r\n+    #Summation term, need to branch over all possible values and continue calculation\r\n+    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n+    # calculation\r\n+    #\r\n+    # You will need to recurse for each element of the summation (i.e. each branch)\r\n+    # Then properly combine the results together\r\n+    #\r\n+    # Slides 26-28 show examples of resolving summations.\r\n+    #\r\n+    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n+    #   BUT remember to change it back to the original values when you are done!\r\n+    #   (The original value for unknown variables is None.)\r\n+    #\r\n+    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n+    #   example of how to make the recursive call(s)\r\n+    #\r\n+    # (Reference solution is 7 lines of code.)\r\n+    for value in [True, False]:\r\n+        # Update the variable value in the dictionary\r\n+        variableValues[var] = value\r\n+\r\n+        # Recurse for each element of the summation (each branch)\r\n+        prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+        # Combine the results together\r\n+        prQ_T += prR_T\r\n+        prQ_F += prR_F\r\n+\r\n+    # Restore the original value for the variable\r\n+    variableValues[var] = original_value\r\n+  else:\r\n+    #Probability term, calculate conditional probability for this variable and continue calculation\r\n+    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n+    if queryVar in model.varDist[var].parents:\r\n+      #Query variable is a condition for this term\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n+      #\r\n+      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n+      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n+      # consider both what happens when the query variable is True, and also when it is False.\r\n+      #\r\n+      # Copy from your code below and modify to deal with this additional element.\r\n+      #\r\n+      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 11 lines of code.)\r\n+      original_value = variableValues[var]\r\n+\r\n+        # Iterate over both cases when the query variable is True and False\r\n+      for query_value in [True, False]:\r\n+            # Update the variable value in the dictionary\r\n+            variableValues[var] = query_value\r\n+\r\n+            # Recurse for each case\r\n+            prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+            # Combine the results together\r\n+            if query_value:\r\n+                prQ_T *= prR_T\r\n+            else:\r\n+                prQ_F *= prR_F\r\n+\r\n+        # Restore the original value for the variable\r\n+      variableValues[var] = original_value\r\n+    elif var==queryVar:\r\n+      #This term is probability _for_ the Query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one second! (Atleast, I recommend this.)\r\n+      #\r\n+      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n+      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n+      # is False.\r\n+      #\r\n+      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n+      # \r\n+      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 5 additional lines of code.)\r\n+      original_value = variableValues[var]\r\n+\r\n+        # Iterate over both cases when the query variable is True and False\r\n+      for query_value in [True, False]:\r\n+            variableValues[var] = query_value\r\n+            prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+            # Combine the results together\r\n+            if query_value:\r\n+                prQ_T *= prR_T\r\n+            else:\r\n+                prQ_F *= prR_F\r\n+\r\n+        # Restore the original value for the variable\r\n+      variableValues[var] = original_value\r\n+    else:\r\n+      #Simple term, no need to worry about query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one first! (It's the simplest of the three.)\r\n+      #\r\n+      # You need to get the conditional probability for this variable and correctly\r\n+      # combine it with the results of the recursive call above.\r\n+      #\r\n+      # Don't forget that this variable's value could be True or False!\r\n+      #\r\n+      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n+      #\r\n+      # (Reference solution is 5 lines of code.)\r\n+      cpt_entry =read_cpt(model, var, variableValues)\r\n+      if variableValues[var]:\r\n+          prQ_T *= cpt_entry\r\n+      else:\r\n+          prQ_F *= (1 - cpt_entry)\r\n+\r\n+    if len(remainingCalc)>1:\r\n+      #If there are still terms left, then recurse\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n+      \r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Update prQ_T, prQ_F with the results from the recursive call.\r\n+      #\r\n+      # How do you combine _factors_ together?\r\n+      #\r\n+      # (Reference solution is 2 lines of code.)\r\n+      prQ_T *= prR_T\r\n+      prQ_F *= prR_F\r\n+\r\n+  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n+  \r\n+##############################################################################\r\n+## Support code\r\n+def read_cpt(model,varName,condVals):\r\n+  \"\"\"\r\n+  Read conditional probability for a specified variable with provided condition (parent) values\r\n+  Note, the value returned is conditional probability for variable being True\r\n+  \r\n+  Warning: If you get an index exception and referenced key has None in it, this means\r\n+    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n+  \r\n+  model: model object, see read_model_file() for specification\r\n+  varName: string, variable name to read probability for\r\n+  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n+              (Missing conditions will cause errors, extraneous values will be ignored)\r\n+  \"\"\"\r\n+  if varName not in model.varDist:\r\n+    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n+  varDist=model.varDist[varName]\r\n+  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n+  if key not in varDist.cpt:\r\n+    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n+  return varDist.cpt[key]\r\n+\r\n+def truefalse_combination_iterator(entries):\r\n+  \"\"\"\r\n+  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n+  \"\"\"\r\n+  entries=list(entries)\r\n+  entries.reverse()\r\n+  if len(entries)>30:\r\n+    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n+  for c in range(1<<len(entries)):\r\n+    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n+\r\n+def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n+  \"\"\"\r\n+  Create represention of terms in an inference calculation such as on slides 20-21\r\n+  \r\n+  Returns a list of (boolean,string) tuples where:\r\n+    (True,variable) represents a summation term where a variable needs to be marginalized\r\n+    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n+  \"\"\"\r\n+  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Naive solution\r\n+  #\r\n+  # model.varsDep already has variables in order of dependency...\r\n+  # So take that and insert summation terms any time we encounter a new hidden variable\r\n+  #\r\n+  # Downside is little optimization, likely to have many unnecessary terms\r\n+  if False:\r\n+    hiddenLeft=set(hiddenVars)\r\n+    seq=[]\r\n+    for v in model.varsDep:\r\n+      #Check if factor variable is a (unhandled) hidden variable\r\n+      if v in hiddenLeft:\r\n+        seq.append( (True,v) ) #If so, trigger a marginalization\r\n+        hiddenLeft.remove(v)   #And mark it as handled\r\n+      for p in model.varDist[v].parents:\r\n+        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n+        if p in hiddenLeft:\r\n+          seq.append( (True,p) )\r\n+          hiddenLeft.remove(p)\r\n+      seq.append( (False,v) ) #Then process the factor itself\r\n+    assert(len(hiddenLeft)==0)\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Arbitrary ordering\r\n+  #\r\n+  # What if we wanted to handle hidden variables in an arbitrary order?\r\n+  #\r\n+  # Possible, but we'll have to be careful where we put factors, after\r\n+  # all their dependencies are satisfied.\r\n+  def seq_from_hid_order(hOrd):\r\n+    #The trick to make this work is to first assign every\r\n+    #hidden variable a priority based on the order\r\n+    prio={h:i for i,h in enumerate(hOrd)}\r\n+    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n+    #Then rate each factor on the highest priority amongst its dependencies\r\n+    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n+    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n+    vOrd.sort()\r\n+    #All that's left is to turn it into the expected sequence format\r\n+    return list( (not nm,v) for _,nm,v in vOrd )\r\n+  \r\n+  #--------------------------------------------------------\r\n+  # Brute force best\r\n+  #\r\n+  # Now, where to get an ordering to use the above?\r\n+  #\r\n+  # We could brute force try every possible ordering...\r\n+  if True:\r\n+    bestSeq=None\r\n+    bestSeqCost=sys.maxsize\r\n+    for hOrd in permutations(hiddenVars):\r\n+      tSeq=seq_from_hid_order(hOrd)\r\n+      #Note, really should do below norm optimization here too\r\n+      \r\n+      #Now the tricky bit is to rate each ordering\r\n+      #We'll do it by doubling the cost of each factor every time\r\n+      #We cross a summation\r\n+      tot=0\r\n+      ct=1\r\n+      for m,v in tSeq:\r\n+        if m:\r\n+          ct*=2\r\n+        else:\r\n+          tot+=ct\r\n+      \r\n+      if tot<bestSeqCost:\r\n+        bestSeq=tSeq\r\n+        bestSeqCost=tot\r\n+    seq=bestSeq\r\n+  # But this will be very expensive for large models\r\n+  #--------------------------------------------------------\r\n+  # Greedy\r\n+  #\r\n+  # Alternately, we could apply a greedy approach.\r\n+  #\r\n+  # Some how rate each hidden variable on how expensive we think\r\n+  # it is, then put the most expensive ones earliest\r\n+  # ***TODO***\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Simple normalization optimization\r\n+  #\r\n+  # One thing we learned is that for a multiplicative term,\r\n+  # if it doesn't mention the query variable, then it's a\r\n+  # constant and can be handled via normalization (folded into alpha)\r\n+  #\r\n+  # This is non-trivial to detect for summation terms, but we\r\n+  # can easily do it for factors outside of any summation...\r\n+  if True:\r\n+    i=0\r\n+    while i<len(seq):\r\n+      m,v=seq[i]\r\n+      if m:\r\n+        break #Found first summation, quit\r\n+      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n+        #No mention of query variable, remove\r\n+        del seq[i]\r\n+      else:\r\n+        i+=1\r\n+  \r\n+  return seq\r\n+\r\n+def calc_query_approx(model,queryVar,queryVal,evidence):\r\n+  raise NotImplementedError()\r\n+\r\n+def generate_joint_prob_table(model):\r\n+  \"\"\"\r\n+  Output a joint probability table for the provided model\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  table=[]\r\n+  row=list(model.vars)\r\n+  row.append('Joint Pr')\r\n+  table.append(row)\r\n+  for varVals in truefalse_combination_iterator(model.vars):\r\n+    pr=calc_global_joint_prob(model,varVals)\r\n+    row=[varVals[x] for x in model.vars]\r\n+    row.append(pr)\r\n+    table.append(row)\r\n+  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+  return\r\n+\r\n+def read_model_file(filename):\r\n+  \"\"\"\r\n+  Returns model object with the following elements:\r\n+    vars : list of strings\r\n+      The list of variables the model describes\r\n+      In alphabetical order\r\n+    varsDep : list of strings\r\n+      Same contents as 'vars' but in dependency order (parents come before children)\r\n+    varDist : dict of objects\r\n+      Distribution information for each variable\r\n+      Dictionary key is variable name\r\n+      Object has the following elements:\r\n+        parents : set of strings\r\n+        children : set of strings\r\n+        cpt : dict of numbers\r\n+          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n+          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n+            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n+  Model file format is as follows:\r\n+    Basic file format is Comma-Separated Value (.csv)\r\n+    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n+    Tables are separated by atleast one empty line\r\n+    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n+    Each table:\r\n+      Starts with a header row containing variable names\r\n+        The last name is the variable whose cond probability is being described\r\n+        Any preceding names are considered to be parent variables\r\n+      Following rows contain True/False values for each parent and probability for main variable being true\r\n+      Any missing parent value combinations will be assumed to be probability 0.5\r\n+    Only Bernoulli/Boolean variables can be represented in this file format\r\n+  \"\"\"\r\n+  class ModelObj:\r\n+    def __init__(self):\r\n+      self.vars=[]\r\n+      self.varsDep=None\r\n+      self.varDist={}\r\n+\r\n+  class VarObj:\r\n+    def __init__(self, parents, children, cpt):\r\n+      self.parents = parents\r\n+      self.children = children\r\n+      self.cpt = cpt\r\n+\r\n+  model=ModelObj()\r\n+  #--------------------------------------------------------\r\n+  #Read data from file\r\n+  with open(filename, newline='') as csvfile:\r\n+    csvreader = csv.reader(csvfile)\r\n+    \r\n+    rowNum=0\r\n+    var=None\r\n+    varIdx=None\r\n+    parents=None\r\n+    cpt=None\r\n+    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n+      rowNum+=1\r\n+      srow=''.join(row).strip()\r\n+      if srow.startswith('#'):\r\n+        continue #Comment line, skip\r\n+      if len(srow)==0:\r\n+        #Empty line\r\n+        if var is not None:\r\n+          #End current table\r\n+          model.vars.append(var)\r\n+          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n+          #Wait for new table\r\n+          var=None\r\n+          varIdx=None\r\n+          parents=None\r\n+          cpt=None\r\n+      elif var is None:\r\n+        #Start new table\r\n+        if len(row)>1:\r\n+          parents=row[0:-1]\r\n+        else:\r\n+          parents=[]\r\n+        varIdx=len(row)-1\r\n+        var=row[varIdx]\r\n+        cpt={}\r\n+      else:\r\n+        #Add new entry to table\r\n+        if len(row)<varIdx+1:\r\n+          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n+        if len(parents)>0:\r\n+          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n+        else:\r\n+          key=frozenset()\r\n+        cpt[key]=float(row[-1])\r\n+  model.vars.sort()\r\n+  #--------------------------------------------------------\r\n+  # Check distributions for missing entries\r\n+  vCheck=frozenset(model.vars)\r\n+  for var in model.vars: #Make sure every mentioned variable has an entry\r\n+    for p in model.varDist[var].parents:\r\n+      if p not in vCheck:\r\n+        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n+  for var in model.vars: #Check every cpt for missing rows\r\n+    varDist=model.varDist[var]\r\n+    missingCnt=0\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      key=frozenset(((x,v) for x,v in varVals.items()))\r\n+      if key not in varDist.cpt:\r\n+        missingCnt+=1\r\n+        varDist.cpt[key]=0.5\r\n+    if missingCnt>0:\r\n+      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n+  #--------------------------------------------------------\r\n+  # Create children entries\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=set()\r\n+  for var in model.vars:\r\n+    for p in model.varDist[var].parents:\r\n+      model.varDist[p].children.add(var)\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n+  #--------------------------------------------------------\r\n+  # Create dependency ordering\r\n+  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n+  idx=0\r\n+  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n+  while idx<len(varsDep):\r\n+    var=varsDep[idx]\r\n+    for c in model.varDist[var].children:\r\n+      parentsLeft[c]-=1\r\n+      if parentsLeft[c]==0:\r\n+        #All parents have been visited, so dependencies of this child are met\r\n+        varsDep.append(c)\r\n+      elif parentsLeft[c]<0:\r\n+        #Repeat visit to a parent can only happen if a cycle exists\r\n+        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n+    idx+=1\r\n+  model.varsDep=varsDep\r\n+  #--------------------------------------------------------\r\n+  return model\r\n+\r\n+def print_model(model):\r\n+  \"\"\"\r\n+  Print a model object back out in pretty form\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  for v in model.vars:\r\n+    varDist=model.varDist[v]\r\n+    print('--------------------------------------------------')\r\n+    print('Variable:',v)\r\n+    print('--------------------------------------------------')\r\n+    print('Children:',', '.join(varDist.children))\r\n+    \r\n+    table=[]\r\n+    row=list(varDist.parents)\r\n+    row.append('P({0}=T|...)'.format(v))\r\n+    table.append(row)\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      pr=read_cpt(model,v,varVals)\r\n+      row=[varVals[x] for x in varDist.parents]\r\n+      row.append(pr)\r\n+      table.append(row)\r\n+    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+    print(\"\")\r\n+    \r\n+##############################################################################\r\n+## Main functions\r\n+def main(args):\r\n+  global DEBUG_OUTPUT\r\n+  if args.debug:\r\n+    DEBUG_OUTPUT=1\r\n+  #Argument checking plus additional parsing\r\n+  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in table mode')\r\n+  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in print mode')\r\n+  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n+    error('Argument --query required in inference modes')\r\n+  elif args.query is not None:\r\n+    if '=' not in args.query:\r\n+      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n+    s=args.query.split('=')\r\n+    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n+  if args.evidence is None:\r\n+    args.evidence=[]\r\n+  else:\r\n+    ev=[]\r\n+    for e in args.evidence:\r\n+      if '=' not in e:\r\n+        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n+      s=e.split('=')\r\n+      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n+    args.evidence={ var:val for var,val in ev }\r\n+\r\n+  print('Reading model from',args.model)\r\n+  model=read_model_file(args.model)\r\n+\r\n+  if args.mode=='table':\r\n+    generate_joint_prob_table(model)\r\n+  elif args.mode=='print':\r\n+    print_model(model)\r\n+  else:\r\n+    #One of the inference modes\r\n+    #Check inputs against model\r\n+    if args.query[0] not in model.vars:\r\n+      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n+    for var,val in args.evidence.items():\r\n+      if var not in model.vars:\r\n+        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n+    #Output problem setup\r\n+    print(\"Inference mode:\",args.mode)\r\n+    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n+    if len(args.evidence)==0:\r\n+      print(\"No evidence\")\r\n+    else:\r\n+      print(\"Evidence:\")\r\n+      for var,val in args.evidence.items():\r\n+        print(\"  '{0}' is {1}\".format(var,val))\r\n+\r\n+    #Run inference\r\n+    pr=None\r\n+    if args.mode=='brute':\r\n+      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n+    elif args.mode=='tree':\r\n+      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n+    else: #args.mode=='approx'\r\n+      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n+    print('Probability is',pr)\r\n+\r\n+  return\r\n+\r\n+def error(msg):\r\n+  print(msg)\r\n+  sys.exit(1)\r\n+  return\r\n+\r\n+if __name__ == '__main__':\r\n+  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n+  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n+  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n+  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n+  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n+  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n+  args = parser.parse_args()\r\n+  error=lambda msg : parser.error(msg)\r\n+  main(args)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1699839800792,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,732 @@\n+import argparse\r\n+import csv\r\n+from itertools import chain, permutations\r\n+import math\r\n+#import matplotlib.pyplot as plt\r\n+#import numpy as np\r\n+from random import random\r\n+import sys\r\n+\r\n+DEBUG_OUTPUT=0\r\n+\r\n+##############################################################################\r\n+## Student code\r\n+def calc_global_joint_prob(model, variableValues):\r\n+  \"\"\"\r\n+  Calculate the global joint probability of a model for a specific set of values\r\n+  model: model object, see read_model_file() for specification\r\n+  variableValues: dictionary of boolean values, keys are variable names\r\n+  \"\"\"\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # You may assume variableValues is complete, i.e containes all variables in the model\r\n+  #   Thus, no marginalization is necessary\r\n+  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n+  #\r\n+  # You can find a complete descrition of the model object in the documentation of\r\n+  #   the read_model_file() function, BUT\r\n+  # All you will need is the list of variables: model.vars\r\n+  #\r\n+  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n+  #\r\n+  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n+  #\r\n+  # (Reference solution is 7 lines of code.)\r\n+  joint_prob = 1.0\r\n+  for var in model.vars:\r\n+      cpt_entry = read_cpt(model, var, variableValues)\r\n+      if variableValues[var]:\r\n+          joint_prob *= cpt_entry\r\n+      else:\r\n+          joint_prob *= 1 - cpt_entry\r\n+  return joint_prob\r\n+\r\n+def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+\r\n+  # This first attempt at probabilistic inference will use the brute-force (table)\r\n+  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n+  #\r\n+  # This requires the calculation of two joint probabilities based on the definition\r\n+  # of conditional probability:\r\n+  #                          Pr( Query & Evidence )\r\n+  #   Pr(Query | Evidence) = ----------------------\r\n+  #                              Pr( Evidence )\r\n+  #\r\n+  # Both of these joint probabilities can be calculated by going over every entry in\r\n+  # the global joint probability table and summing up the probabilities of those\r\n+  # entries that match what we're looking for\r\n+  \r\n+  def dict_issubset(d,sub):\r\n+    \"\"\"\r\n+    Returns True if every key,value pair in sub has a matching key and value in d\r\n+    Note: sub should not contain any entries with value None\r\n+    \"\"\"\r\n+    return all(d.get(key,None)==val for key,val in sub.items())\r\n+     \r\n+  pr_QE=0\r\n+  pr_E=0\r\n+  for jptEntry in truefalse_combination_iterator(model.vars):\r\n+    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # jptEntry will be a dictionary with a key for every variable in the model,\r\n+    #   and the loop will go over every possible combination of True/False for each variable\r\n+    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n+    #\r\n+    # Your task is to collect all the probabilities that match the evidence, and query\r\n+    #\r\n+    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n+    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n+    #\r\n+    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n+    #\r\n+    # (Reference solution is 4 lines of code.)\r\n+    if dict_issubset(jptEntry, evidence):\r\n+            pr_E += pr_entry\r\n+            if jptEntry[queryVar] == queryVal:\r\n+              pr_QE += pr_entry\r\n+  return pr_QE/pr_E\r\n+\r\n+def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+  \r\n+  # First step, we need to figure out what order we will calculate terms in and where\r\n+  # marginalization needs to happen.\r\n+  #\r\n+  # That said, though this is a part of the inference process that you need to know, it's a\r\n+  # bit tricky to get working in general, especially the optimization bits.\r\n+  #\r\n+  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n+  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n+  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n+  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n+  # For example, the formula on slide 20 would be represented as:\r\n+  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n+  # The formula on slide 21 would be:\r\n+  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n+  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n+  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n+  \r\n+  # Debug: Output a nicer version of the calculation order (inference formula)\r\n+  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n+  \r\n+  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n+  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n+  \r\n+  # Next step, implement the calculation\r\n+  #\r\n+  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n+  # and move on to implement the recurse_calc_query_exact_tree() function\r\n+  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n+  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n+  # and associated function and add your own calculation code here\r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n+  #\r\n+  # Normalize this result to get true probability.\r\n+  #\r\n+  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n+  #\r\n+  # Refer to the example on slide 30.\r\n+  #\r\n+  # (Reference solution is 3 lines of code.)\r\n+  total_probability = prQ_T + prQ_F\r\n+  prQ_T /= total_probability\r\n+  prQ_F /= total_probability\r\n+  \r\n+  # Return the probability which answers the query\r\n+  return prQ_T if queryVal else prQ_F\r\n+  \r\n+\r\n+def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n+  \"\"\"\r\n+  Recursiving process the summation tree \r\n+  \r\n+  model,queryVar,evidence: See calc_query_exact_tree()\r\n+  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n+    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n+  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n+  \"\"\"\r\n+  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n+\r\n+  # Your overall task in the function is to assign values to:\r\n+  #   prQ_T\r\n+  #   prQ_F\r\n+  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n+  # covering both cases where query=True and query=False.\r\n+\r\n+  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n+  if marginalize:\r\n+    #Summation term, need to branch over all possible values and continue calculation\r\n+    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n+    # calculation\r\n+    #\r\n+    # You will need to recurse for each element of the summation (i.e. each branch)\r\n+    # Then properly combine the results together\r\n+    #\r\n+    # Slides 26-28 show examples of resolving summations.\r\n+    #\r\n+    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n+    #   BUT remember to change it back to the original values when you are done!\r\n+    #   (The original value for unknown variables is None.)\r\n+    #\r\n+    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n+    #   example of how to make the recursive call(s)\r\n+    #\r\n+    # (Reference solution is 7 lines of code.)\r\n+    for value in [True, False]:\r\n+        # Update the variable value in the dictionary\r\n+        variableValues[var] = value\r\n+\r\n+        # Recurse for each element of the summation (each branch)\r\n+        prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+        # Combine the results together\r\n+        prQ_T += prR_T\r\n+        prQ_F += prR_F\r\n+\r\n+    # Restore the original value for the variable\r\n+    variableValues[var] = original_value\r\n+  else:\r\n+    #Probability term, calculate conditional probability for this variable and continue calculation\r\n+    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n+    if queryVar in model.varDist[var].parents:\r\n+      #Query variable is a condition for this term\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n+      #\r\n+      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n+      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n+      # consider both what happens when the query variable is True, and also when it is False.\r\n+      #\r\n+      # Copy from your code below and modify to deal with this additional element.\r\n+      #\r\n+      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 11 lines of code.)\r\n+      original_value = variableValues[var]\r\n+\r\n+        # Iterate over both cases when the query variable is True and False\r\n+      for query_value in [True, False]:\r\n+            # Update the variable value in the dictionary\r\n+            variableValues[var] = query_value\r\n+\r\n+            # Recurse for each case\r\n+            prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+            # Combine the results together\r\n+            if query_value:\r\n+                prQ_T *= prR_T\r\n+            else:\r\n+                prQ_F *= prR_F\r\n+\r\n+        # Restore the original value for the variable\r\n+      variableValues[var] = original_value\r\n+    elif var==queryVar:\r\n+      #This term is probability _for_ the Query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one second! (Atleast, I recommend this.)\r\n+      #\r\n+      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n+      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n+      # is False.\r\n+      #\r\n+      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n+      # \r\n+      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 5 additional lines of code.)\r\n+      original_value = variableValues[var]\r\n+\r\n+        # Iterate over both cases when the query variable is True and False\r\n+      for query_value in [True, False]:\r\n+            variableValues[var] = query_value\r\n+            prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+\r\n+            # Combine the results together\r\n+            if query_value:\r\n+                prQ_T *= prR_T\r\n+            else:\r\n+                prQ_F *= prR_F\r\n+\r\n+        # Restore the original value for the variable\r\n+      variableValues[var] = original_value\r\n+    else:\r\n+      #Simple term, no need to worry about query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one first! (It's the simplest of the three.)\r\n+      #\r\n+      # You need to get the conditional probability for this variable and correctly\r\n+      # combine it with the results of the recursive call above.\r\n+      #\r\n+      # Don't forget that this variable's value could be True or False!\r\n+      #\r\n+      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n+      #\r\n+      # (Reference solution is 5 lines of code.)\r\n+      cpt_entry =read_cpt(model, var, variableValues)\r\n+      if variableValues[var]:\r\n+          prQ_T *= cpt_entry\r\n+      else:\r\n+          prQ_F *= (1 - cpt_entry)\r\n+\r\n+    if len(remainingCalc)>1:\r\n+      #If there are still terms left, then recurse\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n+      \r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Update prQ_T, prQ_F with the results from the recursive call.\r\n+      #\r\n+      # How do you combine _factors_ together?\r\n+      #\r\n+      # (Reference solution is 2 lines of code.)\r\n+      prQ_T *= prR_T\r\n+      prQ_F *= prR_F\r\n+\r\n+  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n+  \r\n+##############################################################################\r\n+## Support code\r\n+def read_cpt(model,varName,condVals):\r\n+  \"\"\"\r\n+  Read conditional probability for a specified variable with provided condition (parent) values\r\n+  Note, the value returned is conditional probability for variable being True\r\n+  \r\n+  Warning: If you get an index exception and referenced key has None in it, this means\r\n+    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n+  \r\n+  model: model object, see read_model_file() for specification\r\n+  varName: string, variable name to read probability for\r\n+  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n+              (Missing conditions will cause errors, extraneous values will be ignored)\r\n+  \"\"\"\r\n+  if varName not in model.varDist:\r\n+    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n+  varDist=model.varDist[varName]\r\n+  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n+  if key not in varDist.cpt:\r\n+    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n+  return varDist.cpt[key]\r\n+\r\n+def truefalse_combination_iterator(entries):\r\n+  \"\"\"\r\n+  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n+  \"\"\"\r\n+  entries=list(entries)\r\n+  entries.reverse()\r\n+  if len(entries)>30:\r\n+    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n+  for c in range(1<<len(entries)):\r\n+    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n+\r\n+def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n+  \"\"\"\r\n+  Create represention of terms in an inference calculation such as on slides 20-21\r\n+  \r\n+  Returns a list of (boolean,string) tuples where:\r\n+    (True,variable) represents a summation term where a variable needs to be marginalized\r\n+    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n+  \"\"\"\r\n+  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Naive solution\r\n+  #\r\n+  # model.varsDep already has variables in order of dependency...\r\n+  # So take that and insert summation terms any time we encounter a new hidden variable\r\n+  #\r\n+  # Downside is little optimization, likely to have many unnecessary terms\r\n+  if False:\r\n+    hiddenLeft=set(hiddenVars)\r\n+    seq=[]\r\n+    for v in model.varsDep:\r\n+      #Check if factor variable is a (unhandled) hidden variable\r\n+      if v in hiddenLeft:\r\n+        seq.append( (True,v) ) #If so, trigger a marginalization\r\n+        hiddenLeft.remove(v)   #And mark it as handled\r\n+      for p in model.varDist[v].parents:\r\n+        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n+        if p in hiddenLeft:\r\n+          seq.append( (True,p) )\r\n+          hiddenLeft.remove(p)\r\n+      seq.append( (False,v) ) #Then process the factor itself\r\n+    assert(len(hiddenLeft)==0)\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Arbitrary ordering\r\n+  #\r\n+  # What if we wanted to handle hidden variables in an arbitrary order?\r\n+  #\r\n+  # Possible, but we'll have to be careful where we put factors, after\r\n+  # all their dependencies are satisfied.\r\n+  def seq_from_hid_order(hOrd):\r\n+    #The trick to make this work is to first assign every\r\n+    #hidden variable a priority based on the order\r\n+    prio={h:i for i,h in enumerate(hOrd)}\r\n+    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n+    #Then rate each factor on the highest priority amongst its dependencies\r\n+    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n+    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n+    vOrd.sort()\r\n+    #All that's left is to turn it into the expected sequence format\r\n+    return list( (not nm,v) for _,nm,v in vOrd )\r\n+  \r\n+  #--------------------------------------------------------\r\n+  # Brute force best\r\n+  #\r\n+  # Now, where to get an ordering to use the above?\r\n+  #\r\n+  # We could brute force try every possible ordering...\r\n+  if True:\r\n+    bestSeq=None\r\n+    bestSeqCost=sys.maxsize\r\n+    for hOrd in permutations(hiddenVars):\r\n+      tSeq=seq_from_hid_order(hOrd)\r\n+      #Note, really should do below norm optimization here too\r\n+      \r\n+      #Now the tricky bit is to rate each ordering\r\n+      #We'll do it by doubling the cost of each factor every time\r\n+      #We cross a summation\r\n+      tot=0\r\n+      ct=1\r\n+      for m,v in tSeq:\r\n+        if m:\r\n+          ct*=2\r\n+        else:\r\n+          tot+=ct\r\n+      \r\n+      if tot<bestSeqCost:\r\n+        bestSeq=tSeq\r\n+        bestSeqCost=tot\r\n+    seq=bestSeq\r\n+  # But this will be very expensive for large models\r\n+  #--------------------------------------------------------\r\n+  # Greedy\r\n+  #\r\n+  # Alternately, we could apply a greedy approach.\r\n+  #\r\n+  # Some how rate each hidden variable on how expensive we think\r\n+  # it is, then put the most expensive ones earliest\r\n+  # ***TODO***\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Simple normalization optimization\r\n+  #\r\n+  # One thing we learned is that for a multiplicative term,\r\n+  # if it doesn't mention the query variable, then it's a\r\n+  # constant and can be handled via normalization (folded into alpha)\r\n+  #\r\n+  # This is non-trivial to detect for summation terms, but we\r\n+  # can easily do it for factors outside of any summation...\r\n+  if True:\r\n+    i=0\r\n+    while i<len(seq):\r\n+      m,v=seq[i]\r\n+      if m:\r\n+        break #Found first summation, quit\r\n+      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n+        #No mention of query variable, remove\r\n+        del seq[i]\r\n+      else:\r\n+        i+=1\r\n+  \r\n+  return seq\r\n+\r\n+def calc_query_approx(model,queryVar,queryVal,evidence):\r\n+  raise NotImplementedError()\r\n+\r\n+def generate_joint_prob_table(model):\r\n+  \"\"\"\r\n+  Output a joint probability table for the provided model\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  table=[]\r\n+  row=list(model.vars)\r\n+  row.append('Joint Pr')\r\n+  table.append(row)\r\n+  for varVals in truefalse_combination_iterator(model.vars):\r\n+    pr=calc_global_joint_prob(model,varVals)\r\n+    row=[varVals[x] for x in model.vars]\r\n+    row.append(pr)\r\n+    table.append(row)\r\n+  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+  return\r\n+\r\n+def read_model_file(filename):\r\n+  \"\"\"\r\n+  Returns model object with the following elements:\r\n+    vars : list of strings\r\n+      The list of variables the model describes\r\n+      In alphabetical order\r\n+    varsDep : list of strings\r\n+      Same contents as 'vars' but in dependency order (parents come before children)\r\n+    varDist : dict of objects\r\n+      Distribution information for each variable\r\n+      Dictionary key is variable name\r\n+      Object has the following elements:\r\n+        parents : set of strings\r\n+        children : set of strings\r\n+        cpt : dict of numbers\r\n+          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n+          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n+            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n+  Model file format is as follows:\r\n+    Basic file format is Comma-Separated Value (.csv)\r\n+    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n+    Tables are separated by atleast one empty line\r\n+    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n+    Each table:\r\n+      Starts with a header row containing variable names\r\n+        The last name is the variable whose cond probability is being described\r\n+        Any preceding names are considered to be parent variables\r\n+      Following rows contain True/False values for each parent and probability for main variable being true\r\n+      Any missing parent value combinations will be assumed to be probability 0.5\r\n+    Only Bernoulli/Boolean variables can be represented in this file format\r\n+  \"\"\"\r\n+  class ModelObj:\r\n+    def __init__(self):\r\n+      self.vars=[]\r\n+      self.varsDep=None\r\n+      self.varDist={}\r\n+\r\n+  class VarObj:\r\n+    def __init__(self, parents, children, cpt):\r\n+      self.parents = parents\r\n+      self.children = children\r\n+      self.cpt = cpt\r\n+\r\n+  model=ModelObj()\r\n+  #--------------------------------------------------------\r\n+  #Read data from file\r\n+  with open(filename, newline='') as csvfile:\r\n+    csvreader = csv.reader(csvfile)\r\n+    \r\n+    rowNum=0\r\n+    var=None\r\n+    varIdx=None\r\n+    parents=None\r\n+    cpt=None\r\n+    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n+      rowNum+=1\r\n+      srow=''.join(row).strip()\r\n+      if srow.startswith('#'):\r\n+        continue #Comment line, skip\r\n+      if len(srow)==0:\r\n+        #Empty line\r\n+        if var is not None:\r\n+          #End current table\r\n+          model.vars.append(var)\r\n+          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n+          #Wait for new table\r\n+          var=None\r\n+          varIdx=None\r\n+          parents=None\r\n+          cpt=None\r\n+      elif var is None:\r\n+        #Start new table\r\n+        if len(row)>1:\r\n+          parents=row[0:-1]\r\n+        else:\r\n+          parents=[]\r\n+        varIdx=len(row)-1\r\n+        var=row[varIdx]\r\n+        cpt={}\r\n+      else:\r\n+        #Add new entry to table\r\n+        if len(row)<varIdx+1:\r\n+          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n+        if len(parents)>0:\r\n+          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n+        else:\r\n+          key=frozenset()\r\n+        cpt[key]=float(row[-1])\r\n+  model.vars.sort()\r\n+  #--------------------------------------------------------\r\n+  # Check distributions for missing entries\r\n+  vCheck=frozenset(model.vars)\r\n+  for var in model.vars: #Make sure every mentioned variable has an entry\r\n+    for p in model.varDist[var].parents:\r\n+      if p not in vCheck:\r\n+        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n+  for var in model.vars: #Check every cpt for missing rows\r\n+    varDist=model.varDist[var]\r\n+    missingCnt=0\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      key=frozenset(((x,v) for x,v in varVals.items()))\r\n+      if key not in varDist.cpt:\r\n+        missingCnt+=1\r\n+        varDist.cpt[key]=0.5\r\n+    if missingCnt>0:\r\n+      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n+  #--------------------------------------------------------\r\n+  # Create children entries\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=set()\r\n+  for var in model.vars:\r\n+    for p in model.varDist[var].parents:\r\n+      model.varDist[p].children.add(var)\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n+  #--------------------------------------------------------\r\n+  # Create dependency ordering\r\n+  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n+  idx=0\r\n+  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n+  while idx<len(varsDep):\r\n+    var=varsDep[idx]\r\n+    for c in model.varDist[var].children:\r\n+      parentsLeft[c]-=1\r\n+      if parentsLeft[c]==0:\r\n+        #All parents have been visited, so dependencies of this child are met\r\n+        varsDep.append(c)\r\n+      elif parentsLeft[c]<0:\r\n+        #Repeat visit to a parent can only happen if a cycle exists\r\n+        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n+    idx+=1\r\n+  model.varsDep=varsDep\r\n+  #--------------------------------------------------------\r\n+  return model\r\n+\r\n+def print_model(model):\r\n+  \"\"\"\r\n+  Print a model object back out in pretty form\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  for v in model.vars:\r\n+    varDist=model.varDist[v]\r\n+    print('--------------------------------------------------')\r\n+    print('Variable:',v)\r\n+    print('--------------------------------------------------')\r\n+    print('Children:',', '.join(varDist.children))\r\n+    \r\n+    table=[]\r\n+    row=list(varDist.parents)\r\n+    row.append('P({0}=T|...)'.format(v))\r\n+    table.append(row)\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      pr=read_cpt(model,v,varVals)\r\n+      row=[varVals[x] for x in varDist.parents]\r\n+      row.append(pr)\r\n+      table.append(row)\r\n+    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+    print(\"\")\r\n+    \r\n+##############################################################################\r\n+## Main functions\r\n+def main(args):\r\n+  global DEBUG_OUTPUT\r\n+  if args.debug:\r\n+    DEBUG_OUTPUT=1\r\n+  #Argument checking plus additional parsing\r\n+  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in table mode')\r\n+  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in print mode')\r\n+  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n+    error('Argument --query required in inference modes')\r\n+  elif args.query is not None:\r\n+    if '=' not in args.query:\r\n+      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n+    s=args.query.split('=')\r\n+    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n+  if args.evidence is None:\r\n+    args.evidence=[]\r\n+  else:\r\n+    ev=[]\r\n+    for e in args.evidence:\r\n+      if '=' not in e:\r\n+        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n+      s=e.split('=')\r\n+      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n+    args.evidence={ var:val for var,val in ev }\r\n+\r\n+  print('Reading model from',args.model)\r\n+  model=read_model_file(args.model)\r\n+\r\n+  if args.mode=='table':\r\n+    generate_joint_prob_table(model)\r\n+  elif args.mode=='print':\r\n+    print_model(model)\r\n+  else:\r\n+    #One of the inference modes\r\n+    #Check inputs against model\r\n+    if args.query[0] not in model.vars:\r\n+      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n+    for var,val in args.evidence.items():\r\n+      if var not in model.vars:\r\n+        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n+    #Output problem setup\r\n+    print(\"Inference mode:\",args.mode)\r\n+    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n+    if len(args.evidence)==0:\r\n+      print(\"No evidence\")\r\n+    else:\r\n+      print(\"Evidence:\")\r\n+      for var,val in args.evidence.items():\r\n+        print(\"  '{0}' is {1}\".format(var,val))\r\n+\r\n+    #Run inference\r\n+    pr=None\r\n+    if args.mode=='brute':\r\n+      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n+    elif args.mode=='tree':\r\n+      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n+    else: #args.mode=='approx'\r\n+      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n+    print('Probability is',pr)\r\n+\r\n+  return\r\n+\r\n+def error(msg):\r\n+  print(msg)\r\n+  sys.exit(1)\r\n+  return\r\n+\r\n+if __name__ == '__main__':\r\n+  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n+  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n+  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n+  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n+  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n+  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n+  args = parser.parse_args()\r\n+  error=lambda msg : parser.error(msg)\r\n+  main(args)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1699839850486,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,708 @@\n+import argparse\r\n+import csv\r\n+from itertools import chain, permutations\r\n+import math\r\n+#import matplotlib.pyplot as plt\r\n+#import numpy as np\r\n+from random import random\r\n+import sys\r\n+\r\n+DEBUG_OUTPUT=0\r\n+\r\n+##############################################################################\r\n+## Student code\r\n+def calc_global_joint_prob(model, variableValues):\r\n+  \"\"\"\r\n+  Calculate the global joint probability of a model for a specific set of values\r\n+  model: model object, see read_model_file() for specification\r\n+  variableValues: dictionary of boolean values, keys are variable names\r\n+  \"\"\"\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # You may assume variableValues is complete, i.e containes all variables in the model\r\n+  #   Thus, no marginalization is necessary\r\n+  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n+  #\r\n+  # You can find a complete descrition of the model object in the documentation of\r\n+  #   the read_model_file() function, BUT\r\n+  # All you will need is the list of variables: model.vars\r\n+  #\r\n+  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n+  #\r\n+  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n+  #\r\n+  # (Reference solution is 7 lines of code.)\r\n+  joint_prob = 1.0\r\n+  for var in model.vars:\r\n+      cpt_entry = read_cpt(model, var, variableValues)\r\n+      if variableValues[var]:\r\n+          joint_prob *= cpt_entry\r\n+      else:\r\n+          joint_prob *= 1 - cpt_entry\r\n+  return joint_prob\r\n+\r\n+def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+\r\n+  # This first attempt at probabilistic inference will use the brute-force (table)\r\n+  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n+  #\r\n+  # This requires the calculation of two joint probabilities based on the definition\r\n+  # of conditional probability:\r\n+  #                          Pr( Query & Evidence )\r\n+  #   Pr(Query | Evidence) = ----------------------\r\n+  #                              Pr( Evidence )\r\n+  #\r\n+  # Both of these joint probabilities can be calculated by going over every entry in\r\n+  # the global joint probability table and summing up the probabilities of those\r\n+  # entries that match what we're looking for\r\n+  \r\n+  def dict_issubset(d,sub):\r\n+    \"\"\"\r\n+    Returns True if every key,value pair in sub has a matching key and value in d\r\n+    Note: sub should not contain any entries with value None\r\n+    \"\"\"\r\n+    return all(d.get(key,None)==val for key,val in sub.items())\r\n+     \r\n+  pr_QE=0\r\n+  pr_E=0\r\n+  for jptEntry in truefalse_combination_iterator(model.vars):\r\n+    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # jptEntry will be a dictionary with a key for every variable in the model,\r\n+    #   and the loop will go over every possible combination of True/False for each variable\r\n+    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n+    #\r\n+    # Your task is to collect all the probabilities that match the evidence, and query\r\n+    #\r\n+    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n+    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n+    #\r\n+    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n+    #\r\n+    # (Reference solution is 4 lines of code.)\r\n+    if dict_issubset(jptEntry, evidence):\r\n+            pr_E += pr_entry\r\n+            if jptEntry[queryVar] == queryVal:\r\n+              pr_QE += pr_entry\r\n+  return pr_QE/pr_E\r\n+\r\n+def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+  \r\n+  # First step, we need to figure out what order we will calculate terms in and where\r\n+  # marginalization needs to happen.\r\n+  #\r\n+  # That said, though this is a part of the inference process that you need to know, it's a\r\n+  # bit tricky to get working in general, especially the optimization bits.\r\n+  #\r\n+  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n+  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n+  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n+  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n+  # For example, the formula on slide 20 would be represented as:\r\n+  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n+  # The formula on slide 21 would be:\r\n+  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n+  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n+  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n+  \r\n+  # Debug: Output a nicer version of the calculation order (inference formula)\r\n+  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n+  \r\n+  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n+  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n+  \r\n+  # Next step, implement the calculation\r\n+  #\r\n+  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n+  # and move on to implement the recurse_calc_query_exact_tree() function\r\n+  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n+  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n+  # and associated function and add your own calculation code here\r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n+  #\r\n+  # Normalize this result to get true probability.\r\n+  #\r\n+  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n+  #\r\n+  # Refer to the example on slide 30.\r\n+  #\r\n+  # (Reference solution is 3 lines of code.)\r\n+  total_probability = prQ_T + prQ_F\r\n+  prQ_T /= total_probability\r\n+  prQ_F /= total_probability\r\n+  return prQ_T if queryVal else prQ_F\r\n+  \r\n+\r\n+def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n+  \"\"\"\r\n+  Recursiving process the summation tree \r\n+  \r\n+  model,queryVar,evidence: See calc_query_exact_tree()\r\n+  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n+    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n+  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n+  \"\"\"\r\n+  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n+\r\n+  # Your overall task in the function is to assign values to:\r\n+  #   prQ_T\r\n+  #   prQ_F\r\n+  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n+  # covering both cases where query=True and query=False.\r\n+\r\n+  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n+  if marginalize:\r\n+    #Summation term, need to branch over all possible values and continue calculation\r\n+    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n+    # calculation\r\n+    #\r\n+    # You will need to recurse for each element of the summation (i.e. each branch)\r\n+    # Then properly combine the results together\r\n+    #\r\n+    # Slides 26-28 show examples of resolving summations.\r\n+    #\r\n+    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n+    #   BUT remember to change it back to the original values when you are done!\r\n+    #   (The original value for unknown variables is None.)\r\n+    #\r\n+    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n+    #   example of how to make the recursive call(s)\r\n+    #\r\n+    # (Reference solution is 7 lines of code.)\r\n+    for value in [True, False]:\r\n+        variableValues[var] = value\r\n+        prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+        prQ_T += prR_T\r\n+        prQ_F += prR_F\r\n+    variableValues[var] = original_value\r\n+  else:\r\n+    #Probability term, calculate conditional probability for this variable and continue calculation\r\n+    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n+    if queryVar in model.varDist[var].parents:\r\n+      #Query variable is a condition for this term\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n+      #\r\n+      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n+      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n+      # consider both what happens when the query variable is True, and also when it is False.\r\n+      #\r\n+      # Copy from your code below and modify to deal with this additional element.\r\n+      #\r\n+      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 11 lines of code.)\r\n+      original_value = variableValues[var]\r\n+      for query_value in [True, False]:\r\n+            variableValues[var] = query_value\r\n+            prR_T, prR_F = recurse_calc_query_exact_tree\r\n+            if query_value:\r\n+                prQ_T *= prR_T\r\n+            else:\r\n+                prQ_F *= prR_F\r\n+      variableValues[var] = original_value\r\n+    elif var==queryVar:\r\n+      #This term is probability _for_ the Query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one second! (Atleast, I recommend this.)\r\n+      #\r\n+      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n+      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n+      # is False.\r\n+      #\r\n+      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n+      # \r\n+      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 5 additional lines of code.)\r\n+      original_value = variableValues[var]\r\n+      for query_value in [True, False]:\r\n+            variableValues[var] = query_value\r\n+            prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+            if query_value:\r\n+                prQ_T *= prR_T\r\n+            else:\r\n+                prQ_F *= prR_F\r\n+      variableValues[var] = original_value\r\n+    else:\r\n+      #Simple term, no need to worry about query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one first! (It's the simplest of the three.)\r\n+      #\r\n+      # You need to get the conditional probability for this variable and correctly\r\n+      # combine it with the results of the recursive call above.\r\n+      #\r\n+      # Don't forget that this variable's value could be True or False!\r\n+      #\r\n+      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n+      #\r\n+      # (Reference solution is 5 lines of code.)\r\n+      cpt_entry =read_cpt(model, var, variableValues)\r\n+      if variableValues[var]:\r\n+          prQ_T *= cpt_entry\r\n+      else:\r\n+          prQ_F *= (1 - cpt_entry)\r\n+\r\n+    if len(remainingCalc)>1:\r\n+      #If there are still terms left, then recurse\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n+      \r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Update prQ_T, prQ_F with the results from the recursive call.\r\n+      #\r\n+      # How do you combine _factors_ together?\r\n+      #\r\n+      # (Reference solution is 2 lines of code.)\r\n+      prQ_T *= prR_T\r\n+      prQ_F *= prR_F\r\n+\r\n+  return prQ_T, prQ_F\r\n+  \r\n+##############################################################################\r\n+## Support code\r\n+def read_cpt(model,varName,condVals):\r\n+  \"\"\"\r\n+  Read conditional probability for a specified variable with provided condition (parent) values\r\n+  Note, the value returned is conditional probability for variable being True\r\n+  \r\n+  Warning: If you get an index exception and referenced key has None in it, this means\r\n+    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n+  \r\n+  model: model object, see read_model_file() for specification\r\n+  varName: string, variable name to read probability for\r\n+  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n+              (Missing conditions will cause errors, extraneous values will be ignored)\r\n+  \"\"\"\r\n+  if varName not in model.varDist:\r\n+    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n+  varDist=model.varDist[varName]\r\n+  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n+  if key not in varDist.cpt:\r\n+    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n+  return varDist.cpt[key]\r\n+\r\n+def truefalse_combination_iterator(entries):\r\n+  \"\"\"\r\n+  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n+  \"\"\"\r\n+  entries=list(entries)\r\n+  entries.reverse()\r\n+  if len(entries)>30:\r\n+    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n+  for c in range(1<<len(entries)):\r\n+    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n+\r\n+def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n+  \"\"\"\r\n+  Create represention of terms in an inference calculation such as on slides 20-21\r\n+  \r\n+  Returns a list of (boolean,string) tuples where:\r\n+    (True,variable) represents a summation term where a variable needs to be marginalized\r\n+    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n+  \"\"\"\r\n+  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Naive solution\r\n+  #\r\n+  # model.varsDep already has variables in order of dependency...\r\n+  # So take that and insert summation terms any time we encounter a new hidden variable\r\n+  #\r\n+  # Downside is little optimization, likely to have many unnecessary terms\r\n+  if False:\r\n+    hiddenLeft=set(hiddenVars)\r\n+    seq=[]\r\n+    for v in model.varsDep:\r\n+      #Check if factor variable is a (unhandled) hidden variable\r\n+      if v in hiddenLeft:\r\n+        seq.append( (True,v) ) #If so, trigger a marginalization\r\n+        hiddenLeft.remove(v)   #And mark it as handled\r\n+      for p in model.varDist[v].parents:\r\n+        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n+        if p in hiddenLeft:\r\n+          seq.append( (True,p) )\r\n+          hiddenLeft.remove(p)\r\n+      seq.append( (False,v) ) #Then process the factor itself\r\n+    assert(len(hiddenLeft)==0)\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Arbitrary ordering\r\n+  #\r\n+  # What if we wanted to handle hidden variables in an arbitrary order?\r\n+  #\r\n+  # Possible, but we'll have to be careful where we put factors, after\r\n+  # all their dependencies are satisfied.\r\n+  def seq_from_hid_order(hOrd):\r\n+    #The trick to make this work is to first assign every\r\n+    #hidden variable a priority based on the order\r\n+    prio={h:i for i,h in enumerate(hOrd)}\r\n+    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n+    #Then rate each factor on the highest priority amongst its dependencies\r\n+    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n+    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n+    vOrd.sort()\r\n+    #All that's left is to turn it into the expected sequence format\r\n+    return list( (not nm,v) for _,nm,v in vOrd )\r\n+  \r\n+  #--------------------------------------------------------\r\n+  # Brute force best\r\n+  #\r\n+  # Now, where to get an ordering to use the above?\r\n+  #\r\n+  # We could brute force try every possible ordering...\r\n+  if True:\r\n+    bestSeq=None\r\n+    bestSeqCost=sys.maxsize\r\n+    for hOrd in permutations(hiddenVars):\r\n+      tSeq=seq_from_hid_order(hOrd)\r\n+      #Note, really should do below norm optimization here too\r\n+      \r\n+      #Now the tricky bit is to rate each ordering\r\n+      #We'll do it by doubling the cost of each factor every time\r\n+      #We cross a summation\r\n+      tot=0\r\n+      ct=1\r\n+      for m,v in tSeq:\r\n+        if m:\r\n+          ct*=2\r\n+        else:\r\n+          tot+=ct\r\n+      \r\n+      if tot<bestSeqCost:\r\n+        bestSeq=tSeq\r\n+        bestSeqCost=tot\r\n+    seq=bestSeq\r\n+  # But this will be very expensive for large models\r\n+  #--------------------------------------------------------\r\n+  # Greedy\r\n+  #\r\n+  # Alternately, we could apply a greedy approach.\r\n+  #\r\n+  # Some how rate each hidden variable on how expensive we think\r\n+  # it is, then put the most expensive ones earliest\r\n+  # ***TODO***\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Simple normalization optimization\r\n+  #\r\n+  # One thing we learned is that for a multiplicative term,\r\n+  # if it doesn't mention the query variable, then it's a\r\n+  # constant and can be handled via normalization (folded into alpha)\r\n+  #\r\n+  # This is non-trivial to detect for summation terms, but we\r\n+  # can easily do it for factors outside of any summation...\r\n+  if True:\r\n+    i=0\r\n+    while i<len(seq):\r\n+      m,v=seq[i]\r\n+      if m:\r\n+        break #Found first summation, quit\r\n+      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n+        #No mention of query variable, remove\r\n+        del seq[i]\r\n+      else:\r\n+        i+=1\r\n+  \r\n+  return seq\r\n+\r\n+def calc_query_approx(model,queryVar,queryVal,evidence):\r\n+  raise NotImplementedError()\r\n+\r\n+def generate_joint_prob_table(model):\r\n+  \"\"\"\r\n+  Output a joint probability table for the provided model\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  table=[]\r\n+  row=list(model.vars)\r\n+  row.append('Joint Pr')\r\n+  table.append(row)\r\n+  for varVals in truefalse_combination_iterator(model.vars):\r\n+    pr=calc_global_joint_prob(model,varVals)\r\n+    row=[varVals[x] for x in model.vars]\r\n+    row.append(pr)\r\n+    table.append(row)\r\n+  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+  return\r\n+\r\n+def read_model_file(filename):\r\n+  \"\"\"\r\n+  Returns model object with the following elements:\r\n+    vars : list of strings\r\n+      The list of variables the model describes\r\n+      In alphabetical order\r\n+    varsDep : list of strings\r\n+      Same contents as 'vars' but in dependency order (parents come before children)\r\n+    varDist : dict of objects\r\n+      Distribution information for each variable\r\n+      Dictionary key is variable name\r\n+      Object has the following elements:\r\n+        parents : set of strings\r\n+        children : set of strings\r\n+        cpt : dict of numbers\r\n+          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n+          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n+            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n+  Model file format is as follows:\r\n+    Basic file format is Comma-Separated Value (.csv)\r\n+    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n+    Tables are separated by atleast one empty line\r\n+    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n+    Each table:\r\n+      Starts with a header row containing variable names\r\n+        The last name is the variable whose cond probability is being described\r\n+        Any preceding names are considered to be parent variables\r\n+      Following rows contain True/False values for each parent and probability for main variable being true\r\n+      Any missing parent value combinations will be assumed to be probability 0.5\r\n+    Only Bernoulli/Boolean variables can be represented in this file format\r\n+  \"\"\"\r\n+  class ModelObj:\r\n+    def __init__(self):\r\n+      self.vars=[]\r\n+      self.varsDep=None\r\n+      self.varDist={}\r\n+\r\n+  class VarObj:\r\n+    def __init__(self, parents, children, cpt):\r\n+      self.parents = parents\r\n+      self.children = children\r\n+      self.cpt = cpt\r\n+\r\n+  model=ModelObj()\r\n+  #--------------------------------------------------------\r\n+  #Read data from file\r\n+  with open(filename, newline='') as csvfile:\r\n+    csvreader = csv.reader(csvfile)\r\n+    \r\n+    rowNum=0\r\n+    var=None\r\n+    varIdx=None\r\n+    parents=None\r\n+    cpt=None\r\n+    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n+      rowNum+=1\r\n+      srow=''.join(row).strip()\r\n+      if srow.startswith('#'):\r\n+        continue #Comment line, skip\r\n+      if len(srow)==0:\r\n+        #Empty line\r\n+        if var is not None:\r\n+          #End current table\r\n+          model.vars.append(var)\r\n+          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n+          #Wait for new table\r\n+          var=None\r\n+          varIdx=None\r\n+          parents=None\r\n+          cpt=None\r\n+      elif var is None:\r\n+        #Start new table\r\n+        if len(row)>1:\r\n+          parents=row[0:-1]\r\n+        else:\r\n+          parents=[]\r\n+        varIdx=len(row)-1\r\n+        var=row[varIdx]\r\n+        cpt={}\r\n+      else:\r\n+        #Add new entry to table\r\n+        if len(row)<varIdx+1:\r\n+          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n+        if len(parents)>0:\r\n+          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n+        else:\r\n+          key=frozenset()\r\n+        cpt[key]=float(row[-1])\r\n+  model.vars.sort()\r\n+  #--------------------------------------------------------\r\n+  # Check distributions for missing entries\r\n+  vCheck=frozenset(model.vars)\r\n+  for var in model.vars: #Make sure every mentioned variable has an entry\r\n+    for p in model.varDist[var].parents:\r\n+      if p not in vCheck:\r\n+        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n+  for var in model.vars: #Check every cpt for missing rows\r\n+    varDist=model.varDist[var]\r\n+    missingCnt=0\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      key=frozenset(((x,v) for x,v in varVals.items()))\r\n+      if key not in varDist.cpt:\r\n+        missingCnt+=1\r\n+        varDist.cpt[key]=0.5\r\n+    if missingCnt>0:\r\n+      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n+  #--------------------------------------------------------\r\n+  # Create children entries\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=set()\r\n+  for var in model.vars:\r\n+    for p in model.varDist[var].parents:\r\n+      model.varDist[p].children.add(var)\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n+  #--------------------------------------------------------\r\n+  # Create dependency ordering\r\n+  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n+  idx=0\r\n+  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n+  while idx<len(varsDep):\r\n+    var=varsDep[idx]\r\n+    for c in model.varDist[var].children:\r\n+      parentsLeft[c]-=1\r\n+      if parentsLeft[c]==0:\r\n+        #All parents have been visited, so dependencies of this child are met\r\n+        varsDep.append(c)\r\n+      elif parentsLeft[c]<0:\r\n+        #Repeat visit to a parent can only happen if a cycle exists\r\n+        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n+    idx+=1\r\n+  model.varsDep=varsDep\r\n+  #--------------------------------------------------------\r\n+  return model\r\n+\r\n+def print_model(model):\r\n+  \"\"\"\r\n+  Print a model object back out in pretty form\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  for v in model.vars:\r\n+    varDist=model.varDist[v]\r\n+    print('--------------------------------------------------')\r\n+    print('Variable:',v)\r\n+    print('--------------------------------------------------')\r\n+    print('Children:',', '.join(varDist.children))\r\n+    \r\n+    table=[]\r\n+    row=list(varDist.parents)\r\n+    row.append('P({0}=T|...)'.format(v))\r\n+    table.append(row)\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      pr=read_cpt(model,v,varVals)\r\n+      row=[varVals[x] for x in varDist.parents]\r\n+      row.append(pr)\r\n+      table.append(row)\r\n+    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+    print(\"\")\r\n+    \r\n+##############################################################################\r\n+## Main functions\r\n+def main(args):\r\n+  global DEBUG_OUTPUT\r\n+  if args.debug:\r\n+    DEBUG_OUTPUT=1\r\n+  #Argument checking plus additional parsing\r\n+  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in table mode')\r\n+  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in print mode')\r\n+  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n+    error('Argument --query required in inference modes')\r\n+  elif args.query is not None:\r\n+    if '=' not in args.query:\r\n+      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n+    s=args.query.split('=')\r\n+    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n+  if args.evidence is None:\r\n+    args.evidence=[]\r\n+  else:\r\n+    ev=[]\r\n+    for e in args.evidence:\r\n+      if '=' not in e:\r\n+        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n+      s=e.split('=')\r\n+      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n+    args.evidence={ var:val for var,val in ev }\r\n+\r\n+  print('Reading model from',args.model)\r\n+  model=read_model_file(args.model)\r\n+\r\n+  if args.mode=='table':\r\n+    generate_joint_prob_table(model)\r\n+  elif args.mode=='print':\r\n+    print_model(model)\r\n+  else:\r\n+    #One of the inference modes\r\n+    #Check inputs against model\r\n+    if args.query[0] not in model.vars:\r\n+      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n+    for var,val in args.evidence.items():\r\n+      if var not in model.vars:\r\n+        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n+    #Output problem setup\r\n+    print(\"Inference mode:\",args.mode)\r\n+    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n+    if len(args.evidence)==0:\r\n+      print(\"No evidence\")\r\n+    else:\r\n+      print(\"Evidence:\")\r\n+      for var,val in args.evidence.items():\r\n+        print(\"  '{0}' is {1}\".format(var,val))\r\n+\r\n+    #Run inference\r\n+    pr=None\r\n+    if args.mode=='brute':\r\n+      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n+    elif args.mode=='tree':\r\n+      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n+    else: #args.mode=='approx'\r\n+      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n+    print('Probability is',pr)\r\n+\r\n+  return\r\n+\r\n+def error(msg):\r\n+  print(msg)\r\n+  sys.exit(1)\r\n+  return\r\n+\r\n+if __name__ == '__main__':\r\n+  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n+  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n+  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n+  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n+  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n+  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n+  args = parser.parse_args()\r\n+  error=lambda msg : parser.error(msg)\r\n+  main(args)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1699839889059,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,708 @@\n+import argparse\r\n+import csv\r\n+from itertools import chain, permutations\r\n+import math\r\n+#import matplotlib.pyplot as plt\r\n+#import numpy as np\r\n+from random import random\r\n+import sys\r\n+\r\n+DEBUG_OUTPUT=0\r\n+\r\n+##############################################################################\r\n+## Student code\r\n+def calc_global_joint_prob(model, variableValues):\r\n+  \"\"\"\r\n+  Calculate the global joint probability of a model for a specific set of values\r\n+  model: model object, see read_model_file() for specification\r\n+  variableValues: dictionary of boolean values, keys are variable names\r\n+  \"\"\"\r\n+  \r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # You may assume variableValues is complete, i.e containes all variables in the model\r\n+  #   Thus, no marginalization is necessary\r\n+  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n+  #\r\n+  # You can find a complete descrition of the model object in the documentation of\r\n+  #   the read_model_file() function, BUT\r\n+  # All you will need is the list of variables: model.vars\r\n+  #\r\n+  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n+  #\r\n+  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n+  #\r\n+  # (Reference solution is 7 lines of code.)\r\n+  joint_prob = 1.0\r\n+  for var in model.vars:\r\n+      cpt_entry = read_cpt(model, var, variableValues)\r\n+      if variableValues[var]:\r\n+          joint_prob *= cpt_entry\r\n+      else:\r\n+          joint_prob *= 1 - cpt_entry\r\n+  return joint_prob\r\n+\r\n+def calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+\r\n+  # This first attempt at probabilistic inference will use the brute-force (table)\r\n+  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n+  #\r\n+  # This requires the calculation of two joint probabilities based on the definition\r\n+  # of conditional probability:\r\n+  #                          Pr( Query & Evidence )\r\n+  #   Pr(Query | Evidence) = ----------------------\r\n+  #                              Pr( Evidence )\r\n+  #\r\n+  # Both of these joint probabilities can be calculated by going over every entry in\r\n+  # the global joint probability table and summing up the probabilities of those\r\n+  # entries that match what we're looking for\r\n+  \r\n+  def dict_issubset(d,sub):\r\n+    \"\"\"\r\n+    Returns True if every key,value pair in sub has a matching key and value in d\r\n+    Note: sub should not contain any entries with value None\r\n+    \"\"\"\r\n+    return all(d.get(key,None)==val for key,val in sub.items())\r\n+     \r\n+  pr_QE=0\r\n+  pr_E=0\r\n+  for jptEntry in truefalse_combination_iterator(model.vars):\r\n+    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n+\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # jptEntry will be a dictionary with a key for every variable in the model,\r\n+    #   and the loop will go over every possible combination of True/False for each variable\r\n+    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n+    #\r\n+    # Your task is to collect all the probabilities that match the evidence, and query\r\n+    #\r\n+    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n+    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n+    #\r\n+    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n+    #\r\n+    # (Reference solution is 4 lines of code.)\r\n+    if dict_issubset(jptEntry, evidence):\r\n+            pr_E += pr_entry\r\n+            if jptEntry[queryVar] == queryVal:\r\n+              pr_QE += pr_entry\r\n+  return pr_QE/pr_E\r\n+\r\n+def calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n+  \"\"\"\r\n+  Calculate posterior probability for a given variable\r\n+\r\n+  model: model object, see read_model_file() for specification\r\n+  queryVar: string, query variable name\r\n+  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n+  evidence: dictionary of boolean values, where keys are evidence variable names\r\n+            (Any variable not listed as query or evidence is assumed to be hidden)\r\n+  \"\"\"\r\n+  \r\n+  # First step, we need to figure out what order we will calculate terms in and where\r\n+  # marginalization needs to happen.\r\n+  #\r\n+  # That said, though this is a part of the inference process that you need to know, it's a\r\n+  # bit tricky to get working in general, especially the optimization bits.\r\n+  #\r\n+  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n+  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n+  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n+  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n+  # For example, the formula on slide 20 would be represented as:\r\n+  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n+  # The formula on slide 21 would be:\r\n+  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n+  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n+  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n+  \r\n+  # Debug: Output a nicer version of the calculation order (inference formula)\r\n+  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n+  \r\n+  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n+  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n+  \r\n+  # Next step, implement the calculation\r\n+  #\r\n+  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n+  # and move on to implement the recurse_calc_query_exact_tree() function\r\n+  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n+  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n+  # and associated function and add your own calculation code here\r\n+  # YOUR CODE HERE\r\n+  #\r\n+  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n+  #\r\n+  # Normalize this result to get true probability.\r\n+  #\r\n+  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n+  #\r\n+  # Refer to the example on slide 30.\r\n+  #\r\n+  # (Reference solution is 3 lines of code.)\r\n+  total_probability = prQ_T + prQ_F\r\n+  prQ_T /= total_probability\r\n+  prQ_F /= total_probability\r\n+  return prQ_T if queryVal else prQ_F\r\n+  \r\n+\r\n+def recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n+  \"\"\"\r\n+  Recursiving process the summation tree \r\n+  \r\n+  model,queryVar,evidence: See calc_query_exact_tree()\r\n+  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n+    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n+  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n+  \"\"\"\r\n+  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n+\r\n+  # Your overall task in the function is to assign values to:\r\n+  #   prQ_T\r\n+  #   prQ_F\r\n+  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n+  # covering both cases where query=True and query=False.\r\n+\r\n+  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n+  if marginalize:\r\n+    #Summation term, need to branch over all possible values and continue calculation\r\n+    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n+    # YOUR CODE HERE\r\n+    #\r\n+    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n+    # calculation\r\n+    #\r\n+    # You will need to recurse for each element of the summation (i.e. each branch)\r\n+    # Then properly combine the results together\r\n+    #\r\n+    # Slides 26-28 show examples of resolving summations.\r\n+    #\r\n+    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n+    #   BUT remember to change it back to the original values when you are done!\r\n+    #   (The original value for unknown variables is None.)\r\n+    #\r\n+    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n+    #   example of how to make the recursive call(s)\r\n+    #\r\n+    # (Reference solution is 7 lines of code.)\r\n+    for value in [True, False]:\r\n+        variableValues[var] = value\r\n+        prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+        prQ_T += prR_T\r\n+        prQ_F += prR_F\r\n+    variableValues[var] = original_value\r\n+  else:\r\n+    #Probability term, calculate conditional probability for this variable and continue calculation\r\n+    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n+    if queryVar in model.varDist[var].parents:\r\n+      #Query variable is a condition for this term\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n+      #\r\n+      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n+      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n+      # consider both what happens when the query variable is True, and also when it is False.\r\n+      #\r\n+      # Copy from your code below and modify to deal with this additional element.\r\n+      #\r\n+      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 11 lines of code.)\r\n+      original_value = variableValues[var]\r\n+      for query_value in [True, False]:\r\n+            variableValues[var] = query_value\r\n+            prR_T, prR_F = recurse_calc_query_exact_tree\r\n+            if query_value:\r\n+                prQ_T *= prR_T\r\n+            else:\r\n+                prQ_F *= prR_F\r\n+      variableValues[var] = original_value\r\n+    elif var==queryVar:\r\n+      #This term is probability _for_ the Query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one second! (Atleast, I recommend this.)\r\n+      #\r\n+      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n+      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n+      # is False.\r\n+      #\r\n+      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n+      # \r\n+      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n+      #\r\n+      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n+      #   BUT remember to change it back to the original values when you are done!\r\n+      #\r\n+      # (Reference solution is 5 additional lines of code.)\r\n+      original_value = variableValues[var]\r\n+      for query_value in [True, False]:\r\n+            variableValues[var] = query_value\r\n+            prR_T, prR_F = recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc[1:])\r\n+            if query_value:\r\n+                prQ_T *= prR_T\r\n+            else:\r\n+                prQ_F *= prR_F\r\n+      variableValues[var] = original_value\r\n+    else:\r\n+      #Simple term, no need to worry about query variable\r\n+      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n+\r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Finish this one first! (It's the simplest of the three.)\r\n+      #\r\n+      # You need to get the conditional probability for this variable and correctly\r\n+      # combine it with the results of the recursive call above.\r\n+      #\r\n+      # Don't forget that this variable's value could be True or False!\r\n+      #\r\n+      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n+      #\r\n+      # (Reference solution is 5 lines of code.)\r\n+      cpt_entry =read_cpt(model, var, variableValues)\r\n+      if variableValues[var]:\r\n+          prQ_T *= cpt_entry\r\n+      else:\r\n+          prQ_F *= (1 - cpt_entry)\r\n+\r\n+    if len(remainingCalc)>1:\r\n+      #If there are still terms left, then recurse\r\n+      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n+      \r\n+      # YOUR CODE HERE\r\n+      #\r\n+      # Update prQ_T, prQ_F with the results from the recursive call.\r\n+      #\r\n+      # How do you combine _factors_ together?\r\n+      #\r\n+      # (Reference solution is 2 lines of code.)\r\n+      prQ_T *= prR_T\r\n+      prQ_F *= prR_F\r\n+\r\n+  return prQ_T, prQ_F\r\n+  \r\n+##############################################################################\r\n+## Support code\r\n+def read_cpt(model,varName,condVals):\r\n+  \"\"\"\r\n+  Read conditional probability for a specified variable with provided condition (parent) values\r\n+  Note, the value returned is conditional probability for variable being True\r\n+  \r\n+  Warning: If you get an index exception and referenced key has None in it, this means\r\n+    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n+  \r\n+  model: model object, see read_model_file() for specification\r\n+  varName: string, variable name to read probability for\r\n+  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n+              (Missing conditions will cause errors, extraneous values will be ignored)\r\n+  \"\"\"\r\n+  if varName not in model.varDist:\r\n+    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n+  varDist=model.varDist[varName]\r\n+  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n+  if key not in varDist.cpt:\r\n+    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n+  return varDist.cpt[key]\r\n+\r\n+def truefalse_combination_iterator(entries):\r\n+  \"\"\"\r\n+  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n+  \"\"\"\r\n+  entries=list(entries)\r\n+  entries.reverse()\r\n+  if len(entries)>30:\r\n+    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n+  for c in range(1<<len(entries)):\r\n+    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n+\r\n+def generate_exact_inf_term_seq(model,queryVar,evidence):\r\n+  \"\"\"\r\n+  Create represention of terms in an inference calculation such as on slides 20-21\r\n+  \r\n+  Returns a list of (boolean,string) tuples where:\r\n+    (True,variable) represents a summation term where a variable needs to be marginalized\r\n+    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n+  \"\"\"\r\n+  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Naive solution\r\n+  #\r\n+  # model.varsDep already has variables in order of dependency...\r\n+  # So take that and insert summation terms any time we encounter a new hidden variable\r\n+  #\r\n+  # Downside is little optimization, likely to have many unnecessary terms\r\n+  if False:\r\n+    hiddenLeft=set(hiddenVars)\r\n+    seq=[]\r\n+    for v in model.varsDep:\r\n+      #Check if factor variable is a (unhandled) hidden variable\r\n+      if v in hiddenLeft:\r\n+        seq.append( (True,v) ) #If so, trigger a marginalization\r\n+        hiddenLeft.remove(v)   #And mark it as handled\r\n+      for p in model.varDist[v].parents:\r\n+        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n+        if p in hiddenLeft:\r\n+          seq.append( (True,p) )\r\n+          hiddenLeft.remove(p)\r\n+      seq.append( (False,v) ) #Then process the factor itself\r\n+    assert(len(hiddenLeft)==0)\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Arbitrary ordering\r\n+  #\r\n+  # What if we wanted to handle hidden variables in an arbitrary order?\r\n+  #\r\n+  # Possible, but we'll have to be careful where we put factors, after\r\n+  # all their dependencies are satisfied.\r\n+  def seq_from_hid_order(hOrd):\r\n+    #The trick to make this work is to first assign every\r\n+    #hidden variable a priority based on the order\r\n+    prio={h:i for i,h in enumerate(hOrd)}\r\n+    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n+    #Then rate each factor on the highest priority amongst its dependencies\r\n+    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n+    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n+    vOrd.sort()\r\n+    #All that's left is to turn it into the expected sequence format\r\n+    return list( (not nm,v) for _,nm,v in vOrd )\r\n+  \r\n+  #--------------------------------------------------------\r\n+  # Brute force best\r\n+  #\r\n+  # Now, where to get an ordering to use the above?\r\n+  #\r\n+  # We could brute force try every possible ordering...\r\n+  if True:\r\n+    bestSeq=None\r\n+    bestSeqCost=sys.maxsize\r\n+    for hOrd in permutations(hiddenVars):\r\n+      tSeq=seq_from_hid_order(hOrd)\r\n+      #Note, really should do below norm optimization here too\r\n+      \r\n+      #Now the tricky bit is to rate each ordering\r\n+      #We'll do it by doubling the cost of each factor every time\r\n+      #We cross a summation\r\n+      tot=0\r\n+      ct=1\r\n+      for m,v in tSeq:\r\n+        if m:\r\n+          ct*=2\r\n+        else:\r\n+          tot+=ct\r\n+      \r\n+      if tot<bestSeqCost:\r\n+        bestSeq=tSeq\r\n+        bestSeqCost=tot\r\n+    seq=bestSeq\r\n+  # But this will be very expensive for large models\r\n+  #--------------------------------------------------------\r\n+  # Greedy\r\n+  #\r\n+  # Alternately, we could apply a greedy approach.\r\n+  #\r\n+  # Some how rate each hidden variable on how expensive we think\r\n+  # it is, then put the most expensive ones earliest\r\n+  # ***TODO***\r\n+\r\n+  #--------------------------------------------------------\r\n+  # Simple normalization optimization\r\n+  #\r\n+  # One thing we learned is that for a multiplicative term,\r\n+  # if it doesn't mention the query variable, then it's a\r\n+  # constant and can be handled via normalization (folded into alpha)\r\n+  #\r\n+  # This is non-trivial to detect for summation terms, but we\r\n+  # can easily do it for factors outside of any summation...\r\n+  if True:\r\n+    i=0\r\n+    while i<len(seq):\r\n+      m,v=seq[i]\r\n+      if m:\r\n+        break #Found first summation, quit\r\n+      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n+        #No mention of query variable, remove\r\n+        del seq[i]\r\n+      else:\r\n+        i+=1\r\n+  \r\n+  return seq\r\n+\r\n+def calc_query_approx(model,queryVar,queryVal,evidence):\r\n+  raise NotImplementedError()\r\n+\r\n+def generate_joint_prob_table(model):\r\n+  \"\"\"\r\n+  Output a joint probability table for the provided model\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  table=[]\r\n+  row=list(model.vars)\r\n+  row.append('Joint Pr')\r\n+  table.append(row)\r\n+  for varVals in truefalse_combination_iterator(model.vars):\r\n+    pr=calc_global_joint_prob(model,varVals)\r\n+    row=[varVals[x] for x in model.vars]\r\n+    row.append(pr)\r\n+    table.append(row)\r\n+  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+  return\r\n+\r\n+def read_model_file(filename):\r\n+  \"\"\"\r\n+  Returns model object with the following elements:\r\n+    vars : list of strings\r\n+      The list of variables the model describes\r\n+      In alphabetical order\r\n+    varsDep : list of strings\r\n+      Same contents as 'vars' but in dependency order (parents come before children)\r\n+    varDist : dict of objects\r\n+      Distribution information for each variable\r\n+      Dictionary key is variable name\r\n+      Object has the following elements:\r\n+        parents : set of strings\r\n+        children : set of strings\r\n+        cpt : dict of numbers\r\n+          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n+          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n+            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n+  Model file format is as follows:\r\n+    Basic file format is Comma-Separated Value (.csv)\r\n+    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n+    Tables are separated by atleast one empty line\r\n+    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n+    Each table:\r\n+      Starts with a header row containing variable names\r\n+        The last name is the variable whose cond probability is being described\r\n+        Any preceding names are considered to be parent variables\r\n+      Following rows contain True/False values for each parent and probability for main variable being true\r\n+      Any missing parent value combinations will be assumed to be probability 0.5\r\n+    Only Bernoulli/Boolean variables can be represented in this file format\r\n+  \"\"\"\r\n+  class ModelObj:\r\n+    def __init__(self):\r\n+      self.vars=[]\r\n+      self.varsDep=None\r\n+      self.varDist={}\r\n+\r\n+  class VarObj:\r\n+    def __init__(self, parents, children, cpt):\r\n+      self.parents = parents\r\n+      self.children = children\r\n+      self.cpt = cpt\r\n+\r\n+  model=ModelObj()\r\n+  #--------------------------------------------------------\r\n+  #Read data from file\r\n+  with open(filename, newline='') as csvfile:\r\n+    csvreader = csv.reader(csvfile)\r\n+    \r\n+    rowNum=0\r\n+    var=None\r\n+    varIdx=None\r\n+    parents=None\r\n+    cpt=None\r\n+    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n+      rowNum+=1\r\n+      srow=''.join(row).strip()\r\n+      if srow.startswith('#'):\r\n+        continue #Comment line, skip\r\n+      if len(srow)==0:\r\n+        #Empty line\r\n+        if var is not None:\r\n+          #End current table\r\n+          model.vars.append(var)\r\n+          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n+          #Wait for new table\r\n+          var=None\r\n+          varIdx=None\r\n+          parents=None\r\n+          cpt=None\r\n+      elif var is None:\r\n+        #Start new table\r\n+        if len(row)>1:\r\n+          parents=row[0:-1]\r\n+        else:\r\n+          parents=[]\r\n+        varIdx=len(row)-1\r\n+        var=row[varIdx]\r\n+        cpt={}\r\n+      else:\r\n+        #Add new entry to table\r\n+        if len(row)<varIdx+1:\r\n+          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n+        if len(parents)>0:\r\n+          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n+        else:\r\n+          key=frozenset()\r\n+        cpt[key]=float(row[-1])\r\n+  model.vars.sort()\r\n+  #--------------------------------------------------------\r\n+  # Check distributions for missing entries\r\n+  vCheck=frozenset(model.vars)\r\n+  for var in model.vars: #Make sure every mentioned variable has an entry\r\n+    for p in model.varDist[var].parents:\r\n+      if p not in vCheck:\r\n+        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n+  for var in model.vars: #Check every cpt for missing rows\r\n+    varDist=model.varDist[var]\r\n+    missingCnt=0\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      key=frozenset(((x,v) for x,v in varVals.items()))\r\n+      if key not in varDist.cpt:\r\n+        missingCnt+=1\r\n+        varDist.cpt[key]=0.5\r\n+    if missingCnt>0:\r\n+      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n+  #--------------------------------------------------------\r\n+  # Create children entries\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=set()\r\n+  for var in model.vars:\r\n+    for p in model.varDist[var].parents:\r\n+      model.varDist[p].children.add(var)\r\n+  for var in model.vars:\r\n+    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n+  #--------------------------------------------------------\r\n+  # Create dependency ordering\r\n+  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n+  idx=0\r\n+  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n+  while idx<len(varsDep):\r\n+    var=varsDep[idx]\r\n+    for c in model.varDist[var].children:\r\n+      parentsLeft[c]-=1\r\n+      if parentsLeft[c]==0:\r\n+        #All parents have been visited, so dependencies of this child are met\r\n+        varsDep.append(c)\r\n+      elif parentsLeft[c]<0:\r\n+        #Repeat visit to a parent can only happen if a cycle exists\r\n+        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n+    idx+=1\r\n+  model.varsDep=varsDep\r\n+  #--------------------------------------------------------\r\n+  return model\r\n+\r\n+def print_model(model):\r\n+  \"\"\"\r\n+  Print a model object back out in pretty form\r\n+  \"\"\"\r\n+  from tabulate import tabulate\r\n+  for v in model.vars:\r\n+    varDist=model.varDist[v]\r\n+    print('--------------------------------------------------')\r\n+    print('Variable:',v)\r\n+    print('--------------------------------------------------')\r\n+    print('Children:',', '.join(varDist.children))\r\n+    \r\n+    table=[]\r\n+    row=list(varDist.parents)\r\n+    row.append('P({0}=T|...)'.format(v))\r\n+    table.append(row)\r\n+    for varVals in truefalse_combination_iterator(varDist.parents):\r\n+      pr=read_cpt(model,v,varVals)\r\n+      row=[varVals[x] for x in varDist.parents]\r\n+      row.append(pr)\r\n+      table.append(row)\r\n+    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n+    print(\"\")\r\n+    \r\n+##############################################################################\r\n+## Main functions\r\n+def main(args):\r\n+  global DEBUG_OUTPUT\r\n+  if args.debug:\r\n+    DEBUG_OUTPUT=1\r\n+  #Argument checking plus additional parsing\r\n+  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in table mode')\r\n+  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n+    error('Arguments --query and --evidence not allowed in print mode')\r\n+  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n+    error('Argument --query required in inference modes')\r\n+  elif args.query is not None:\r\n+    if '=' not in args.query:\r\n+      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n+    s=args.query.split('=')\r\n+    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n+  if args.evidence is None:\r\n+    args.evidence=[]\r\n+  else:\r\n+    ev=[]\r\n+    for e in args.evidence:\r\n+      if '=' not in e:\r\n+        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n+      s=e.split('=')\r\n+      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n+    args.evidence={ var:val for var,val in ev }\r\n+\r\n+  print('Reading model from',args.model)\r\n+  model=read_model_file(args.model)\r\n+\r\n+  if args.mode=='table':\r\n+    generate_joint_prob_table(model)\r\n+  elif args.mode=='print':\r\n+    print_model(model)\r\n+  else:\r\n+    #One of the inference modes\r\n+    #Check inputs against model\r\n+    if args.query[0] not in model.vars:\r\n+      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n+    for var,val in args.evidence.items():\r\n+      if var not in model.vars:\r\n+        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n+    #Output problem setup\r\n+    print(\"Inference mode:\",args.mode)\r\n+    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n+    if len(args.evidence)==0:\r\n+      print(\"No evidence\")\r\n+    else:\r\n+      print(\"Evidence:\")\r\n+      for var,val in args.evidence.items():\r\n+        print(\"  '{0}' is {1}\".format(var,val))\r\n+\r\n+    #Run inference\r\n+    pr=None\r\n+    if args.mode=='brute':\r\n+      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n+    elif args.mode=='tree':\r\n+      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n+    else: #args.mode=='approx'\r\n+      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n+    print('Probability is',pr)\r\n+\r\n+  return\r\n+\r\n+def error(msg):\r\n+  print(msg)\r\n+  sys.exit(1)\r\n+  return\r\n+\r\n+if __name__ == '__main__':\r\n+  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n+  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n+  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n+  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n+  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n+  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n+  args = parser.parse_args()\r\n+  error=lambda msg : parser.error(msg)\r\n+  main(args)\n\\ No newline at end of file\n"
                }
            ],
            "date": 1699506624831,
            "name": "Commit-0",
            "content": "import argparse\r\nimport csv\r\nfrom itertools import chain, permutations\r\nimport math\r\n#import matplotlib.pyplot as plt\r\n#import numpy as np\r\nfrom random import random\r\nimport sys\r\n\r\nDEBUG_OUTPUT=0\r\n\r\n##############################################################################\r\n## Student code\r\ndef calc_global_joint_prob(model, variableValues):\r\n  \"\"\"\r\n  Calculate the global joint probability of a model for a specific set of values\r\n  model: model object, see read_model_file() for specification\r\n  variableValues: dictionary of boolean values, keys are variable names\r\n  \"\"\"\r\n  \r\n  # YOUR CODE HERE\r\n  read_model_file(burglary_alram.csv)\r\n  #\r\n  # You may assume variableValues is complete, i.e containes all variables in the model\r\n  #   Thus, no marginalization is necessary\r\n  # All you need to do is factorize the model, as shown in the example on slides 15-16\r\n  #\r\n  # You can find a complete descrition of the model object in the documentation of\r\n  #   the read_model_file() function, BUT\r\n  # All you will need is the list of variables: model.vars\r\n  #\r\n  # You may use the read_cpt() helper function to get the rest of what you need from the model object\r\n  #\r\n  # Hint: Don't forget that you need to handle the fact that variables can have both True and False values!\r\n  #\r\n  # (Reference solution is 7 lines of code.)\r\n  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n\r\ndef calc_query_exact_brute(model, queryVar, queryVal, evidence):\r\n  \"\"\"\r\n  Calculate posterior probability for a given variable\r\n\r\n  model: model object, see read_model_file() for specification\r\n  queryVar: string, query variable name\r\n  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n  evidence: dictionary of boolean values, where keys are evidence variable names\r\n            (Any variable not listed as query or evidence is assumed to be hidden)\r\n  \"\"\"\r\n\r\n  # This first attempt at probabilistic inference will use the brute-force (table)\r\n  #   enumeration approach shown in the Probability Intro slides (see slide 24)\r\n  #\r\n  # This requires the calculation of two joint probabilities based on the definition\r\n  # of conditional probability:\r\n  #                          Pr( Query & Evidence )\r\n  #   Pr(Query | Evidence) = ----------------------\r\n  #                              Pr( Evidence )\r\n  #\r\n  # Both of these joint probabilities can be calculated by going over every entry in\r\n  # the global joint probability table and summing up the probabilities of those\r\n  # entries that match what we're looking for\r\n  \r\n  def dict_issubset(d,sub):\r\n    \"\"\"\r\n    Returns True if every key,value pair in sub has a matching key and value in d\r\n    Note: sub should not contain any entries with value None\r\n    \"\"\"\r\n    return all(d.get(key,None)==val for key,val in sub.items())\r\n     \r\n  pr_QE=0\r\n  pr_E=0\r\n  for jptEntry in truefalse_combination_iterator(model.vars):\r\n    pr_entry=calc_global_joint_prob(model,jptEntry)\r\n\r\n    # YOUR CODE HERE\r\n    #\r\n    # jptEntry will be a dictionary with a key for every variable in the model,\r\n    #   and the loop will go over every possible combination of True/False for each variable\r\n    # (See generate_joint_prob_table() for an example of the truefalse_combination_iterator() generator in use.)\r\n    #\r\n    # Your task is to collect all the probabilities that match the evidence, and query\r\n    #\r\n    # Slides 22-23 of the \"Probability Intro\" slideset show examples of simple inference with joint probability tables.\r\n    # Slides 24-25 of the \"Probability Intro\" slideset show examples of calculating conditional probabilities.\r\n    #\r\n    # Hint: You would find a dictionary \"is subset\" operation very useful in solving this problem\r\n    #\r\n    # (Reference solution is 4 lines of code.)\r\n    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n\r\n  return pr_QE/pr_E\r\n\r\ndef calc_query_exact_tree(model, queryVar, queryVal, evidence):\r\n  \"\"\"\r\n  Calculate posterior probability for a given variable\r\n\r\n  model: model object, see read_model_file() for specification\r\n  queryVar: string, query variable name\r\n  queryVal: boolean, value of the query variable we are calculating the probabilty for\r\n  evidence: dictionary of boolean values, where keys are evidence variable names\r\n            (Any variable not listed as query or evidence is assumed to be hidden)\r\n  \"\"\"\r\n  \r\n  # First step, we need to figure out what order we will calculate terms in and where\r\n  # marginalization needs to happen.\r\n  #\r\n  # That said, though this is a part of the inference process that you need to know, it's a\r\n  # bit tricky to get working in general, especially the optimization bits.\r\n  #\r\n  # So I have provided an implementation for this below. If you're curious, feel free to have a look.\r\n  calcOrder=generate_exact_inf_term_seq(model,queryVar,evidence)\r\n  # This will return a list of (boolean,string) tuples that indicates which parts need to be calculated in which order.\r\n  # True indicates a summation (i.e. marginalization) term, False indicates a probability term.\r\n  # For example, the formula on slide 20 would be represented as:\r\n  # [ (True,'A'), (True,'E'), (False,'J'), (False,'M'), (False,'A'), (False,'B'), (False,'E') ]\r\n  # The formula on slide 21 would be:\r\n  # [ (False,'B'), (True,'A'), (False,'J'), (False,'M'), (True,'E'), (False,'A'), (False,'E') ]\r\n  # Some marginalization terms for hidden variables, and probability terms for any variables, may be missing\r\n  # if my code determines they can be optimized away (e.g., handled by normalization instead).\r\n  \r\n  # Debug: Output a nicer version of the calculation order (inference formula)\r\n  if DEBUG_OUTPUT>0: print('Inf formula: '+' '.join( ( ('sum('+v+')') if m else 'P({0}|{1})'.format(v,','.join(model.varDist[v].parents)) ) for m,v in calcOrder))\r\n  \r\n  #Make a dictionary with entries for every possible variable, and their values where available (None otherwise)\r\n  variableValues={v:evidence.get(v,None) for v in model.vars}\r\n  \r\n  # Next step, implement the calculation\r\n  #\r\n  # I strongly recommend using a recursive solution, in which case leave the below line of code\r\n  # and move on to implement the recurse_calc_query_exact_tree() function\r\n  prQ_T,prQ_F=recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,calcOrder)\r\n  # HOWEVER, you are not required to implement recursively, in which case delete the above line\r\n  # and associated function and add your own calculation code here\r\n  \r\n  # YOUR CODE HERE\r\n  #\r\n  # The result from above is the *relative* probability that our query variable is True (prQ_T) or False (prQ_F).\r\n  #\r\n  # Normalize this result to get true probability.\r\n  #\r\n  # Then return the probability which answers the query (i.e. queryVal could be True or False)\r\n  #\r\n  # Refer to the example on slide 30.\r\n  #\r\n  # (Reference solution is 3 lines of code.)\r\n  raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n\r\ndef recurse_calc_query_exact_tree(model, queryVar, evidence, variableValues, remainingCalc):\r\n  \"\"\"\r\n  Recursiving process the summation tree \r\n  \r\n  model,queryVar,evidence: See calc_query_exact_tree()\r\n  variableValues: dictionary of boolean values or None, values for entire set of variables or None if no value set yet\r\n    Note: You MAY change this structure during the recursion, but make sure undo those changes when you're done with them\r\n  remainingCalc: list of (boolean,string), see XXX and comments in calc_query_exact_tree() for format\r\n  \"\"\"\r\n  if DEBUG_OUTPUT>0: indent='    '*(len(evidence)-sum(m for m,v in remainingCalc)) #Indent based on how deep in the recursion we are\r\n\r\n  # Your overall task in the function is to assign values to:\r\n  #   prQ_T\r\n  #   prQ_F\r\n  # Which should (eventually) contain the (relative) probabilities for the remainder of the calculation\r\n  # covering both cases where query=True and query=False.\r\n\r\n  marginalize,var=remainingCalc[0] #Grab details for the next term we have to deal with\r\n  if marginalize:\r\n    #Summation term, need to branch over all possible values and continue calculation\r\n    if DEBUG_OUTPUT>0: print(indent+'Sum over '+var)\r\n\r\n    # YOUR CODE HERE\r\n    #\r\n    # This represents a summation term in our equation, or equivalently a branch in the tree view of our\r\n    # calculation\r\n    #\r\n    # You will need to recurse for each element of the summation (i.e. each branch)\r\n    # Then properly combine the results together\r\n    #\r\n    # Slides 26-28 show examples of resolving summations.\r\n    #\r\n    # Hint: You will find it useful to change some values in the 'variableValues' dictionary.\r\n    #   BUT remember to change it back to the original values when you are done!\r\n    #   (The original value for unknown variables is None.)\r\n    #\r\n    # Hint 2: It might help you to skip this initially and work on the below code first, as it includes an\r\n    #   example of how to make the recursive call(s)\r\n    #\r\n    # (Reference solution is 7 lines of code.)\r\n    raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n  else:\r\n    #Probability term, calculate conditional probability for this variable and continue calculation\r\n    prQ_T, prQ_F = 1,1 #Base case if we don't recurse below\r\n    if queryVar in model.varDist[var].parents:\r\n      #Query variable is a condition for this term\r\n      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [QC]'.format(var,','.join(model.varDist[var].parents)))\r\n\r\n      # YOUR CODE HERE\r\n      #\r\n      # Finish this one third! (Atleast, I strongly recommend doing so.)\r\n      #\r\n      # The reason is that this code has the same purpose as 'Simple term', but you must deal with the\r\n      # fact that the query variable is involved as a condition of this term. Meaning you have to\r\n      # consider both what happens when the query variable is True, and also when it is False.\r\n      #\r\n      # Copy from your code below and modify to deal with this additional element.\r\n      #\r\n      # Slides 25-26 show examples of dealing with terms referencing the query variable.\r\n      #\r\n      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n      #   BUT remember to change it back to the original values when you are done!\r\n      #\r\n      # (Reference solution is 11 lines of code.)\r\n      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n    elif var==queryVar:\r\n      #This term is probability _for_ the Query variable\r\n      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [Q]'.format(var,','.join(model.varDist[var].parents)))\r\n\r\n      # YOUR CODE HERE\r\n      #\r\n      # Finish this one second! (Atleast, I recommend this.)\r\n      #\r\n      # In this case, you are dealing with the term specifically for the query variable. You will need\r\n      # to address the fact that we calculate for cases when the query variable is True and also when it\r\n      # is False.\r\n      #\r\n      # Other than that, the code is very similar to your 'Simple term' solution below, so copy that and modify.\r\n      # \r\n      # Slides 29 show examples of dealing with terms referencing the query variable.\r\n      #\r\n      # Hint: As above, you will find it useful to change some values in the 'variableValues' dictionary.\r\n      #   BUT remember to change it back to the original values when you are done!\r\n      #\r\n      # (Reference solution is 5 additional lines of code.)\r\n      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n    else:\r\n      #Simple term, no need to worry about query variable\r\n      if DEBUG_OUTPUT>0: print(indent+'P({0}|{1}) [S]'.format(var,','.join(model.varDist[var].parents)))\r\n\r\n      # YOUR CODE HERE\r\n      #\r\n      # Finish this one first! (It's the simplest of the three.)\r\n      #\r\n      # You need to get the conditional probability for this variable and correctly\r\n      # combine it with the results of the recursive call above.\r\n      #\r\n      # Don't forget that this variable's value could be True or False!\r\n      #\r\n      # Slide 28 shows examples of dealing with terms that *do not* reference the query variable.\r\n      #\r\n      # (Reference solution is 5 lines of code.)\r\n      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n\r\n    if len(remainingCalc)>1:\r\n      #If there are still terms left, then recurse\r\n      prR_T, prR_F = recurse_calc_query_exact_tree(model,queryVar,evidence,variableValues,remainingCalc[1:])\r\n      \r\n      # YOUR CODE HERE\r\n      #\r\n      # Update prQ_T, prQ_F with the results from the recursive call.\r\n      #\r\n      # How do you combine _factors_ together?\r\n      #\r\n      # (Reference solution is 2 lines of code.)\r\n      raise NotImplementedError() #DELETE AND ADD YOUR CODE\r\n\r\n  return prQ_T, prQ_F #Return (relative) probability that query is True vs False\r\n  \r\n##############################################################################\r\n## Support code\r\ndef read_cpt(model,varName,condVals):\r\n  \"\"\"\r\n  Read conditional probability for a specified variable with provided condition (parent) values\r\n  Note, the value returned is conditional probability for variable being True\r\n  \r\n  Warning: If you get an index exception and referenced key has None in it, this means\r\n    the dictionary you passed for condVals doesn't contain all the needed condition values\r\n  \r\n  model: model object, see read_model_file() for specification\r\n  varName: string, variable name to read probability for\r\n  condValues: dictionary of boolean values, where keys are condition/parent names for the specificed variable\r\n              (Missing conditions will cause errors, extraneous values will be ignored)\r\n  \"\"\"\r\n  if varName not in model.varDist:\r\n    raise ValueError(\"Variable '{0}' not in model\".format(varName))\r\n  varDist=model.varDist[varName]\r\n  key=frozenset(((x,condVals.get(x,None)) for x in varDist.parents))\r\n  if key not in varDist.cpt:\r\n    raise IndexError(\"CPT for variable '{0}' has no entry matching:\\n{1}\".format(varName,\"\\n\".join(\"{0}={1}\".format(x,v) for x,v in key)))\r\n  return varDist.cpt[key]\r\n\r\ndef truefalse_combination_iterator(entries):\r\n  \"\"\"\r\n  Create a sequence of dictonaries contain all possible combinations of True and False for each entry in 'entries'\r\n  \"\"\"\r\n  entries=list(entries)\r\n  entries.reverse()\r\n  if len(entries)>30:\r\n    error('truefalse_combination_iterator() does not support more than 30 entries at this time')\r\n  for c in range(1<<len(entries)):\r\n    yield {x:(c&(1<<i))>0 for x,i in zip(entries,range(len(entries)))}\r\n\r\ndef generate_exact_inf_term_seq(model,queryVar,evidence):\r\n  \"\"\"\r\n  Create represention of terms in an inference calculation such as on slides 20-21\r\n  \r\n  Returns a list of (boolean,string) tuples where:\r\n    (True,variable) represents a summation term where a variable needs to be marginalized\r\n    (False,variable) represents a probability term where the conditional probability of a term needs to be included\r\n  \"\"\"\r\n  hiddenVars=tuple(v for v in model.vars if (v!=queryVar and v not in evidence))\r\n\r\n  #--------------------------------------------------------\r\n  # Naive solution\r\n  #\r\n  # model.varsDep already has variables in order of dependency...\r\n  # So take that and insert summation terms any time we encounter a new hidden variable\r\n  #\r\n  # Downside is little optimization, likely to have many unnecessary terms\r\n  if False:\r\n    hiddenLeft=set(hiddenVars)\r\n    seq=[]\r\n    for v in model.varsDep:\r\n      #Check if factor variable is a (unhandled) hidden variable\r\n      if v in hiddenLeft:\r\n        seq.append( (True,v) ) #If so, trigger a marginalization\r\n        hiddenLeft.remove(v)   #And mark it as handled\r\n      for p in model.varDist[v].parents:\r\n        #Check if a condition is a (unhandled) hidden variable, etc etc\r\n        if p in hiddenLeft:\r\n          seq.append( (True,p) )\r\n          hiddenLeft.remove(p)\r\n      seq.append( (False,v) ) #Then process the factor itself\r\n    assert(len(hiddenLeft)==0)\r\n\r\n  #--------------------------------------------------------\r\n  # Arbitrary ordering\r\n  #\r\n  # What if we wanted to handle hidden variables in an arbitrary order?\r\n  #\r\n  # Possible, but we'll have to be careful where we put factors, after\r\n  # all their dependencies are satisfied.\r\n  def seq_from_hid_order(hOrd):\r\n    #The trick to make this work is to first assign every\r\n    #hidden variable a priority based on the order\r\n    prio={h:i for i,h in enumerate(hOrd)}\r\n    prio.update((v,-1) for v in model.vars if v not in prio) #non-hidden variables get lowest prio so they don't count\r\n    #Then rate each factor on the highest priority amongst its dependencies\r\n    vOrd=[(max(chain((prio[v],),(prio[c] for c in model.varDist[v].parents))),True,v) for v in model.vars]\r\n    vOrd.extend( (prio[h],False,h) for h in hOrd ) #Add placeholers for summations as well, the False ensures these will sort before their dependents\r\n    vOrd.sort()\r\n    #All that's left is to turn it into the expected sequence format\r\n    return list( (not nm,v) for _,nm,v in vOrd )\r\n  \r\n  #--------------------------------------------------------\r\n  # Brute force best\r\n  #\r\n  # Now, where to get an ordering to use the above?\r\n  #\r\n  # We could brute force try every possible ordering...\r\n  if True:\r\n    bestSeq=None\r\n    bestSeqCost=sys.maxsize\r\n    for hOrd in permutations(hiddenVars):\r\n      tSeq=seq_from_hid_order(hOrd)\r\n      #Note, really should do below norm optimization here too\r\n      \r\n      #Now the tricky bit is to rate each ordering\r\n      #We'll do it by doubling the cost of each factor every time\r\n      #We cross a summation\r\n      tot=0\r\n      ct=1\r\n      for m,v in tSeq:\r\n        if m:\r\n          ct*=2\r\n        else:\r\n          tot+=ct\r\n      \r\n      if tot<bestSeqCost:\r\n        bestSeq=tSeq\r\n        bestSeqCost=tot\r\n    seq=bestSeq\r\n  # But this will be very expensive for large models\r\n  #--------------------------------------------------------\r\n  # Greedy\r\n  #\r\n  # Alternately, we could apply a greedy approach.\r\n  #\r\n  # Some how rate each hidden variable on how expensive we think\r\n  # it is, then put the most expensive ones earliest\r\n  # ***TODO***\r\n\r\n  #--------------------------------------------------------\r\n  # Simple normalization optimization\r\n  #\r\n  # One thing we learned is that for a multiplicative term,\r\n  # if it doesn't mention the query variable, then it's a\r\n  # constant and can be handled via normalization (folded into alpha)\r\n  #\r\n  # This is non-trivial to detect for summation terms, but we\r\n  # can easily do it for factors outside of any summation...\r\n  if True:\r\n    i=0\r\n    while i<len(seq):\r\n      m,v=seq[i]\r\n      if m:\r\n        break #Found first summation, quit\r\n      if v!=queryVar and all(cv!=queryVar for cv in model.varDist[v].parents):\r\n        #No mention of query variable, remove\r\n        del seq[i]\r\n      else:\r\n        i+=1\r\n  \r\n  return seq\r\n\r\ndef calc_query_approx(model,queryVar,queryVal,evidence):\r\n  raise NotImplementedError()\r\n\r\ndef generate_joint_prob_table(model):\r\n  \"\"\"\r\n  Output a joint probability table for the provided model\r\n  \"\"\"\r\n  from tabulate import tabulate\r\n  table=[]\r\n  row=list(model.vars)\r\n  row.append('Joint Pr')\r\n  table.append(row)\r\n  for varVals in truefalse_combination_iterator(model.vars):\r\n    pr=calc_global_joint_prob(model,varVals)\r\n    row=[varVals[x] for x in model.vars]\r\n    row.append(pr)\r\n    table.append(row)\r\n  print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n  return\r\n\r\ndef read_model_file(filename):\r\n  \"\"\"\r\n  Returns model object with the following elements:\r\n    vars : list of strings\r\n      The list of variables the model describes\r\n      In alphabetical order\r\n    varsDep : list of strings\r\n      Same contents as 'vars' but in dependency order (parents come before children)\r\n    varDist : dict of objects\r\n      Distribution information for each variable\r\n      Dictionary key is variable name\r\n      Object has the following elements:\r\n        parents : set of strings\r\n        children : set of strings\r\n        cpt : dict of numbers\r\n          Conditional probability table for variable, i.e., probability of variable true given each combination of parent values\r\n          Dictionary key is a set of (var_name,var_value) tuples containing values for all parents (and nothing else)\r\n            From dict: cpt[frozenset(((x,dict[x]) if x in dict else (x,None) for x in parents))]\r\n  Model file format is as follows:\r\n    Basic file format is Comma-Separated Value (.csv)\r\n    File contains multiple tables, one table per variable representing that variable's conditional probability table\r\n    Tables are separated by atleast one empty line\r\n    Any row that starts with '#' (excluding whitespace) will be treated as a comment and skipped\r\n    Each table:\r\n      Starts with a header row containing variable names\r\n        The last name is the variable whose cond probability is being described\r\n        Any preceding names are considered to be parent variables\r\n      Following rows contain True/False values for each parent and probability for main variable being true\r\n      Any missing parent value combinations will be assumed to be probability 0.5\r\n    Only Bernoulli/Boolean variables can be represented in this file format\r\n  \"\"\"\r\n  class ModelObj:\r\n    def __init__(self):\r\n      self.vars=[]\r\n      self.varsDep=None\r\n      self.varDist={}\r\n\r\n  class VarObj:\r\n    def __init__(self, parents, children, cpt):\r\n      self.parents = parents\r\n      self.children = children\r\n      self.cpt = cpt\r\n\r\n  model=ModelObj()\r\n  #--------------------------------------------------------\r\n  #Read data from file\r\n  with open(filename, newline='') as csvfile:\r\n    csvreader = csv.reader(csvfile)\r\n    \r\n    rowNum=0\r\n    var=None\r\n    varIdx=None\r\n    parents=None\r\n    cpt=None\r\n    for row in ([e for e in x if len(e)>0] for x in chain(csvreader,[[]])):\r\n      rowNum+=1\r\n      srow=''.join(row).strip()\r\n      if srow.startswith('#'):\r\n        continue #Comment line, skip\r\n      if len(srow)==0:\r\n        #Empty line\r\n        if var is not None:\r\n          #End current table\r\n          model.vars.append(var)\r\n          model.varDist[var]=VarObj(frozenset(parents),None,cpt)\r\n          #Wait for new table\r\n          var=None\r\n          varIdx=None\r\n          parents=None\r\n          cpt=None\r\n      elif var is None:\r\n        #Start new table\r\n        if len(row)>1:\r\n          parents=row[0:-1]\r\n        else:\r\n          parents=[]\r\n        varIdx=len(row)-1\r\n        var=row[varIdx]\r\n        cpt={}\r\n      else:\r\n        #Add new entry to table\r\n        if len(row)<varIdx+1:\r\n          error(\"Malformat in csv line {0}: Too few columns for parent values and variable probability\".format(rowNum))\r\n        if len(parents)>0:\r\n          key=frozenset(zip(parents,(e.strip().upper().startswith('T') for e in row[0:-1])))\r\n        else:\r\n          key=frozenset()\r\n        cpt[key]=float(row[-1])\r\n  model.vars.sort()\r\n  #--------------------------------------------------------\r\n  # Check distributions for missing entries\r\n  vCheck=frozenset(model.vars)\r\n  for var in model.vars: #Make sure every mentioned variable has an entry\r\n    for p in model.varDist[var].parents:\r\n      if p not in vCheck:\r\n        error(\"Variable '{0}' has '{1}' as parent, but variable '{1}' was not defined\".format(var,p))\r\n  for var in model.vars: #Check every cpt for missing rows\r\n    varDist=model.varDist[var]\r\n    missingCnt=0\r\n    for varVals in truefalse_combination_iterator(varDist.parents):\r\n      key=frozenset(((x,v) for x,v in varVals.items()))\r\n      if key not in varDist.cpt:\r\n        missingCnt+=1\r\n        varDist.cpt[key]=0.5\r\n    if missingCnt>0:\r\n      print(\"Warning: read_model_file(): Variable '{0}' had {1} missing entries, filled with 0.5\".format(var,missingCnt))\r\n  #--------------------------------------------------------\r\n  # Create children entries\r\n  for var in model.vars:\r\n    model.varDist[var].children=set()\r\n  for var in model.vars:\r\n    for p in model.varDist[var].parents:\r\n      model.varDist[p].children.add(var)\r\n  for var in model.vars:\r\n    model.varDist[var].children=frozenset(model.varDist[var].children)\r\n  #--------------------------------------------------------\r\n  # Create dependency ordering\r\n  varsDep=[x for x in model.vars if len(model.varDist[x].parents)==0] #Start from prior variables (no parents)\r\n  idx=0\r\n  parentsLeft={x:len(model.varDist[x].parents) for x in model.vars} #Track how many of a node's parents are still not in the ordering\r\n  while idx<len(varsDep):\r\n    var=varsDep[idx]\r\n    for c in model.varDist[var].children:\r\n      parentsLeft[c]-=1\r\n      if parentsLeft[c]==0:\r\n        #All parents have been visited, so dependencies of this child are met\r\n        varsDep.append(c)\r\n      elif parentsLeft[c]<0:\r\n        #Repeat visit to a parent can only happen if a cycle exists\r\n        error(\"Cycle in graph detected, involving variable '{0}'\".format(var))\r\n    idx+=1\r\n  model.varsDep=varsDep\r\n  #--------------------------------------------------------\r\n  return model\r\n\r\ndef print_model(model):\r\n  \"\"\"\r\n  Print a model object back out in pretty form\r\n  \"\"\"\r\n  from tabulate import tabulate\r\n  for v in model.vars:\r\n    varDist=model.varDist[v]\r\n    print('--------------------------------------------------')\r\n    print('Variable:',v)\r\n    print('--------------------------------------------------')\r\n    print('Children:',', '.join(varDist.children))\r\n    \r\n    table=[]\r\n    row=list(varDist.parents)\r\n    row.append('P({0}=T|...)'.format(v))\r\n    table.append(row)\r\n    for varVals in truefalse_combination_iterator(varDist.parents):\r\n      pr=read_cpt(model,v,varVals)\r\n      row=[varVals[x] for x in varDist.parents]\r\n      row.append(pr)\r\n      table.append(row)\r\n    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\r\n    print(\"\")\r\n    \r\n##############################################################################\r\n## Main functions\r\ndef main(args):\r\n  global DEBUG_OUTPUT\r\n  if args.debug:\r\n    DEBUG_OUTPUT=1\r\n  #Argument checking plus additional parsing\r\n  if args.mode=='table' and ( args.query is not None or args.evidence is not None ):\r\n    error('Arguments --query and --evidence not allowed in table mode')\r\n  if args.mode=='print' and ( args.query is not None or args.evidence is not None ):\r\n    error('Arguments --query and --evidence not allowed in print mode')\r\n  if args.mode!='table' and args.mode!='print' and ( args.query is None ):\r\n    error('Argument --query required in inference modes')\r\n  elif args.query is not None:\r\n    if '=' not in args.query:\r\n      error('Query variable malformed, must follow VariableName=True or VariableName=False format')\r\n    s=args.query.split('=')\r\n    args.query=(s[0].strip(),s[1].strip().upper().startswith('T'))\r\n  if args.evidence is None:\r\n    args.evidence=[]\r\n  else:\r\n    ev=[]\r\n    for e in args.evidence:\r\n      if '=' not in e:\r\n        error(\"Evidence argument '{0}' malformed, must follow VariableName=True or VariableName=False format\".format(e))\r\n      s=e.split('=')\r\n      ev.append( (s[0].strip(),s[1].strip().upper().startswith('T')) )\r\n    args.evidence={ var:val for var,val in ev }\r\n\r\n  print('Reading model from',args.model)\r\n  model=read_model_file(args.model)\r\n\r\n  if args.mode=='table':\r\n    generate_joint_prob_table(model)\r\n  elif args.mode=='print':\r\n    print_model(model)\r\n  else:\r\n    #One of the inference modes\r\n    #Check inputs against model\r\n    if args.query[0] not in model.vars:\r\n      error(\"'{0}' is not a variable in supplied model\".format(args.query[0]))\r\n    for var,val in args.evidence.items():\r\n      if var not in model.vars:\r\n        error(\"'{0}' is not a variable in supplied model\".format(var))\r\n    #Output problem setup\r\n    print(\"Inference mode:\",args.mode)\r\n    print(\"Query: '{0}' is {1}\".format(args.query[0],args.query[1]))\r\n    if len(args.evidence)==0:\r\n      print(\"No evidence\")\r\n    else:\r\n      print(\"Evidence:\")\r\n      for var,val in args.evidence.items():\r\n        print(\"  '{0}' is {1}\".format(var,val))\r\n\r\n    #Run inference\r\n    pr=None\r\n    if args.mode=='brute':\r\n      pr=calc_query_exact_brute(model,args.query[0],args.query[1],args.evidence)\r\n    elif args.mode=='tree':\r\n      pr=calc_query_exact_tree(model,args.query[0],args.query[1],args.evidence)\r\n    else: #args.mode=='approx'\r\n      pr=calc_query_approx(model,args.query[0],args.query[1],args.evidence)\r\n    print('Probability is',pr)\r\n\r\n  return\r\n\r\ndef error(msg):\r\n  print(msg)\r\n  sys.exit(1)\r\n  return\r\n\r\nif __name__ == '__main__':\r\n  parser = argparse.ArgumentParser(description=\"CSE3521 Homework 3 - Probabilistic Inference\")\r\n  parser.add_argument('--model', type=str, action='store', required=True, help='Input file to load model from')\r\n  parser.add_argument('--mode', type=str, action='store', choices=['brute', 'tree', 'approx', 'table', 'print' ], required=True, help='How to process the model')\r\n  parser.add_argument('--query', '-q', type=str, action='store', help='Query variable to perform inference on, in format VariableName=True or VariableName=False')\r\n  parser.add_argument('--evidence', '-e', type=str, action='append', help='Evidence variable and value, in format VariableName=True or VariableName=False\\nRepeat argument for multiple variables')\r\n  parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging output statements')\r\n  args = parser.parse_args()\r\n  error=lambda msg : parser.error(msg)\r\n  main(args)"
        }
    ]
}